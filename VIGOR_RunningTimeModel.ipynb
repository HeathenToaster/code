{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T13:43:35.962963Z",
     "start_time": "2020-07-23T13:43:33.614263Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import fnmatch\n",
    "import matplotlib.cbook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import platform\n",
    "from pylab import rcParams\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "# session lists in a .py file\n",
    "# import sessionlists\n",
    "%run sessionlists\n",
    "import VIGOR_utils\n",
    "import VIGOR_dataProcessing \n",
    "import VIGOR_WAITMODEL_Functions\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "startTimeNotebook = datetime.datetime.now()\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !git clone https://github.com/HeathenToaster/code\n",
    "    %cd code\n",
    "\n",
    "plt.style.use('./Figures/test.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T13:43:36.014402Z",
     "start_time": "2020-07-23T13:43:35.968581Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to data is: /home/david/Desktop/DATA\n",
      "Current working directory: /home/david/Desktop/code\n",
      "Save Path:  /home/david/Desktop/Save\n"
     ]
    }
   ],
   "source": [
    "#### Define folder with data \n",
    "if platform.system()=='Linux':\n",
    "    root=\"/home/david/Desktop/DATA\"\n",
    "    savePath=\"/home/david/Desktop/Save\"\n",
    "elif platform.system()=='Darwin':\n",
    "    root=\"/Users/tom/Desktop/DATA\"\n",
    "    savePath=\"/Users/tom/Desktop/Save\"\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !gdown --id 1oxWJLF67TEifzQFgtUHIyhnEsS6AeQUW\n",
    "    !unzip -qq /content/code/datacopy.zip\n",
    "    root=\"/content/code/datacopy\"\n",
    "    savePath=\"/content/Save\"\n",
    "    print(\"I'm running on Colab\")\n",
    "print(\"Path to data is: %s\"%root)\n",
    "\n",
    "retval = os.getcwd()\n",
    "print(\"Current working directory: %s\" % retval)\n",
    "print(\"Save Path: \", savePath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for RatF00\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'brainstatus_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31222/1782875968.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loading data for {animal}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# define marker and color for each rat, used in plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mfnmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RatF*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrat_markers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"$\\u2640$\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrainstatus_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrainstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mfnmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RatM*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrat_markers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"$\\u2642$\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrainstatus_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrainstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mfnmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Rat00*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrat_markers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"$\\u2426$\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrainstatus_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrainstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'brainstatus_plot' is not defined"
     ]
    }
   ],
   "source": [
    "rat_markers = {}\n",
    "sequence = {}\n",
    "\n",
    "# define colors for each rat\n",
    "palette = {'RatF00': (0.4, 0.0, 0.0), 'RatF01': (0.55, 0.13, 0.13), 'RatF02': (0.8, 0.2, 0.2), 'RatF03': (1, 0.6, 0.6),\n",
    "            'RatM00': (0.0, 0.4, 0.0), 'RatM01': (0.13, 0.55, 0.13), 'RatM02': (0.2, 0.8, 0.2), 'RatM03': (0.6, 1.0, 0.6)}\n",
    "\n",
    "# define brain status (lesion/CNO/intact) for each rat, used in plots\n",
    "# needs to be properly implemented, setting is in behav_params for each session.\n",
    "brainstatus = {'RatF00': 'normal', 'RatF01': 'lesion', 'RatF02': 'normal', 'RatF03': 'lesion',\n",
    "               'RatM00': 'normal', 'RatM01': 'normal', 'RatM02': 'normal', 'RatM03': 'normal'}\n",
    "\n",
    "# define list of rats to be analyzed\n",
    "# only these rats will be loaded and analyzed for now   \n",
    "animalList = ['RatF00', 'RatF01', 'RatF02', 'RatM00', 'RatM01', 'RatM02']  # [os.path.basename(path) for path in sorted(glob.glob(root+\"/Rat*\"))]\n",
    "\n",
    "for index, animal in enumerate(animalList):\n",
    "    print(f'Loading data for {animal}')\n",
    "    # define marker and color for each rat, used in plots\n",
    "    if fnmatch.fnmatch(animal, 'RatF*'): rat_markers[animal]=[palette[animal], \"$\\u2640$\", brainstatus_plot(brainstatus[animal])]\n",
    "    elif fnmatch.fnmatch(animal, 'RatM*'): rat_markers[animal]=[palette[animal], \"$\\u2642$\", brainstatus_plot(brainstatus[animal])]\n",
    "    elif fnmatch.fnmatch(animal, 'Rat00*'): rat_markers[animal]=[(0.0, 0.0, 0.0), \"$\\u2426$\", brainstatus_plot(brainstatus[animal])]\n",
    "    else: print(\"error, this is not a rat you got here\")\n",
    "\n",
    "    # loop over all sessions for each rat and get the pickled preprocessed data. Data is processed in VIGOR_Preprocess.py\n",
    "    # data (list or list of lists) for each variable is stored in a dictionary with keys (animal, session)\n",
    "    for session in sorted(matchsession(animal, dist60+dist90+dist120 + \\\n",
    "                                                TM20+TM10+TM2+TMrev2+TMrev10+TMrev20+\\\n",
    "                                                dist60bis+dist90bis+dist120bis)):\n",
    "        # get the preprocessed data from the pickle file\n",
    "        # In this notebook we only need the sequence of events, so we only load that\n",
    "        sequence[animal, session] = get_from_pickle(root, animal, session, name=\"test.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_running_times(data, memsize=3, filter=[0, 3600], tooshort=0.5):\n",
    "    \"\"\"get waiting times from data\"\"\"\n",
    "    running_times = {k:[] for k in meankeys(generate_targetList(seq_len=memsize)[::-1])}\n",
    "    for i in range(len(data)):\n",
    "        if data[i][1] == 'run':\n",
    "            if filter[0] <= data[i][0] <= filter[1] and data[i][3] != 0:\n",
    "                if data[i][3] > tooshort:  # filter out waits shorter than 0.5s\n",
    "                    try:\n",
    "                        avg_rwd = round(np.mean([data[i-n-1][2] for n in range(1, (memsize*2)+1, 2)]),2)\n",
    "                        running_times[avg_rwd].append(data[i][3])\n",
    "                    except:  # put the first n waits in rwd=1 (because we don't have the previous n runs to compute the average reward)\n",
    "                        running_times[1].append(data[i][3])\n",
    "    return running_times\n",
    "\n",
    "# separate the data into time and reward bins\n",
    "def prepare_dataR(sequence, animalList, sessionList, memsize=3, time_bins=6):\n",
    "    bin_size = 3600/time_bins\n",
    "    targetlist = generate_targetList(memsize)[::-1]\n",
    "    temp_data = {}\n",
    "    for bin in range(time_bins):\n",
    "        temp_data[bin] = {}\n",
    "        for animal in animalList:\n",
    "            temp_data[bin][animal] = {k:[] for k in meankeys(targetlist)}\n",
    "            for session in matchsession(animal, sessionList):\n",
    "                temp_data[bin][animal] = combine_dict(temp_data[bin][animal], get_running_times(sequence[animal, session], memsize=memsize, filter=[bin*bin_size, (bin+1)*bin_size]))\n",
    "    \n",
    "    data = {}\n",
    "    for animal in animalList:\n",
    "        data[animal] = np.zeros((time_bins, len(meankeys(targetlist)))).tolist()\n",
    "        for i, avg in enumerate(meankeys(targetlist)):  # 1 -> 0\n",
    "            for bin in range(time_bins):\n",
    "                data[animal][bin][i] = np.asarray(temp_data[bin][animal][avg])\n",
    "    return data\n",
    "\n",
    "\n",
    "data60 = prepare_dataR(sequence, animalList, dist60)\n",
    "data90 = prepare_dataR(sequence, animalList, dist90)\n",
    "data120 = prepare_dataR(sequence, animalList, dist120)\n",
    "\n",
    "data20 = prepare_dataR(sequence, animalList, TM20)\n",
    "data10 = prepare_dataR(sequence, animalList, TM10)\n",
    "data2 = prepare_dataR(sequence, animalList, TM2+TMrev2)\n",
    "datarev10 = prepare_dataR(sequence, animalList, TMrev10)\n",
    "datarev20 = prepare_dataR(sequence, animalList, TMrev20)\n",
    "\n",
    "dataAll = prepare_dataR(sequence, animalList, dist60+dist90+dist120 + TM20+TM10+TM2+TMrev2+TMrev10+TMrev20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task  \n",
    "The task and the main behavioral results are presented in notebook 1.  \n",
    "We developed an automated foraging task in which water restricted rats have to run back and\n",
    "forth on a treadmill to obtain drops of water. Within one hour-long session, the\n",
    "probability of getting a reward was alternatively high and low in 5 min-long uncued\n",
    "blocks (dark and light gray in fig.1).  \n",
    "\n",
    "<img src=\"Figures/Picturetask1.png\" alt=\"task\" width=\"300\"/>  \n",
    "\n",
    "## Experimental conditions\n",
    "Across sessions, we manipulated the effort rats had to produce by either\n",
    "modifying the length of the treadmill while its speed remained null, or by\n",
    "manipulating the speed and direction of the belt to facilitate or counteract the\n",
    "animals' crossings.\n",
    "\n",
    "<img src=\"Figures/conditions.png\" alt=\"conditions\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim of the Notebook \n",
    "One of the variables that we analyze is the duration of the running times (blue part on the track of the animal, Fig 1A.).  \n",
    "A quick analysis of the median running time shows that it increases along the \n",
    "session, but no clear modulation in function of reward (Fig1B.); i.e. animals are less motivated/more tired as time passes, they run slower and don't modulate their speed according to the reward probability.   \n",
    "\n",
    "In this notebook we characterise how time and reward probability affects running time.  \n",
    "\n",
    "Fig 1.  \n",
    "A) Position of an example animal across a 120 cm session. Blue is run epoch, orange is running epoch.  \n",
    "Reward probability in 5 min blocks is either high (90%, dark gray), or low (10%, light gray)  \n",
    "B) Median running time across session and blocks.  \n",
    "Reward probability in 5 min blocks is either high (90%, dark gray), or low (10%, light gray)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 1.\n",
    "animal, session = 'RatM01', 'RatM01_2021_07_22_17_14_48'  # 'RatF00', 'RatF00_2021_07_24_15_28_05'\n",
    "fig, axs = plt.subplots(1, 2, figsize = (24, 4), gridspec_kw={'width_ratios': [5, 1]})\n",
    "\n",
    "# Load preprocessed data for one animal and one session. params contains the parameters of the session,\n",
    "# runningTimeInLeftBin and runningTimeInRightBin contain the running time in each time bin for each animal\n",
    "example_params = get_from_pickle(root, animal, session, name=\"params.p\")\n",
    "example_runningTimeInLeftBin, example_runningTimeInRightBin = get_from_pickle(root, animal, session, name=\"timeRun.p\")\n",
    "\n",
    "# plot the trajectory\n",
    "plot_animal_trajectory(root=root, animal=animal, session=session, params=example_params, barplotaxes=[0, 3600, 0, 120], \n",
    "                 xyLabels=[\"Time (min)\", \"Position along treadmill (cm)\"], title=\"Position of example animal across a 120 cm session\", ax=axs[0])\n",
    "\n",
    "# plot the median running time in each time block\n",
    "plot_median_per_bin([example_runningTimeInLeftBin[i]+example_runningTimeInRightBin[i] for i in range(0, 12)], \n",
    "                example_params['rewardProbaBlock'], example_params['blocks'], barplotaxes=[0, 3600/60, 0, 2.5], \n",
    "                color=['dodgerblue'], xyLabels=[\"Time (min)\",\"running time (s)\"], title=\"Median running time\", scatter=False, stat='Med. ', ax=axs[1]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data binning\n",
    "\n",
    "The data is binned as in the running time model. \n",
    "This yields the following complete distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import cauchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_full_distributionRun(data, animal, plot_fit=False, N_bins=6, N_avg=4):\n",
    "    '''plot the full distribution of the data'''\n",
    "    ###\n",
    "    # NOT SAME NUMBER OF OBSERVATIONS IN EACH CURVE, BUT SAME NORMALIZATION ???\n",
    "    ###\n",
    "\n",
    "    def _plot_Cauchy_fitted(waits, p, ax=None, color='k', plot_fit=True, label='', lw=2):\n",
    "        \"\"\"plot fitted wald distribution without fitting\"\"\"\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "        waits = np.asarray(waits)\n",
    "\n",
    "        bins = np.linspace(0, waits.max(), int(max(waits))*25)\n",
    "        ydata, xdata, _ = ax.hist(waits, bins=bins,\n",
    "                                  color=color, alpha=1, zorder=1,\n",
    "                                  density=True,  # weights=np.ones_like(waits) / len(waits),\n",
    "                                  histtype=\"step\", lw=lw, cumulative=-1, label=label)\n",
    "\n",
    "        if plot_fit:\n",
    "            x = np.linspace(0.001, 500, 10000)\n",
    "            loc, scale = p\n",
    "            ax.plot(x, cauchy.sf(x, loc=loc, scale=scale), color=color, lw=2, zorder=4, ls='--', label=f'{label} fit')\n",
    "        return ax\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1, N_bins, figsize=(3*N_bins, 3))\n",
    "    (mu, sigma, mu_t, sigma_t, mu_R, sigma_R), loss = modelrun_fit(data[animal])\n",
    "\n",
    "    lbls = ['1', '0.67', '0.33', '0']\n",
    "    for j in range(N_bins):\n",
    "        for i in range(N_avg):\n",
    "            color = plt.get_cmap('inferno')(i / N_avg)\n",
    "            lw = 3.5 if j == 0 and i == 1 else 2\n",
    "            _plot_Cauchy_fitted(data[animal][j][i],\n",
    "                              (mu + j*mu_t + i*mu_R,\n",
    "                               sigma + j*sigma_t + i*sigma_R), \n",
    "                              ax=axs[j], color=color, plot_fit=plot_fit, label=lbls[i], lw=lw)\n",
    "        axs[j].set_xlim(.1, 100)\n",
    "        axs[j].set_ylim(.001, 1.1)\n",
    "        axs[j].set_xscale(\"log\")\n",
    "        axs[j].set_yscale(\"log\")\n",
    "        axs[j].set_xlabel('log(idle time) (s)')\n",
    "        axs[j].set_ylabel('log(1-CDF)')\n",
    "        axs[j].set_title(f'{j*10}-{(j+1)*10} min')\n",
    "        axs[j].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 3.\n",
    "# distribution of running times\n",
    "\n",
    "animal = 'RatM01'\n",
    "exampledata = prepare_dataR(sequence, animalList, dist120)\n",
    "plot_full_distributionRun(exampledata, animal, plot_fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import cauchy\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "x = np.linspace(-5, 50, 1000)\n",
    "axs[0].plot(x, cauchy.pdf(x, 0, 1), 'k-', label='Default')\n",
    "axs[0].plot(x, cauchy.pdf(x, 2.5, 1), 'c', label='increased mu')\n",
    "axs[0].plot(x, cauchy.pdf(x, 0, 2.5), 'r-', label='increased sigma')\n",
    "axs[0].plot(x, cauchy.pdf(x, 1.35, .2), '--', label='expe data example')\n",
    "axs[0].set_ylabel('PDF')\n",
    "axs[0].set_xlabel('t')\n",
    "axs[0].set_xlim(-5, 5)\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(x, cauchy.sf(x, 0, 1), 'k-', label='Default')\n",
    "axs[1].plot(x, cauchy.sf(x, 2.5, 1), 'c', label='increased mu')\n",
    "axs[1].plot(x, cauchy.sf(x, 0, 2.5), 'r-', label='increased sigma')\n",
    "axs[1].plot(x, cauchy.sf(x, 1.35, .2), '--', label='expe data example')\n",
    "axs[1].set_xlabel('t')\n",
    "axs[1].set_xlim(0.01, 50)\n",
    "axs[1].set_ylim(0.01, 1.1)\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_ylabel('CDF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "We fit running time distributions $x$ to the Cauchy distribution using the maximum likelihood estimation method.\n",
    "\n",
    "We find the parameters $\\hat{\\mu}, \\hat{\\sigma}$ that maximizes the log-likelihood function $\\ell (Cauchy(x); \\mu, \\sigma)$, with $\\mu, \\sigma \\in \\Mu, \\Sigma$, using the default 'L-BFGS-B' method from scipy. https://en.wikipedia.org/wiki/Limited-memory_BFGS#L-BFGS-B  \n",
    " \n",
    "Fig 5.\n",
    "Sanity check: We generate synthetic running times from a Wald distribution with known $\\mu, \\sigma$ parameters, and fit them to check that the fitted parameters are the same as the known parameters. We are able to recover the parameters well (QUANTIFY).  \n",
    "\n",
    "TOP LEFT) Synthetic data fit with different values of $\\sigma$.  \n",
    "TOP RIGHT) Synthetic data fit with different values of $\\mu$  \n",
    "BOT LEFT&RIGHT) Hidden (lines) and recovered (dots) parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo\n",
    "t0 = 0\n",
    "N = 1000\n",
    "std = 1\n",
    "AAA = 5\n",
    "MEAN = 1\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "means = np.linspace(0.1, 1, 10)\n",
    "plot_color_line(axs[1, 0], means, means, means, cmap = 'autumn', vmin=0, vmax=1, alpha=1, linewidth=2, linestyle = '-', zorder = 1)\n",
    "axs[1, 0].plot(means, [t0 for _ in means], color='g')\n",
    "axs[1, 0].plot(means, [AAA for _ in means], color='c')\n",
    "for mean in means:\n",
    "    mu, theta, sigma, lossWald = example_wald_fit(mean, std, AAA, t0, N, ax=axs[0, 0], color=plt.get_cmap('autumn')(mean / max(means)))\n",
    "    axs[1, 0].scatter(mean, mu, color='c', label='mu_fit')\n",
    "    axs[1, 0].scatter(mean, theta, color='g', label='theta_fit')\n",
    "    axs[1, 0].scatter(mean, sigma, color=plt.get_cmap('autumn')(mean / max(means)), label='sigma_fit')\n",
    "    axs[1, 0].set_xlabel('sigma ground truth')\n",
    "    axs[1, 0].set_ylabel('fitted params')\n",
    "\n",
    "As = np.linspace(1, 5, 10)\n",
    "plot_color_line(axs[1, 1], As, As, As, cmap = 'winter', vmin=0, vmax=5, alpha=1, linewidth=2, linestyle = '-', zorder = 1)\n",
    "axs[1, 1].plot(As, [t0 for _ in As], color='g')\n",
    "axs[1, 1].plot(As, [MEAN for _ in As], color='r')\n",
    "for A in As:\n",
    "    mu, theta, sigma, lossWald = example_wald_fit(MEAN, std, A, t0, N, ax=axs[0, 1], color=plt.get_cmap('winter')(A / max(As)))\n",
    "    axs[1, 1].scatter(A, mu, color=plt.get_cmap('winter')(A / max(As)), label='mu_fit')\n",
    "    axs[1, 1].scatter(A, theta, color='g', label='theta_fit')\n",
    "    axs[1, 1].scatter(A, sigma, color='r', label='sigma_fit')\n",
    "    axs[1, 1].set_xlabel(' mu ground truth')\n",
    "    axs[1, 1].set_ylabel('fitted params')\n",
    "\n",
    "\n",
    "legend_without_duplicate_labels(axs[1, 0])\n",
    "legend_without_duplicate_labels(axs[1, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running time model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have the Cauchy distribution with $\\mu$ and $\\sigma$ parameters that we can fit and recover from individual running times distributions. \n",
    "We've seen earlier that the sub-distributions of running times in our data changes with time $t$ but not with the reward history $R$.  \n",
    "Can we link $t$ and $R$ to $\\mu$ and/or $\\sigma$?  \n",
    "\n",
    "To evaluate how $\\mu$ and $\\sigma$ change with $t$ and/or $R$ we define the following model:\n",
    "\n",
    "$\\Mu(t, R) = \\mu_0 + \\mu_t t + \\mu_R R$  \n",
    "$\\Sigma(t, R) = \\sigma_0 + \\sigma_t t + \\sigma_R R$  \n",
    "\n",
    "With:  \n",
    "$\\mu_0, \\sigma_0$ parameters at the beginning of the session (0-10 min) and $\\frac{3}{3}$ rewards have been obtained  \n",
    "$\\mu_t, \\sigma_t$ how $\\mu$ and $\\sigma$ evolve linearly with time  \n",
    "$\\mu_R, \\sigma_R$ how $\\mu$ and $\\sigma$ evolve linearly with reward history  \n",
    "\n",
    "\n",
    "We find the best $\\mu_0, \\mu_t, \\mu_R, \\sigma_0, \\sigma_t, \\sigma_R$ that minimize the total error of the model using maximum likelihood estimation.  \n",
    "\n",
    "The total error of the model is defined as:  \n",
    "$\\sum_{n_t=0}^{6} \\sum_{n_R=0}^{1} \\frac{\\ell (Wald(x(t, R)); \\mu_0 + \\mu_t + \\mu_R, \\sigma_0 + \\sigma_t + \\sigma_R)}{N(t, R)}$  \n",
    "\n",
    "with:  \n",
    "$x$, experimental data  \n",
    "$x(t, R)$, experimental data for a given $t$ and $R$  \n",
    "$N(t, R)$, number of observations in $x(t, R)$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical representation of $\\mu$ and $\\sigma$ evolution\n",
    "Evolution of $\\mathrm{A}$ and $\\sigma$ on the z axis, with $R$ on the x axis, $t$ on the y axis.  \n",
    "- $\\Mu$: starts low, increases with $t$, no change with $R$  \n",
    "- $\\sigma$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok\n",
    "from scipy.stats import cauchy\n",
    "def modelrun_crit(params, *args, robustness_param=1e-20):\n",
    "    mu, sigma, mu_prime, sigma_prime, mu_second, sigma_second = params\n",
    "    neg_log_lik_val = 0\n",
    "    N_bins, N_avg = args[1]\n",
    "    MU = np.zeros((N_bins, N_avg))\n",
    "    SIGMA = np.zeros((N_bins, N_avg))\n",
    "\n",
    "    for bin in range(N_bins):\n",
    "        for avg in range(N_avg):\n",
    "            MU[bin, avg] = mu + bin*mu_prime + avg*mu_second\n",
    "            SIGMA[bin, avg] = sigma + bin*sigma_prime + avg*sigma_second\n",
    "\n",
    "    for bin in range(N_bins):\n",
    "        for avg in range(N_avg):\n",
    "            _mu = MU[bin, avg] if MU[bin, avg] > 0 else 1e-8\n",
    "            _sigma = SIGMA[bin, avg] if SIGMA[bin, avg] > 0 else 1e-8\n",
    "\n",
    "            pdf_vals = cauchy.pdf(args[0][bin][avg], scale=_sigma, loc=_mu,)\n",
    "            ln_pdf_vals = np.log(pdf_vals + robustness_param)\n",
    "            log_lik_val = ln_pdf_vals.sum()\n",
    "\n",
    "            n = len(args[0][bin][avg]) if len(args[0][bin][avg]) > 0 else 1\n",
    "            neg_log_lik_val += (-log_lik_val / n)\n",
    "            # except:\n",
    "            #     neg_log_lik_val += 0  # add 0 instead of throwing an error when there is no data in a bin*avg\n",
    "    return neg_log_lik_val\n",
    "\n",
    "def modelrun_compare(params, *args, robustness_param=1e-20):\n",
    "    \"\"\"BIC to compare models with different number of parameters and curves\"\"\"\n",
    "    mu, sigma, mu_t, sigma_t, mu_R, sigma_R = params\n",
    "    BIC = 0\n",
    "    N_bins, N_avg = args[1]\n",
    "    N_params = args[2]\n",
    "    MU = np.zeros((N_bins, N_avg))\n",
    "    SIGMA = np.zeros((N_bins, N_avg))\n",
    "\n",
    "    for bin in range(N_bins):\n",
    "        for avg in range(N_avg):\n",
    "            MU[bin, avg] = mu + bin*mu_t + avg*mu_R\n",
    "            SIGMA[bin, avg] = sigma + bin*sigma_t + avg*sigma_R\n",
    "\n",
    "    for bin in range(N_bins):\n",
    "        for avg in range(N_avg):\n",
    "            _mu = MU[bin, avg] if MU[bin, avg] > 0 else 1e-8\n",
    "            _sigma = SIGMA[bin, avg] if SIGMA[bin, avg] > 0 else 1e-8\n",
    "            # try:\n",
    "            pdf_vals = cauchy.pdf(args[0][bin][avg], loc=_mu, scale=_sigma)\n",
    "            ln_pdf_vals = np.log(pdf_vals + robustness_param)\n",
    "            log_lik_val = ln_pdf_vals.sum()\n",
    "\n",
    "            n = len(args[0][bin][avg]) if len(args[0][bin][avg]) > 0 else 1\n",
    "            k = N_params\n",
    "            BIC += k * np.log(n) - 2 * log_lik_val\n",
    "            # except:\n",
    "            #     BIC += 0  # add 0 instead of throwing an error when there is no data in a bin*avg\n",
    "    return BIC\n",
    "\n",
    "#params = a, t, g, a', t', g', a'', t'', g''\n",
    "def modelrun_fit(data, init=[1, 1, 1, 1, 1, 1], f=modelrun_crit, \n",
    "N_bins=6, N_avg=4, N_params=2, mu_t_fixed=False, sigma_t_fixed=False, mu_R_fixed=False, sigma_R_fixed=False, ):\n",
    "    params_init = np.array(init)\n",
    "    mu_t_bounds = (None, None) if not mu_t_fixed else (0, 1e-8)\n",
    "    sigma_t_bounds = (None, None) if not sigma_t_fixed else (0, 1e-8)\n",
    "    mu_R_bounds = (None, None) if not mu_R_fixed else (0, 1e-8)\n",
    "    sigma_R_bounds = (None, None) if not sigma_R_fixed else (0, 1e-8)\n",
    "\n",
    "    res = scipy.optimize.minimize(f, params_init, args=(data, [N_bins, N_avg], N_params), \n",
    "                                        bounds=((0, None), (0, None), \n",
    "                                            mu_t_bounds, sigma_t_bounds, \n",
    "                                            mu_R_bounds, sigma_R_bounds))\n",
    "    return res.x, res.fun\n",
    "\n",
    "modelrun_fit(data60[animal])\n",
    "modelrun_fit(data60[animal], f=modelrun_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT THE SAME ANIMAL AS BEFORE (RatM01)!!!!!!!!\n",
    "\n",
    "def plot_parameter_evolutionRunTime(p, axs=None, N_bins=6, N_avg=4):\n",
    "\n",
    "    (mu, sigma, mu_t, sigma_t, mu_R, sigma_R) = p\n",
    "    MU = np.zeros((N_bins, N_avg))\n",
    "    SIGMA = np.zeros((N_bins, N_avg))\n",
    "\n",
    "    for bin in range(N_bins):\n",
    "        for avg in range(N_avg):\n",
    "            MU[bin, avg] = mu + bin*mu_t + avg*mu_R\n",
    "            SIGMA[bin, avg] = sigma + bin*sigma_t + avg*sigma_R\n",
    "\n",
    "    if axs is None:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5), subplot_kw={'projection': '3d'})\n",
    "\n",
    "    X, Y = np.meshgrid(np.arange(N_avg), np.arange(N_bins))\n",
    "    axs[0].plot_surface(X, Y, MU, cmap='winter', edgecolor='none')\n",
    "    axs[0].set_title(r'Value of $\\Mu$')\n",
    "    axs[0].set_xticks([0, 1, 2, 3])\n",
    "    axs[0].set_xticklabels(['1', '0.67', '0.33', '0'])\n",
    "    axs[0].set_xlabel('Reward history', labelpad=5)\n",
    "    axs[0].set_ylim([-0.5, 5.5])\n",
    "    axs[0].set_yticks([0, 1, 2, 3, 4, 5])\n",
    "    axs[0].set_yticklabels(['0-10', '10-20', '20-30', '30-40', '40-50', '50-60'], va='center', ha='left', rotation=-15)\n",
    "    axs[0].set_ylabel('Time bin', labelpad=15)\n",
    "    axs[0].set_zlabel(r'$\\mu$', labelpad=5)\n",
    "    axs[0].set_zlim([1.2, 1.8])\n",
    "    axs[0].set_zticks([1.2, 1.4, 1.6, 1.8])\n",
    "    # axs[0].set_zticklabels(['1.0', '1.5', '2.0'])\n",
    "    axs[0].text(0., 5, 2., r\"$\\mu R$: Effect of reward on $\\Mu$\", color='black', fontsize=12, zdir='x', zorder=10)\n",
    "    axs[0].text(3, 0.5, 1.2, r\"$\\mu t$: Effect of time on $\\Mu$\", color='black', fontsize=12, zdir=(0, 6, 1), zorder=10)\n",
    "    axs[0].text(0, 0, 0.6, r\"$\\mu_0$: Baseline $\\Mu$\", color='black', fontsize=12, zdir='x', zorder=10)\n",
    "\n",
    "    axs[1].plot_surface(X, Y, SIGMA, cmap='autumn', edgecolor='none')\n",
    "    axs[1].set_title(r'Value of $\\Sigma$')\n",
    "    axs[1].set_xticks([0, 1, 2, 3])\n",
    "    axs[1].set_xticklabels(['1', '0.67', '0.33', '0'])\n",
    "    axs[1].set_xlabel('Reward history')\n",
    "    axs[1].set_ylim([-0.5, 5.5])\n",
    "    axs[1].set_yticks([0, 1, 2, 3, 4, 5])\n",
    "    axs[1].set_yticklabels(['0-10', '10-20', '20-30', '30-40', '40-50', '50-60'], va='center', ha='left', rotation=-15)\n",
    "    axs[1].set_ylabel('Time bin')\n",
    "    axs[1].set_zlabel(r'$\\sigma$')\n",
    "    axs[1].set_zlim([.0, .3])\n",
    "    # axs[1].set_zticks([.2, .4, .6, 0.8])\n",
    "    # axs[1].set_zticklabels(['0.2', '0.4', '0.6', '0.8'])\n",
    "    axs[1].text(0, 5, 0, r\"$\\sigma R$: Effect of reward on $\\Sigma$\", color='black', fontsize=12, zdir=(4, 0, -.5), zorder=10)\n",
    "    axs[1].text(0, -1, .6, r\"$\\sigma t$: Effect of time on $\\Sigma$\", color='black', fontsize=12, zdir=(0, -10, .1), zorder=10)\n",
    "    axs[1].text(0, 0, 0.4, r\"$\\sigma_0$: Baseline $\\Sigma$\", color='black', fontsize=12, zdir='x', zorder=10)\n",
    "\n",
    "# example fit model on all 120 cm session for each animal\n",
    "# print fitted parameters and loss for each animal\n",
    "animal = 'RatF01'\n",
    "exampledata = prepare_dataR(sequence, animalList, dist120)\n",
    "p, loss = modelrun_fit(exampledata[animal])\n",
    "(mu, sigma, mu_t, sigma_t, mu_R, sigma_R) = p\n",
    "\n",
    "print(f\"{animal}  mu:{mu:.2f}, mut:{mu_t:.2f}, muR: {mu_R:.2f}, || s: {sigma:.2f}, st: {sigma_t:.2f}, sR: {sigma_R:.2f} ||| loss: {loss:.2f}\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), subplot_kw={'projection': '3d'})\n",
    "plot_parameter_evolutionRunTime((mu, sigma, mu_t, sigma_t, mu_R, sigma_R), axs=axs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "### Example animal fit - 120cm\n",
    "Fit of the model for the same example animal on all Dist-120cm sessions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'RatM01'\n",
    "exampledata = prepare_dataR(sequence, animalList, dist120)\n",
    "plot_full_distributionRun(exampledata, animal, plot_fit=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All experimental conditions fit\n",
    "We can now do the same as above for all experimental conditions (Distances and TM speed) and for each rat.  \n",
    "Each color is a different rat.  \n",
    "\n",
    "$Mu$:  \n",
    "- $\\mu_0$ > 0, positive bound at start, increases with distance and when TM speed reverse  \n",
    "- $\\mu_t$ > 0, $\\mu$ increases with time  \n",
    "- $\\mu_R$ = 0, no effect of reward history on $\\mu$  \n",
    "\n",
    "The average running time increases when distance increases, and when TM is reversed -> animals do not manage to keep up the pace. \n",
    "The average running time increases with time, but not with reward history.  \n",
    "**$mu$ is congruent with *tiredness*, low at the start of session, increases with time/total distance traveled**\n",
    "\n",
    "\n",
    "$\\sigma$:  \n",
    "- $\\sigma_0$ > 0, initial variability  \n",
    "- $\\sigma t$ ~ 0, no effect of time on $\\sigma$  \n",
    "- $\\sigma R$ > 0, $\\sigma$ increases with reward history  \n",
    "\n",
    "**Variability increases when no reward. *exploration/exploitation*?**  \n",
    " \n",
    "\n",
    "**!!! Do stats !!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok\n",
    "fig, axs = plt.subplots(6, 2, figsize=(10, 20))\n",
    "ylabels = [r'$\\mu$', r\"$\\mu'$\", r\"$\\mu''$\", r'$\\sigma$', r\"$\\sigma'$\", r\"$\\sigma''$\"]\n",
    "# ylabels = [r'$\\mu$', r\"$\\mu'/\\mu$\", r\"$\\mu''/\\mu$\", r'$\\sigma$', r\"$\\sigma'/\\sigma$\", r\"$\\sigma''/\\sigma$\"]\n",
    "ylims = [[-.2, 2.5], [-.1, .3], [-.25, .25], [-.2, .2], [-.1, .1], [-.1, .1], ]\n",
    "\n",
    "\n",
    "\n",
    "mu = {}\n",
    "sigma = {}\n",
    "mu_t = {}\n",
    "sigma_t = {}\n",
    "mu_R = {}\n",
    "sigma_R = {}\n",
    "lossWald = {}\n",
    "\n",
    "mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed = False, False, False, False\n",
    "# mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed = False, True, True, False\n",
    "# mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed = False, False, True, False\n",
    "# mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed = True, True, True, True\n",
    "\n",
    "for animal in animalList:\n",
    "\n",
    "    mu[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    sigma[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    mu_t[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    sigma_t[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    mu_R[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    sigma_R[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    lossWald[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "\n",
    "\n",
    "    for cond, data in zip([\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"], [data60, data90, data120, data20, data10, data2, datarev10, datarev20]):\n",
    "        (mu[animal][cond], sigma[animal][cond], \\\n",
    "        mu_t[animal][cond], sigma_t[animal][cond], \\\n",
    "        mu_R[animal][cond], sigma_R[animal][cond]), lossWald[animal][cond] = modelrun_fit(data[animal], mu_t_fixed=mu_t_fixed, \n",
    "                                                                                                                                    sigma_t_fixed=sigma_t_fixed, \n",
    "                                                                                                                                    mu_R_fixed=mu_R_fixed, \n",
    "                                                                                                                                    sigma_R_fixed=sigma_R_fixed, \n",
    "                                                                                                                                    )\n",
    "        # ######### normalize p' and p'' by p\n",
    "        # mu_t[animal][cond] /= mu[animal][cond]\n",
    "        # sigma_t[animal][cond] /= sigma[animal][cond]\n",
    "        # mu_R[animal][cond] /= mu[animal][cond]\n",
    "        # sigma_R[animal][cond] /= sigma[animal][cond]\n",
    "        # ###############\n",
    "\n",
    "    vars = [mu, mu_t, mu_R, sigma, sigma_t, sigma_R, ]\n",
    "\n",
    "    for i, (var, ylabel, ylim) in enumerate(zip(vars, ylabels, ylims)):\n",
    "        axs[i, 0].scatter(np.arange(3), [var[animal][\"60\"], var[animal][\"90\"], var[animal][\"120\"]], color=rat_markers[animal][0], label=animal)\n",
    "        axs[i, 0].set_title(f\"\")\n",
    "        axs[i, 0].set_xticks(np.arange(3))\n",
    "        axs[i, 0].set_xticklabels([\"60\", \"90\", \"120\"])\n",
    "        axs[i, 0].set_ylabel(ylabel)\n",
    "        axs[i, 0].set_xlim(-.5, 2.5)\n",
    "        axs[i, 0].set_ylim(ylim)\n",
    "        axs[i, 0].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    for i, (var, ylabel, ylim) in enumerate(zip(vars, ylabels, ylims)):\n",
    "        axs[i, 1].scatter(np.arange(5), [var[animal][\"20\"], var[animal][\"10\"], var[animal][\"2\"], var[animal][\"rev10\"], var[animal][\"rev20\"]], color=rat_markers[animal][0], label=animal)\n",
    "        axs[i, 1].set_title(f\"\")\n",
    "        axs[i, 1].set_xticks(np.arange(5))\n",
    "        axs[i, 1].set_xticklabels([\"20\", \"10\", \"0\", \"-10\", \"-20\"])\n",
    "        axs[i, 1].set_ylabel(ylabel)\n",
    "        axs[i, 1].set_xlim(-.5, 4.5)\n",
    "        axs[i, 1].set_ylim(ylim)\n",
    "        axs[i, 1].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "axs[i, 0].set_xlabel(\"Distance\")\n",
    "axs[i, 1].set_xlabel(r'$v_{belt}$')\n",
    "\n",
    "#mean per condition\n",
    "for idx, cond in enumerate([\"60\", \"90\", \"120\"]):\n",
    "    for jdx, var in enumerate([ mu, mu_t, mu_R, sigma, sigma_t, sigma_R,]):\n",
    "        d = [var[animal][cond] for animal in animalList]\n",
    "        mean, std = np.mean(d), np.std(d)/np.sqrt(len(d))\n",
    "        s, p = stats.ttest_1samp(d, 0)\n",
    "        if p < .05: axs[jdx, 0].scatter(idx+.3, mean, color='k', marker=r'$\\ast$')\n",
    "        axs[jdx, 0].errorbar(idx+.2, mean, yerr=std, color='black', marker='o', markersize=5, capsize=5, capthick=2, linewidth=2)\n",
    "\n",
    "for idx, cond in enumerate([\"20\", \"10\", \"2\", \"rev10\", \"rev20\"]):\n",
    "    for jdx, var in enumerate([ mu, mu_t, mu_R, sigma, sigma_t, sigma_R,]):\n",
    "        d = [var[animal][cond] for animal in animalList]\n",
    "        mean, std = np.mean(d), np.std(d)/np.sqrt(len(d))\n",
    "        s, p = stats.ttest_1samp(d, 0)\n",
    "        if p < .05: axs[jdx, 1].scatter(idx+.3, mean, color='k', marker=r'$\\ast$')\n",
    "        axs[jdx, 1].errorbar(idx+.2, mean, yerr=std, color='black', marker='o', markersize=5, capsize=5, capthick=2, linewidth=2)\n",
    "\n",
    "test_all_conds_between_themselves([\"60\", \"90\", \"120\"], vars, ax=axs[:, 0])\n",
    "test_all_conds_between_themselves([\"20\", \"10\", \"2\", \"rev10\", \"rev20\"], vars, ax=axs[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok\n",
    "targetlist = generate_targetList(3)[::-1]\n",
    "fig, axs = plt.subplots(9, len(meankeys(targetlist)), figsize=(12, 27))\n",
    "exampledata = prepare_dataR(sequence, animalList, dist120)\n",
    "\n",
    "mu = {}\n",
    "sigma = {}\n",
    "mu_prime = {}\n",
    "sigma_prime = {}\n",
    "mu_second = {}\n",
    "sigma_second = {}\n",
    "lossWald = {}\n",
    "loc = {}\n",
    "\n",
    "def plot_cauchy_fitted(waits, p, ax=None, color='k'):\n",
    "    if ax is None: ax = plt.gca()\n",
    "    waits = np.asarray(waits)\n",
    "\n",
    "    bins=np.linspace(0, waits.max(), int(max(waits))*10)\n",
    "    ydata, xdata, _ = ax.hist(waits, bins=bins,\n",
    "                    color=color, alpha=.5, zorder=1, \n",
    "                    density=True, # weights=np.ones_like(waits) / len(waits),\n",
    "                    histtype=\"step\", lw=2, \n",
    "                    cumulative=-1,\n",
    "                    )\n",
    "\n",
    "    x = np.linspace(0.01, 500, 10000)\n",
    "    # (mu, theta, sigma) = p\n",
    "    loc, scale = p\n",
    "    ax.plot(x, cauchy.sf(x, scale=scale, loc=loc), color=color, lw=1, zorder=4, label=f'mean={scale:.2f}, s={s:.2f}')\n",
    "\n",
    "    # ax.plot(x, 1-Wald_cdf(x, mu, theta, sigma), color=color, lw=1, zorder=4, label=f'mean={sigma:.2f}, A={mu:.2f}, t0={theta:.2f}')\n",
    "\n",
    "    ax.set_xlim(.1, 150)\n",
    "    ax.set_ylim(.001, 1.1)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel('log Wait time')\n",
    "    ax.set_ylabel('log 1-CDF')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "for animal in animalList:\n",
    "\n",
    "    (mu[animal], sigma[animal], \n",
    "        mu_prime[animal], sigma_prime[animal], \n",
    "        mu_second[animal], sigma_second[animal]), lossWald[animal] = modelrun_fit(exampledata[animal], \n",
    "                                                                                    # mu_t_fixed=False, \n",
    "                                                                                    # sigma_t_fixed=True, \n",
    "                                                                                    # mu_R_fixed=True, \n",
    "                                                                                    # sigma_R_fixed=True, \n",
    "                                                                                    )\n",
    "\n",
    "    print(f\"{animal}   mu: {mu[animal]:.2f}, mut: {mu_prime[animal]:.2f}, muR: {mu_second[animal]:.2f}, || sig: {sigma[animal]:.2f}, sigt: {sigma_prime[animal]:.2f}, sigR: {sigma_second[animal]:.2f},||| loss: {lossWald[animal]:.2f}\")\n",
    "\n",
    "    x = [0, 1, 2, 3, 4, 5]\n",
    "    for i, avg in enumerate(meankeys(targetlist)):\n",
    "        axs[0, i].plot(x, [mu[animal] + (bin*mu_prime[animal]) for bin in x] + i*mu_second[animal], color=rat_markers[animal][0], label=animal, marker='o')\n",
    "        axs[0, i].set_title(f\"{avg:.2f}\")\n",
    "        axs[0, i].set_xticks(x)\n",
    "        # axs[0, i].set_xlabel('Time bin')\n",
    "        axs[0, i].set_ylabel(r'$\\mu$')\n",
    "        axs[0, i].set_ylim([1, 3])\n",
    "        \n",
    "        axs[1, i].plot(x, [sigma[animal] + (bin*sigma_prime[animal]) for bin in x] + i*sigma_second[animal], color=rat_markers[animal][0], label=animal, marker='o')\n",
    "        # axs[1, i].set_title(f\"{avg:.2f}\")\n",
    "        axs[1, i].set_xticks(x)\n",
    "        axs[1, i].set_xlabel('Time bin')\n",
    "        axs[1, i].set_ylabel(r'$\\sigma$')\n",
    "        axs[1, i].set_ylim([0, 1])\n",
    "\n",
    "    y = lossWald[animal]\n",
    "    axs[2, 0].plot(0, y, color=rat_markers[animal][0], label=animal, marker='o')\n",
    "    axs[2, 0].set_title(f\"model loss\")\n",
    "    axs[2, 0].set_ylabel(r'loss')\n",
    "\n",
    "    for j in range(6):\n",
    "        for i, avg in enumerate(meankeys(targetlist)):\n",
    "            plot_cauchy_fitted(exampledata[animal][j][i], (mu[animal] + j*mu_prime[animal] + i*mu_second[animal], sigma[animal] + j*sigma_prime[animal] + i*sigma_second[animal]), ax=axs[3+j, i], color=rat_markers[animal][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetlist = generate_targetList(seq_len=4)[::-1]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 7))\n",
    "\n",
    "\n",
    "losses = {}\n",
    "the_keys_i_want = [(False, False, False, False), \n",
    "                    (True, False, False, False), \n",
    "                    (False, True, False, False), \n",
    "                    (False, False, True, False), \n",
    "                    (False, False, False, True), \n",
    "                    (True, True, True, True)]\n",
    "\n",
    "the_keys_i_want = [(False, False, False, False), \n",
    "                    (False, False, True, False), \n",
    "                    (False, True, False, False), \n",
    "                    (True, False, False, False), \n",
    "                    (False, False, False, True), \n",
    "                    (True, True, True, True)]\n",
    "\n",
    "for animal in animalList:\n",
    "    losses[animal] = {}\n",
    "    for mu_t_fixed in [False, True]:\n",
    "        for sigma_t_fixed in [False, True]:\n",
    "            for mu_R_fixed in [False, True]:\n",
    "                for sigma_R_fixed in [False, True]:\n",
    "                    number_of_params = 2  # mu, sigma\n",
    "                    number_of_extra_params = mu_t_fixed+sigma_t_fixed+mu_R_fixed+sigma_R_fixed\n",
    "                    loss = modelrun_fit(dataAll[animal],\n",
    "                                        f=modelrun_compare,\n",
    "                                        mu_t_fixed=mu_t_fixed, \n",
    "                                        sigma_t_fixed=sigma_t_fixed, \n",
    "                                        mu_R_fixed=mu_R_fixed, \n",
    "                                        sigma_R_fixed=sigma_R_fixed, \n",
    "                                        N_params=number_of_params + (4 - number_of_extra_params),\n",
    "                                        )[1]\n",
    "\n",
    "                    print(f'{animal}: {mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed}, n_params={number_of_params + (4 - number_of_extra_params)}, loss={loss}')\n",
    "\n",
    "                    losses[animal][(mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed)] = loss\n",
    "\n",
    "    axs[0].scatter(np.arange(16), losses[animal].values(), color=rat_markers[animal][0], label=animal)\n",
    "    axs[0].set_title(f\"loss\")\n",
    "    axs[0].set_ylabel(r'$\\Sigma$ Loss')\n",
    "    axs[0].set_xticks(np.arange(-1, 16))\n",
    "    axs[0].set_xticklabels(dict_to_xticklabels(losses[animal], labels=['μt', 'μR', 'σt', 'σR']))\n",
    "    # axs[0].set_ylim([80000, 140000])\n",
    "    axs[0].set_xlim([-1.5, 16.5])\n",
    "\n",
    "    axs[1].scatter(np.arange(16), list(losses[animal].values())/losses[animal][False, False, False, False], color=rat_markers[animal][0], label=animal)\n",
    "    axs[1].set_title(f\"nomalized loss\")\n",
    "    axs[1].set_ylabel(r'$\\Sigma$ Loss, Normalized')\n",
    "    axs[1].set_xticks(np.arange(-1, 16))\n",
    "    axs[1].set_xticklabels(dict_to_xticklabels(losses[animal], labels=['μt', 'μR', 'σt', 'σR']))\n",
    "    # axs[1].set_ylim([.975, 1.5])\n",
    "    axs[1].set_xlim([-1.5, 16.5])\n",
    "    axs[1].axhline(1, color='k', linestyle='--')\n",
    "\n",
    "    for i, key in enumerate(the_keys_i_want):\n",
    "        axs[2].scatter(i+1, losses[animal][key]/losses[animal][False, False, False, False], color=rat_markers[animal][0], label=animal)\n",
    "    axs[2].set_title(f\"normalized loss (1)\")\n",
    "    axs[2].set_ylabel(r'$\\Sigma$ Loss')\n",
    "    axs[2].set_xticks(np.arange(7))\n",
    "    axs[2].set_xticklabels(dict_to_xticklabels({k:losses[animal][k] for k in the_keys_i_want}, labels=['μt', 'μR', 'σt', 'σR']))\n",
    "    # axs[2].set_ylim([.975, 1.5])\n",
    "    axs[2].set_xlim([-.5, 6.5])\n",
    "    axs[2].axhline(1, color='k', linestyle='--')\n",
    "\n",
    "# average by key\n",
    "means = [np.mean([losses[animal][key] for animal in animalList]) for key in losses[animal].keys()]\n",
    "yerr = [np.std([losses[animal][key] for animal in animalList]) for key in losses[animal].keys()]\n",
    "axs[0].errorbar(np.arange(16)+.25, means, yerr=yerr, color='k', label='Mean', marker='o', fmt=' ')\n",
    "\n",
    "means_norm = [np.mean([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in losses[animal].keys()]\n",
    "yerr_norm = [np.std([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in losses[animal].keys()]\n",
    "axs[1].errorbar(np.arange(16)+.25, means_norm, yerr=yerr_norm, color='k', label='Mean', marker='o', fmt=' ')\n",
    "\n",
    "means_norm_select = [np.mean([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in the_keys_i_want]\n",
    "yerr_norm_select = [np.std([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in the_keys_i_want]\n",
    "axs[2].errorbar(np.arange(len(the_keys_i_want))+1.25, means_norm_select, yerr=yerr_norm_select, color='k', label='Mean', marker='o', fmt=' ')\n",
    "\n",
    "\n",
    "for idx, key in enumerate(losses[animal].keys()):\n",
    "    data = [losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "    s, p = stats.ttest_1samp(data, 1)\n",
    "    if p < .05: axs[1].scatter(idx+.25, np.mean(data) + np.std(data) + 0.0025, color='k', marker=r'$\\ast$')\n",
    "\n",
    "print(\"all vs ++++: (1 sample t-tests)\")\n",
    "for idx, key in enumerate(the_keys_i_want):\n",
    "    data = [losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "    s, p = stats.ttest_1samp(data, 1)\n",
    "    if p < .05: axs[2].scatter(idx+1.25, np.mean(data) + np.std(data) + 0.0025, color='k', marker=r'$\\ast$')\n",
    "    print(f\"1 vs. {key}: {p:.3f} {'*' if p < .05 else ''}\")\n",
    "print()\n",
    "print(\"comparisons: (2 sample t-tests)\")\n",
    "test_all_keys_between_themselves(losses, the_keys_i_want[1:], axs[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_xticklabels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<memsizes = np.arange(1, 9)\n",
    "\n",
    "losses = {k:np.zeros(len(memsizes)) for k in animalList}\n",
    "sessions = dist60+dist90+dist120+TM20+TM10+TM2+TMrev2+TMrev10+TMrev20\n",
    "\n",
    "for idx, memsize in enumerate(memsizes):\n",
    "    data_all = prepare_data(sequence, animalList, sessions, memsize=memsize, time_bins=6)\n",
    "    for animal in animalList:\n",
    "        p, losses[animal][idx] = modelrun_fit(data_all[animal], f=modelrun_compare, N_bins=6, N_avg=len(meankeys(generate_targetList(seq_len=memsize)[::-1])))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "avglosses = np.zeros((len(animalList), len(memsizes)))\n",
    "for idx, animal in enumerate(animalList):\n",
    "    axs[0].plot(memsizes, losses[animal], color=rat_markers[animal][0])\n",
    "    axs[1].plot(memsizes, (losses[animal])/(losses[animal][0]), color=rat_markers[animal][0], label=animal)\n",
    "    avglosses[idx] = losses[animal]/losses[animal][0]\n",
    "\n",
    "f = np.mean(avglosses[:3], axis=0)\n",
    "m = np.mean(avglosses[3:], axis=0)\n",
    "avglosses = np.median(avglosses, axis=0)\n",
    "\n",
    "axs[1].plot(memsizes, avglosses, color='k', lw=2)\n",
    "z = np.poly1d(np.polyfit(memsizes, avglosses, 4))\n",
    "x=np.linspace(1, 8, 100)\n",
    "axs[1].plot(x, z(x), color='k', lw=3, ls='--')\n",
    "print(x[np.argmin(z(x))])\n",
    "# axs[0].plot(memsizes, f/3, color='r', lw=2, ls='--')\n",
    "# axs[0].plot(memsizes, m/3, color='g', lw=2, ls='--')\n",
    "# axs[1].plot(memsizes, f, color='r', lw=2, ls='--')\n",
    "# axs[1].plot(memsizes, m, color='g', lw=2, ls='--')\n",
    "\n",
    "axs[0].set_xlabel('mem span')\n",
    "axs[1].set_xlabel('mem span')\n",
    "axs[0].set_ylabel(r'$\\Sigma$ loss')\n",
    "axs[1].set_ylabel(r'$\\Sigma$ loss, norm')\n",
    "axs[1].legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "a05f93782d31fb45d30263a0389582a01d7e14abf3ec6aacde92652303ee35ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
