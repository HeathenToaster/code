{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T13:43:35.962963Z",
     "start_time": "2020-07-23T13:43:33.614263Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import fnmatch\n",
    "import matplotlib.cbook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import platform\n",
    "from pylab import rcParams\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "startTimeNotebook = datetime.datetime.now()\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !git clone https://github.com/HeathenToaster/code\n",
    "    %cd code\n",
    "\n",
    "# session lists in a .py file\n",
    "# import sessionlists\n",
    "%run sessionlists\n",
    "from VIGOR_utils import *\n",
    "from VIGOR_MODELS_Functions import *\n",
    "\n",
    "plt.style.use('./Figures/test.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T13:43:36.014402Z",
     "start_time": "2020-07-23T13:43:35.968581Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Define folder with data \n",
    "if platform.system()=='Linux':\n",
    "    root=\"/home/david/Desktop/ALLDATA\"\n",
    "    savePath=\"/home/david/Desktop/Save\"\n",
    "elif platform.system()=='Darwin':\n",
    "    root=\"/Users/tom/Desktop/sequencesALLDATA\"\n",
    "    savePath=\"/Users/tom/Desktop/Save\"\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !gdown --id 1BSepSzm1-KQJlUvv8C23p_qyHvtzvrZ8\n",
    "    !unzip -qq /content/code/sequencesALLDATA.zip\n",
    "    root=\"/content/code/sequencesALLDATA\"\n",
    "    savePath=\"/content/Save\"\n",
    "    print(\"I'm running on Colab\")\n",
    "print(\"Path to data is: %s\"%root)\n",
    "\n",
    "retval = os.getcwd()\n",
    "print(\"Current working directory: %s\" % retval)\n",
    "print(\"Save Path: \", savePath)\n",
    "\n",
    "print(f'Found {len(glob.glob(root+\"/*\"))} rats in the data folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_markers = {}\n",
    "sequence = {}\n",
    "\n",
    "# define colors for each rat\n",
    "palette = {'RatF00': (0.4, 0.0, 0.0), 'RatF01': (0.55, 0.13, 0.13), 'RatF02': (0.8, 0.2, 0.2),\n",
    "           'RatM00': (0.0, 0.4, 0.0), 'RatM01': (0.13, 0.55, 0.13), 'RatM02': (0.2, 0.8, 0.2),\n",
    "           'RatF20': (0.4, 0.0, 0.0), 'RatF21': (0.55, 0.13, 0.13), 'RatF22': (0.8, 0.2, 0.2),\n",
    "           'RatM20': (0.0, 0.4, 0.0), 'RatM21': (0.13, 0.55, 0.13), 'RatM22': (0.2, 0.8, 0.2),\n",
    "           'RatF30': (0.4, 0.0, 0.0), 'RatF31': (0.55, 0.13, 0.13), 'RatF32': (0.8, 0.2, 0.2), 'RatF33': (0.8, 0.2, 0.2),\n",
    "           'RatM30': (0.0, 0.4, 0.0), 'RatM31': (0.13, 0.55, 0.13), 'RatM32': (0.2, 0.8, 0.2), \n",
    "           'RatF30L': (0.4, 0.0, 0.0), 'RatF31L': (0.55, 0.13, 0.13), 'RatF32L': (0.8, 0.2, 0.2), 'RatF33L': (0.8, 0.2, 0.2),\n",
    "           'RatM30L': (0.0, 0.4, 0.0), 'RatM31L': (0.13, 0.55, 0.13), 'RatM32L': (0.2, 0.8, 0.2)}\n",
    "\n",
    "# define brain status (lesion/CNO/intact) for each rat, used in plots\n",
    "# needs to be properly implemented, setting is in behav_params for each session.\n",
    "brainstatus = {'RatF00': 'normal', 'RatF01': 'normal', 'RatF02': 'normal',\n",
    "               'RatM00': 'normal', 'RatM01': 'normal', 'RatM02': 'normal',\n",
    "               'RatF20': 'thcre', 'RatF21': 'thcre', 'RatF22': 'thcre',\n",
    "               'RatM20': 'thcre', 'RatM21': 'thcre', 'RatM22': 'thcre',\n",
    "               'RatF30': 'lesion', 'RatF31': 'lesion', 'RatF32': 'normal', 'RatF33': 'normal',\n",
    "               'RatM30': 'lesion', 'RatM31': 'normal', 'RatM32': 'normal',\n",
    "                'RatF30L': 'lesion', 'RatF31L': 'lesion', 'RatF32L': 'biglesion', 'RatF33L': 'biglesion',\n",
    "                'RatM30L': 'lesion', 'RatM31L': 'biglesion', 'RatM32L': 'biglesion'\n",
    "               }\n",
    "\n",
    "markers = {'normal': 'o', 'thcre': 'd', 'lesion': 'x', 'biglesion': 'X'}\n",
    "lines = {'normal': '-', 'thcre': '--', 'lesion': ':', 'biglesion': '-.'}\n",
    "\n",
    "# define list of rats to be analyzed\n",
    "# first batch  \n",
    "# animalList = ['RatF00', 'RatF01', 'RatF02', 'RatM00', 'RatM01', 'RatM02']\n",
    "\n",
    "# all rats\n",
    "# animalList = [os.path.basename(path) for path in sorted(glob.glob(root+\"/Rat*\"))]\n",
    "# animalList += ['RatF30L', 'RatF31L', 'RatF32L', 'RatF33L', 'RatM30L', 'RatM31L', 'RatM32L']\n",
    "\n",
    "# INTACT RATS\n",
    "animalList = ['RatF00', 'RatF01', 'RatF02', 'RatM00', 'RatM01', 'RatM02', 'RatF32', 'RatF33', 'RatM31', 'RatM32']\n",
    "# animalList += ['RatF20', 'RatF21', 'RatF22', 'RatM20', 'RatM21', 'RatM22']\n",
    "\n",
    "\n",
    "for index, animal in enumerate(animalList):\n",
    "    print(f'Loading data for {animal}')\n",
    "    # define marker and color for each rat, used in plots\n",
    "    if fnmatch.fnmatch(animal, 'RatF*'):\n",
    "        rat_markers[animal]=[palette[animal], markers[brainstatus[animal]], lines[brainstatus[animal]]]\n",
    "    elif fnmatch.fnmatch(animal, 'RatM*'):\n",
    "        rat_markers[animal]=[palette[animal], markers[brainstatus[animal]], lines[brainstatus[animal]]]\n",
    "    elif fnmatch.fnmatch(animal, 'Rat00*'):\n",
    "        rat_markers[animal]=[(0.0, 0.0, 0.0), \"$\\u2426$\",]\n",
    "    else:\n",
    "        print(\"error, this is not a rat you got here\")\n",
    "\n",
    "    # loop over all sessions for each rat and get the pickled preprocessed data. Data is processed in VIGOR_Preprocess.py\n",
    "    # data (list or list of lists) for each variable is stored in a dictionary with keys (animal, session)\n",
    "    for session in sorted(matchsession(animal, dist60+dist90+dist120 + TM20+TM10+TM2+TMrev2+TMrev10+TMrev20)):\n",
    "                                                #  dist60bis+dist90bis+dist120bis)):\n",
    "\n",
    "        # get the preprocessed data from the pickle file\n",
    "        # In this notebook we only need the sequence of events, so we only load that\n",
    "        biglesion = True if 'L' in session else False\n",
    "        sequence[animal, session] = get_from_pickle(root, animal[0:6], session, name=\"sequence.p\", biglesion=biglesion)\n",
    "\n",
    "data60 = prepare_data_running_times(sequence, animalList, dist60)\n",
    "data90 = prepare_data_running_times(sequence, animalList, dist90)\n",
    "data120 = prepare_data_running_times(sequence, animalList, dist120)\n",
    "\n",
    "data20 = prepare_data_running_times(sequence, animalList, TM20)\n",
    "data10 = prepare_data_running_times(sequence, animalList, TM10)\n",
    "data2 = prepare_data_running_times(sequence, animalList, TM2+TMrev2)\n",
    "datarev10 = prepare_data_running_times(sequence, animalList, TMrev10)\n",
    "datarev20 = prepare_data_running_times(sequence, animalList, TMrev20)\n",
    "\n",
    "dataAll = prepare_data_running_times(sequence, animalList, dist60+dist90+dist120 + TM20+TM10+TM2+TMrev2+TMrev10+TMrev20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task  \n",
    "The task and the main behavioral results are presented in notebook 1.  \n",
    "We developed an automated foraging task in which water restricted rats have to run back and\n",
    "forth on a treadmill to obtain drops of water. Within one hour-long session, the\n",
    "probability of getting a reward was alternatively high and low in 5 min-long uncued\n",
    "blocks (dark and light gray in fig.1).  \n",
    "\n",
    "<img src=\"Figures/Picturetask1.png\" alt=\"task\" width=\"300\"/>  \n",
    "\n",
    "## Experimental conditions\n",
    "Across sessions, we manipulated the effort rats had to produce by either\n",
    "modifying the length of the treadmill while its speed remained null, or by\n",
    "manipulating the speed and direction of the belt to facilitate or counteract the\n",
    "animals' crossings.\n",
    "\n",
    "<img src=\"Figures/conditions.png\" alt=\"conditions\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim of the Notebook \n",
    "One of the variables that we analyze is the duration of the running times (blue part on the track of the animal, Fig 1A.).  \n",
    "A quick analysis of the median running time shows that it increases along the \n",
    "session, but no clear modulation in function of reward (Fig1B.); i.e. animals are less motivated/more tired as time passes, they run slower and don't modulate their speed according to the reward probability.   \n",
    "\n",
    "In this notebook we characterise how time and reward probability affects running time.  \n",
    "\n",
    "Fig 1.  \n",
    "A) Position of an example animal across a 120 cm session. Blue is run epoch, orange is running epoch.  \n",
    "Reward probability in 5 min blocks is either high (90%, dark gray), or low (10%, light gray)  \n",
    "B) Median running time across session and blocks.  \n",
    "Reward probability in 5 min blocks is either high (90%, dark gray), or low (10%, light gray)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 1.\n",
    "animal, session = 'RatM01', 'RatM01_2021_07_22_17_14_48'  # 'RatF00', 'RatF00_2021_07_24_15_28_05'\n",
    "fig, axs = plt.subplots(1, 2, figsize = (24, 4), gridspec_kw={'width_ratios': [5, 1]})\n",
    "\n",
    "# Load preprocessed data for one animal and one session. params contains the parameters of the session,\n",
    "# runningTimeInLeftBin and runningTimeInRightBin contain the running time in each time bin for each animal\n",
    "example_params = get_from_pickle(root, animal, session, name=\"params.p\")\n",
    "example_runningTimeInLeftBin, example_runningTimeInRightBin = get_from_pickle(root, animal, session, name=\"timeRun.p\")\n",
    "\n",
    "# plot the trajectory\n",
    "plot_animal_trajectory(root=root, animal=animal, session=session, params=example_params, barplotaxes=[0, 3600, 0, 120], \n",
    "                 xyLabels=[\"Time (min)\", \"Position along treadmill (cm)\"], title=\"Position of example animal across a 120 cm session\", ax=axs[0])\n",
    "\n",
    "# plot the median running time in each time block\n",
    "plot_median_per_bin([example_runningTimeInLeftBin[i]+example_runningTimeInRightBin[i] for i in range(0, 12)], \n",
    "                example_params['rewardProbaBlock'], example_params['blocks'], barplotaxes=[0, 3600/60, 0, 2.5], \n",
    "                color=['dodgerblue'], xyLabels=[\"Time (min)\",\"running time (s)\"], title=\"Median running time\", scatter=False, stat='Med. ', ax=axs[1]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data binning\n",
    "\n",
    "The data is binned as in the running time model. \n",
    "This yields the following complete distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 3.\n",
    "# distribution of running times\n",
    "\n",
    "animal = 'RatM01'\n",
    "exampledata = prepare_data_running_times(sequence, animalList, dist120)\n",
    "plot_full_distribution_run(exampledata, animal, plot_fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cauchy distribution\n",
    "\n",
    "We use the Cauchy distribution to fit the running times.  \n",
    "Why --> distribution has big peak, and some running times are long\n",
    "Cauchy looks like normal distribution but has a bigger peak and a fat tail. Fits well with only two parameters and I did not find anything better (lognormal, frechet, norm, weibull have been tested). Is the ratio of two independant normally distributed variables (e.g. Speed = Thirst/Tiredness ??).  \n",
    "\n",
    "The probability density function of the Cauchy distribution is:  \n",
    "\n",
    "$Cauchy(x|\\mu, \\sigma) = \\frac{1}{\\pi \\sigma \\left[1+ \\left(\\frac{x-\\mu}{\\sigma}\\right)²\\right]}$  \n",
    "\n",
    "The cauchy distribution has 2 parameters: $\\mu$, $\\sigma$.  \n",
    "- $\\mu$ is location of the peak (shifts the distribution)  \n",
    "- $\\sigma$ is half the width at half the peak (spread).  $\\sigma > 0$\n",
    "\n",
    "Note that the Cauchy distribution classically uses the parameters $x_0$ and $\\gamma$ (because mean and variance are undefined), we use $\\mu$ instead of $x_0$ and $\\sigma$ instead of $\\gamma$ to avoid confusion with parameters in the idle time model.  \n",
    "\n",
    "\n",
    "&nbsp;  \n",
    "A) Changes in the Cauchy distribution as a result of changes in the $\\mu$, $\\sigma$ parameters.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "x = np.linspace(-5, 50, 1000)\n",
    "axs[0].plot(x, stats.cauchy.pdf(x, 0, 1), 'k-', label='Default')\n",
    "axs[0].plot(x, stats.cauchy.pdf(x, 2.5, 1), 'c', label='increased mu')\n",
    "axs[0].plot(x, stats.cauchy.pdf(x, 0, 2.5), 'r-', label='increased sigma')\n",
    "axs[0].plot(x, stats.cauchy.pdf(x, 1.35, .2), '--', label='expe data example')\n",
    "axs[0].set_ylabel('PDF')\n",
    "axs[0].set_xlabel('t')\n",
    "axs[0].set_xlim(-5, 5)\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(x, stats.cauchy.sf(x, 0, 1), 'k-', label='Default')\n",
    "axs[1].plot(x, stats.cauchy.sf(x, 2.5, 1), 'c', label='increased mu')\n",
    "axs[1].plot(x, stats.cauchy.sf(x, 0, 2.5), 'r-', label='increased sigma')\n",
    "axs[1].plot(x, stats.cauchy.sf(x, 1.35, .2), '--', label='expe data example')\n",
    "axs[1].set_xlabel('t')\n",
    "axs[1].set_xlim(0.01, 50)\n",
    "axs[1].set_ylim(0.01, 1.1)\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_ylabel('CDF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "We fit running time distributions $x$ to the Cauchy distribution using the maximum likelihood estimation method.\n",
    "\n",
    "We find the parameters $\\hat{\\mu}, \\hat{\\sigma}$ that maximizes the log-likelihood function $\\ell (Cauchy(x); \\mu, \\sigma)$, with $\\mu, \\sigma \\in \\mathrm{M}, \\Sigma$, using the default 'L-BFGS-B' method from scipy. https://en.wikipedia.org/wiki/Limited-memory_BFGS#L-BFGS-B  \n",
    " \n",
    "Fig 5.\n",
    "Sanity check: We generate synthetic running times from a Wald distribution with known $\\mu, \\sigma$ parameters, and fit them to check that the fitted parameters are the same as the known parameters. We are able to recover the parameters well (QUANTIFY).  \n",
    "\n",
    "TOP LEFT) Synthetic data fit with different values of $\\sigma$.  \n",
    "TOP RIGHT) Synthetic data fit with different values of $\\mu$  \n",
    "BOT LEFT&RIGHT) Hidden (lines) and recovered (dots) parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "std = .1\n",
    "MEAN = 1\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "x = np.linspace(0.01, 500, 1000)\n",
    "means = np.linspace(1, 2, 10)\n",
    "plot_color_line(axs[1, 0], means, means, means, cmap = 'autumn', vmin=0, vmax=2.5, alpha=1, linewidth=2, linestyle = '-', zorder = 1)\n",
    "axs[1, 0].plot(means, [std for _ in means], color='c')\n",
    "for mean in means:\n",
    "    mu, sigma, _ = example_cauchy_fit(mean, std, N, ax=axs[0, 0], color=plt.get_cmap('autumn')(mean / max(means)))\n",
    "    axs[1, 0].scatter(mean, sigma, color='c', label='')\n",
    "    axs[1, 0].scatter(mean, mu, color=plt.get_cmap('autumn')(mean / max(means)), label='mu_fit')\n",
    "    axs[1, 0].set_xlabel('sigma ground truth')\n",
    "    axs[1, 0].set_ylabel('fitted params')\n",
    "\n",
    "As = np.linspace(.05, .15, 10)\n",
    "plot_color_line(axs[1, 1], As, As, As, cmap = 'winter', vmin=0, vmax=.25, alpha=1, linewidth=2, linestyle = '-', zorder = 1)\n",
    "axs[1, 1].plot(As, [MEAN for _ in As], color='r')\n",
    "for A in As:\n",
    "    mu, sigma, _ = example_cauchy_fit(MEAN, A, N, ax=axs[0, 1], color=plt.get_cmap('winter')(A / max(As)))\n",
    "    axs[1, 1].scatter(A, sigma, color=plt.get_cmap('winter')(A / max(As)), label='sigma_fit')\n",
    "    axs[1, 1].scatter(A, mu, color='r', label='')\n",
    "    axs[1, 1].set_xlabel(' mu ground truth')\n",
    "    axs[1, 1].set_ylabel('fitted params')\n",
    "\n",
    "legend_without_duplicate_labels(axs[1, 0])\n",
    "legend_without_duplicate_labels(axs[1, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running time model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have the Cauchy distribution with $\\mu$ and $\\sigma$ parameters that we can fit and recover from individual running times distributions. \n",
    "We've seen earlier that the sub-distributions of running times in our data changes with time $t$ but not with the reward history $R$.  \n",
    "Can we link $t$ and $R$ to $\\mu$ and/or $\\sigma$?  \n",
    "\n",
    "To evaluate how $\\mu$ and $\\sigma$ change with $t$ and/or $R$ we define the following model:\n",
    "\n",
    "$\\mathrm{M}(t, R) = \\mu_0 + \\mu_t t + \\mu_R R$  \n",
    "$\\Sigma(t, R) = \\sigma_0 + \\sigma_t t + \\sigma_R R$  \n",
    "\n",
    "With:  \n",
    "$\\mu_0, \\sigma_0$ parameters at the beginning of the session (0-10 min) and $\\frac{3}{3}$ rewards have been obtained  \n",
    "$\\mu_t, \\sigma_t$ how $\\mu$ and $\\sigma$ evolve linearly with time  \n",
    "$\\mu_R, \\sigma_R$ how $\\mu$ and $\\sigma$ evolve linearly with reward history  \n",
    "\n",
    "\n",
    "We find the best $\\mu_0, \\mu_t, \\mu_R, \\sigma_0, \\sigma_t, \\sigma_R$ that minimize the total error of the model using maximum likelihood estimation.  \n",
    "\n",
    "The total error of the model is same method as idle time\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical representation of $\\mu$ and $\\sigma$ evolution\n",
    "Evolution of $\\mathrm{A}$ and $\\sigma$ on the z axis, with $R$ on the x axis, $t$ on the y axis.  \n",
    "- $\\mathrm{M}$: starts low, increases with $t$, no change with $R$  \n",
    "- $\\sigma$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT THE SAME ANIMAL AS BEFORE (RatM01)!!!!!!!!\n",
    "\n",
    "# example fit model on all 120 cm session for each animal\n",
    "# print fitted parameters and loss for each animal\n",
    "animal = 'RatF01'\n",
    "exampledata = prepare_data_running_times(sequence, animalList, dist120)\n",
    "p, loss = modelrun_fit(exampledata[animal])\n",
    "(mu, sigma, mu_t, sigma_t, mu_R, sigma_R) = p\n",
    "\n",
    "print(f\"{animal}  mu:{mu:.2f}, mut:{mu_t:.2f}, muR: {mu_R:.2f}, || s: {sigma:.2f}, st: {sigma_t:.2f}, sR: {sigma_R:.2f} ||| loss: {loss:.2f}\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), subplot_kw={'projection': '3d'})\n",
    "plot_parameter_evolutionRun((mu, sigma, mu_t, sigma_t, mu_R, sigma_R), axs=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetlist = generate_targetList(seq_len=4)[::-1]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 7))\n",
    "\n",
    "the_keys_i_want = [(False, False, False, False), \n",
    "                    (True, False, False, False), \n",
    "                    (False, True, False, False), \n",
    "                    (False, False, True, False), \n",
    "                    (False, False, False, True), \n",
    "                    (True, True, True, True)]\n",
    "\n",
    "if os.path.exists(\"picklejar/running_time_model_BIC_ablation.p\"):\n",
    "    losses = pickle.load(open(\"picklejar/running_time_model_BIC_ablation.p\", \"rb\"))\n",
    "else:\n",
    "    losses = {}\n",
    "    for animal in animalList:\n",
    "        losses[animal] = {}\n",
    "        for mu_t_fixed in [False, True]:\n",
    "            for sigma_t_fixed in [False, True]:\n",
    "                for mu_R_fixed in [False, True]:\n",
    "                    for sigma_R_fixed in [False, True]:\n",
    "                        number_of_params = 2  # mu, sigma\n",
    "                        number_of_extra_params = mu_t_fixed+sigma_t_fixed+mu_R_fixed+sigma_R_fixed\n",
    "                        loss = modelrun_fit(dataAll[animal],\n",
    "                                            f=modelrun_compare,\n",
    "                                            mu_t_fixed=mu_t_fixed, \n",
    "                                            sigma_t_fixed=sigma_t_fixed, \n",
    "                                            mu_R_fixed=mu_R_fixed, \n",
    "                                            sigma_R_fixed=sigma_R_fixed, \n",
    "                                            N_params=number_of_params + (4 - number_of_extra_params),\n",
    "                                            )[1]\n",
    "\n",
    "                        losses[animal][(mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed)] = loss\n",
    "\n",
    "for animal in animalList:\n",
    "    axs[0].scatter(np.arange(16), losses[animal].values(), color=rat_markers[animal][0], label=animal)\n",
    "    axs[0].set_title(f\"loss\")\n",
    "    axs[0].set_ylabel(r'$\\Sigma$ Loss')\n",
    "    axs[0].set_xticks(np.arange(-1, 16))\n",
    "    axs[0].set_xticklabels(dict_to_xticklabels(losses[animal], labels=['μt', 'σt', 'μR', 'σR']))\n",
    "    # axs[0].set_ylim([80000, 140000])\n",
    "    axs[0].set_xlim([-1.5, 16.5])\n",
    "\n",
    "    axs[1].scatter(np.arange(16), list(losses[animal].values())/losses[animal][False, False, False, False], color=rat_markers[animal][0], label=animal)\n",
    "    axs[1].set_title(f\"nomalized loss\")\n",
    "    axs[1].set_ylabel(r'$\\Sigma$ Loss, Normalized')\n",
    "    axs[1].set_xticks(np.arange(-1, 16))\n",
    "    axs[1].set_xticklabels(dict_to_xticklabels(losses[animal], labels=['μt', 'σt', 'μR', 'σR']))\n",
    "    # axs[1].set_ylim([.975, 1.5])\n",
    "    axs[1].set_xlim([-1.5, 16.5])\n",
    "    axs[1].axhline(1, color='k', linestyle='--')\n",
    "\n",
    "    for i, key in enumerate(the_keys_i_want):\n",
    "        axs[2].scatter(i+1, losses[animal][key]/losses[animal][False, False, False, False], color=rat_markers[animal][0], label=animal)\n",
    "    axs[2].set_title(f\"normalized loss (1)\")\n",
    "    axs[2].set_ylabel(r'$\\Sigma$ Loss')\n",
    "    axs[2].set_xticks(np.arange(7))\n",
    "    axs[2].set_xticklabels(dict_to_xticklabels({k:losses[animal][k] for k in the_keys_i_want}, labels=['μt', 'σt', 'μR', 'σR']))\n",
    "    # axs[2].set_ylim([.975, 1.5])\n",
    "    axs[2].set_xlim([-.5, 6.5])\n",
    "    axs[2].axhline(1, color='k', linestyle='--')\n",
    "\n",
    "# average by key\n",
    "means = [np.mean([losses[animal][key] for animal in animalList]) for key in losses[animal].keys()]\n",
    "yerr = [np.std([losses[animal][key] for animal in animalList]) for key in losses[animal].keys()]\n",
    "axs[0].errorbar(np.arange(16)+.25, means, yerr=yerr, color='k', label='Mean', marker='o', fmt=' ')\n",
    "\n",
    "means_norm = [np.mean([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in losses[animal].keys()]\n",
    "yerr_norm = [np.std([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in losses[animal].keys()]\n",
    "axs[1].errorbar(np.arange(16)+.25, means_norm, yerr=yerr_norm, color='k', label='Mean', marker='o', fmt=' ')\n",
    "\n",
    "means_norm_select = [np.mean([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in the_keys_i_want]\n",
    "yerr_norm_select = [np.std([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in the_keys_i_want]\n",
    "axs[2].errorbar(np.arange(len(the_keys_i_want))+1.25, means_norm_select, yerr=yerr_norm_select, color='k', label='Mean', marker='o', fmt=' ')\n",
    "\n",
    "_losses1 = [losses[animal][False, False, False, False]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "_losses2 = [losses[animal][True, False, False, False]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "_losses3 = [losses[animal][False, True, False, False]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "_losses4 = [losses[animal][False, False, True, False]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "_losses5 = [losses[animal][False, False, False, True]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "_losses6 = [losses[animal][True, True, True, True]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "\n",
    "print(\"Effect of parameters on loss (Friedman)\")\n",
    "f_test = stats.friedmanchisquare(_losses1, _losses2, _losses3, _losses4, _losses5, _losses6)\n",
    "print(f'Friedman test: F={f_test[0]:.3f}, p={f_test[1]:.3f}')\n",
    "print(\" \")\n",
    "print(\"comparisons: (wilcoxon)\")\n",
    "test_all_keys_between_themselves(losses, the_keys_i_want, axs[2])\n",
    "\n",
    "# pickle.dump(losses, open(\"picklejar/running_time_model_BIC_ablation.p\", \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "### Example animal fit - 120cm\n",
    "Fit of the model for the same example animal on all Dist-120cm sessions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'RatM01'\n",
    "exampledata = prepare_data_running_times(sequence, animalList, dist120)\n",
    "plot_full_distribution_run(exampledata, animal, plot_fit=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All experimental conditions fit\n",
    "We can now do the same as above for all experimental conditions (Distances and TM speed) and for each rat.  \n",
    "Each color is a different rat.  \n",
    "\n",
    "$\\mathrm{M}$:  \n",
    "- $\\mu_0$ > 0, positive bound at start, increases with distance and when TM speed reverse  \n",
    "- $\\mu_t$ > 0, $\\mu$ increases with time  \n",
    "- $\\mu_R$ = 0, no effect of reward history on $\\mu$  \n",
    "\n",
    "The average running time increases when distance increases, and when TM is reversed -> animals do not manage to keep up the pace. \n",
    "The average running time increases with time, but not with reward history.  \n",
    "**$\\mu$ is congruent with *tiredness*, low at the start of session, increases with time/total distance traveled**\n",
    "\n",
    "\n",
    "$\\sigma$:  \n",
    "- $\\sigma_0$ > 0, initial variability  \n",
    "- $\\sigma t$ ~ 0, small effect of time on $\\sigma$  \n",
    "- $\\sigma R$ ~ 0, small effect of reward history on $\\sigma$  \n",
    "\n",
    "**Variability increases slightly with time and when reward is low**  \n",
    " \n",
    "\n",
    "**Stats**\n",
    "Not normal, so use wilcoxon to see if mean in each condition is != 0.  \n",
    "Wilcoxon to see if difference between two conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, figsize=(12, 20), gridspec_kw={'width_ratios': [5, 5, 2]})\n",
    "ylabels = [r'$\\mu_0$', r\"$\\mu_t$\", r\"$\\mu_R$\", r'$\\sigma_0$', r\"$\\sigma_t$\", r\"$\\sigma_R$\"]\n",
    "ylims = [[-.2, 2.5], [-.05, .2], [-.15, .15], [-.05, .2], [-.05, .05], [-.025, .1], ]\n",
    "mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed = False, False, False, False\n",
    "# mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed = False, True, True, False\n",
    "# mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed = False, False, True, False\n",
    "# mu_t_fixed, sigma_t_fixed, mu_R_fixed, sigma_R_fixed = True, True, True, True\n",
    "\n",
    "mu, mu_t, mu_R, sigma, sigma_t, sigma_R, loss = {}, {}, {}, {}, {}, {}, {}\n",
    "if os.path.exists(\"picklejar/running_time_model_parameters_fit.p\"):\n",
    "    mu, mu_t, mu_R, sigma, sigma_t, sigma_R, loss = pickle.load(open(\"picklejar/running_time_model_parameters_fit.p\", \"rb\"))\n",
    "else:\n",
    "    for animal in animalList:\n",
    "        mu[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        sigma[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        mu_t[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        sigma_t[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        mu_R[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        sigma_R[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        loss[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "\n",
    "        for cond, data in zip([\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"], [data60, data90, data120, data20, data10, data2, datarev10, datarev20]):\n",
    "            (mu[animal][cond], sigma[animal][cond], \\\n",
    "            mu_t[animal][cond], sigma_t[animal][cond], \\\n",
    "            mu_R[animal][cond], sigma_R[animal][cond]), loss[animal][cond] = modelrun_fit(data[animal], mu_t_fixed=mu_t_fixed, \n",
    "                                                                                                                                        sigma_t_fixed=sigma_t_fixed, \n",
    "                                                                                                                                        mu_R_fixed=mu_R_fixed, \n",
    "                                                                                                                                        sigma_R_fixed=sigma_R_fixed, \n",
    "                                                                                                                                        )\n",
    "vars = [mu, mu_t, mu_R, sigma, sigma_t, sigma_R, ]\n",
    "for animal in animalList:\n",
    "    for i, (var, ylabel, ylim) in enumerate(zip(vars, ylabels, ylims)):\n",
    "        axs[i, 0].scatter(np.arange(3), [var[animal][\"60\"], var[animal][\"90\"], var[animal][\"120\"]], color=rat_markers[animal][0], label=animal, marker=rat_markers[animal][1])\n",
    "        axs[i, 0].set_title(f\"\")\n",
    "        axs[i, 0].set_xticks(np.arange(3))\n",
    "        axs[i, 0].set_xticklabels([\"60\", \"90\", \"120\"])\n",
    "        axs[i, 0].set_ylabel(ylabel)\n",
    "        axs[i, 0].set_xlim(-.5, 2.5)\n",
    "        axs[i, 0].set_ylim(ylim)\n",
    "        axs[i, 0].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    for i, (var, ylabel, ylim) in enumerate(zip(vars, ylabels, ylims)):\n",
    "        axs[i, 1].scatter(np.arange(5), [var[animal][\"20\"], var[animal][\"10\"], var[animal][\"2\"], var[animal][\"rev10\"], var[animal][\"rev20\"]], color=rat_markers[animal][0], label=animal, marker=rat_markers[animal][1])\n",
    "        axs[i, 1].set_title(f\"\")\n",
    "        axs[i, 1].set_xticks(np.arange(5))\n",
    "        axs[i, 1].set_xticklabels([\"20\", \"10\", \"0\", \"-10\", \"-20\"])\n",
    "        axs[i, 1].set_ylabel(ylabel)\n",
    "        axs[i, 1].set_xlim(-.5, 4.5)\n",
    "        axs[i, 1].set_ylim(ylim)\n",
    "        axs[i, 1].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "    \n",
    "axs[i, 0].set_xlabel(\"Distance\")\n",
    "axs[i, 1].set_xlabel(r'$v_{belt}$')\n",
    "axs[i, 2].set_xlabel(\"All conditions pooled\")\n",
    "\n",
    "#mean per condition\n",
    "for idx, cond in enumerate([\"60\", \"90\", \"120\"]):\n",
    "    for jdx, var in enumerate([ mu, mu_t, mu_R, sigma, sigma_t, sigma_R,]):\n",
    "        d = [var[animal][cond] for animal in animalList]\n",
    "        mean, std = np.mean(d), np.std(d)/np.sqrt(len(d))\n",
    "        s, p = stats.wilcoxon(d)\n",
    "        if p < .05: axs[jdx, 0].scatter(idx+.3, mean, color='k', marker=r'$\\ast$')\n",
    "        axs[jdx, 0].errorbar(idx+.2, mean, yerr=std, color='black', marker='o', markersize=5, capsize=5, capthick=2, linewidth=2)\n",
    "\n",
    "for idx, cond in enumerate([\"20\", \"10\", \"2\", \"rev10\", \"rev20\"]):\n",
    "    for jdx, var in enumerate([ mu, mu_t, mu_R, sigma, sigma_t, sigma_R,]):\n",
    "        d = [var[animal][cond] for animal in animalList]\n",
    "        mean, std = np.mean(d), np.std(d)/np.sqrt(len(d))\n",
    "        s, p = stats.wilcoxon(d)\n",
    "        if p < .05: axs[jdx, 1].scatter(idx+.3, mean, color='k', marker=r'$\\ast$')\n",
    "        axs[jdx, 1].errorbar(idx+.2, mean, yerr=std, color='black', marker='o', markersize=5, capsize=5, capthick=2, linewidth=2)\n",
    "\n",
    "test_all_conds_between_themselves([\"60\", \"90\", \"120\"], vars, ax=axs[:, 0])\n",
    "test_all_conds_between_themselves([\"20\", \"10\", \"2\", \"rev10\", \"rev20\"], vars, ax=axs[:, 1])\n",
    "\n",
    "\n",
    "Zmu = {animal: {key: (mu[animal][key] - np.mean([mu[animal][key] for animal in animalList]))/np.std([mu[animal][key] for animal in animalList]) for key in mu[animal]} for animal in animalList}\n",
    "Zmu_t = {animal: {key: (mu_t[animal][key] - np.mean([mu_t[animal][key] for animal in animalList]))/np.std([mu_t[animal][key] for animal in animalList]) for key in mu_t[animal]} for animal in animalList}\n",
    "Zmu_R = {animal: {key: (mu_R[animal][key] - np.mean([mu_R[animal][key] for animal in animalList]))/np.std([mu_R[animal][key] for animal in animalList]) for key in mu_R[animal]} for animal in animalList}\n",
    "Zsigma = {animal: {key: (sigma[animal][key] - np.mean([sigma[animal][key] for animal in animalList]))/np.std([sigma[animal][key] for animal in animalList]) for key in sigma[animal]} for animal in animalList}\n",
    "Zsigma_t = {animal: {key: (sigma_t[animal][key] - np.mean([sigma_t[animal][key] for animal in animalList]))/np.std([sigma_t[animal][key] for animal in animalList]) for key in sigma_t[animal]} for animal in animalList}\n",
    "Zsigma_R = {animal: {key: (sigma_R[animal][key] - np.mean([sigma_R[animal][key] for animal in animalList]))/np.std([sigma_R[animal][key] for animal in animalList]) for key in sigma_R[animal]} for animal in animalList}\n",
    "\n",
    "traits = {animal: [] for animal in animalList}\n",
    "Zvars = [Zmu, Zmu_t, Zmu_R, Zsigma, Zsigma_t, Zsigma_R]\n",
    "for j, zvar in enumerate(Zvars):\n",
    "    for animal in animalList:\n",
    "        zscores = [zvar[animal][cond] for cond in [\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"]]\n",
    "        pdf = stats.norm.pdf(np.linspace(-3, 3, 600), np.mean(zscores), np.std(zscores))\n",
    "        traits[animal].append(np.mean(zscores))\n",
    "        axs[j, 2].plot(pdf, np.linspace(-3, 3, 600), color=rat_markers[animal][0], linestyle=rat_markers[animal][2])\n",
    "        Ri = compute_Ri(zvar, animalList)\n",
    "        axs[j, 2].annotate(f'Ri = {Ri:.2f}: {interpret_Ri(Ri)}', xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "        axs[j, 2].set_ylim(-3, 3)\n",
    "        axs[j, 2].set_ylabel(\"Z-scored \" + ylabels[j])\n",
    "        axs[j, 2].set_xlabel(\"\")\n",
    "        axs[j, 2].set_xticks([])\n",
    "\n",
    "# pickle.dump([mu, mu_t, mu_R, sigma, sigma_t, sigma_R, loss], open(\"picklejar/running_time_model_parameters_fit.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 2, figsize=(10, 20), gridspec_kw={'width_ratios': [3, 1]})\n",
    "for j, zvar in enumerate(Zvars):\n",
    "    for animal in animalList:\n",
    "        zscores = [zvar[animal][cond] for cond in [\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"]]\n",
    "\n",
    "        axs[j, 0].plot(np.arange(8), zscores, color=rat_markers[animal][0], linestyle=rat_markers[animal][2])\n",
    "\n",
    "\n",
    "        # axs[j, 1].hist(zscores, bins=np.linspace(-3, 3, 61), color=rat_markers[animal][0], alpha=0.25)\n",
    "        Ri = compute_Ri(zvar, animalList)\n",
    "        pdf = stats.norm.pdf(np.linspace(-3, 3, 600), np.mean(zscores), np.std(zscores))\n",
    "        axs[j, 1].plot(pdf, np.linspace(-3, 3, 600), color=rat_markers[animal][0], linestyle=rat_markers[animal][2])\n",
    "        axs[j, 1].annotate(f'Ri = {Ri:.2f}: {interpret_Ri(Ri)}', xy=(0.05, 0.9), xycoords='axes fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'RatF00': 212.02, 'RatF01': 205.85, 'RatF02': 193.75,\n",
    "            'RatM00': 259.37, 'RatM01': 278.12, 'RatM02': 253.19,\n",
    "            'RatF20': 220.10, 'RatF21': 215.53, 'RatF22': 215.0,\n",
    "            'RatM20': 254.68, 'RatM21': 307.29, 'RatM22': 330.53,\n",
    "            'RatF30': 217.32, 'RatF31': 228.95, 'RatF32': 216.80, 'RatF33': 222.77,\n",
    "            'RatM30': 261.38, 'RatM31': 300.55, 'RatM32': 279.23, \n",
    "            'RatF30L': 217.32, 'RatF31L': 228.95, 'RatF32L': 216.80, 'RatF33L': 222.77,\n",
    "            'RatM30L': 261.38, 'RatM31L': 300.55, 'RatM32L': 279.23}\n",
    "\n",
    "fig, ax = plt.subplots(1, 6, figsize=(15, 3))\n",
    "for j, zvar in enumerate(Zvars):\n",
    "    _x, _y = [], []\n",
    "    for animal in animalList:\n",
    "        zscores = [zvar[animal][cond] for cond in [\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"]]\n",
    "        y = np.mean(zscores)\n",
    "        x = weights[animal]\n",
    "\n",
    "        ax[j].scatter(x, y, color=rat_markers[animal][0], marker=rat_markers[animal][1], s=100)\n",
    "        ax[j].set_xlabel(\"Weight (g)\")\n",
    "        ax[j].set_ylabel(ylabels[j])\n",
    "        ax[j].set_ylim(-2, 2)\n",
    "\n",
    "        _x.append(x)\n",
    "        _y.append(y)\n",
    "\n",
    "    print(stats.pearsonr(_x, _y))\n",
    "    gradient, intercept, r_value, p_value, std_err = stats.linregress(_x, _y)\n",
    "    ax[j].plot(np.linspace(np.min(_x), np.max(_x), 100), gradient * np.linspace(np.min(_x), np.max(_x), 100) + intercept, color='black', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "for idx, animal in enumerate(animalList):\n",
    "        make_spider(axs, traits[animal], title='', \n",
    "        color=rat_markers[animal][0], marker=rat_markers[animal][1], linestyle=rat_markers[animal][2],\n",
    "        labels=[r'$\\mu_0$', r\"$\\mu_t$\", r\"$\\mu_R$\", r'$\\sigma_0$', r\"$\\sigma_t$\", r\"$\\sigma_R$\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "\n",
    "def f(a=1, b=1, m=1, d=1):\n",
    "    T = np.linspace(0, 2.5, 100)\n",
    "    timecost = a*m*T\n",
    "    plt.plot(T, timecost, color='g')\n",
    "\n",
    "    speedcost = (b*m*d*d)/T\n",
    "    plt.plot(T, speedcost, color='r')\n",
    "\n",
    "    E_w = timecost + speedcost\n",
    "    plt.plot(T, E_w, color='b')\n",
    "\n",
    "    plt.ylim(0, 10)\n",
    "    plt.show()\n",
    "\n",
    "interact(f, a=(0, 10, 0.1), b=(0, 10, 0.1), m=(0, 10, 0.1), d=(0, 10, 0.1));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "a05f93782d31fb45d30263a0389582a01d7e14abf3ec6aacde92652303ee35ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
