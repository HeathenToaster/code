{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T13:43:35.962963Z",
     "start_time": "2020-07-23T13:43:33.614263Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import fnmatch\n",
    "import matplotlib.cbook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import platform\n",
    "from pylab import rcParams\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "startTimeNotebook = datetime.datetime.now()\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !git clone https://github.com/HeathenToaster/code\n",
    "    %cd code\n",
    "\n",
    "# session lists in a .py file\n",
    "# import sessionlists\n",
    "%run sessionlists\n",
    "from VIGOR_utils import *\n",
    "from VIGOR_MODELS_Functions import *\n",
    "\n",
    "plt.style.use('./Figures/test.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T13:43:36.014402Z",
     "start_time": "2020-07-23T13:43:35.968581Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Define folder with data \n",
    "if platform.system()=='Linux':\n",
    "    root=\"/home/david/Desktop/ALLDATA\"\n",
    "    savePath=\"/home/david/Desktop/Save\"\n",
    "elif platform.system()=='Darwin':\n",
    "    root=\"/Users/tom/Desktop/sequencesALLDATA\"\n",
    "    savePath=\"/Users/tom/Desktop/Save\"\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !gdown --id 1BSepSzm1-KQJlUvv8C23p_qyHvtzvrZ8\n",
    "    !unzip -qq /content/code/sequencesALLDATA.zip\n",
    "    root=\"/content/code/sequencesALLDATA\"\n",
    "    savePath=\"/content/Save\"\n",
    "    print(\"I'm running on Colab\")\n",
    "print(\"Path to data is: %s\"%root)\n",
    "\n",
    "retval = os.getcwd()\n",
    "print(\"Current working directory: %s\" % retval)\n",
    "print(\"Save Path: \", savePath)\n",
    "\n",
    "print(f'Found {len(glob.glob(root+\"/*\"))} rats in the data folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_markers = {}\n",
    "sequence = {}\n",
    "\n",
    "# define colors for each rat\n",
    "palette = {'RatF00': (0.4, 0.0, 0.0), 'RatF01': (0.55, 0.13, 0.13), 'RatF02': (0.8, 0.2, 0.2),\n",
    "           'RatM00': (0.0, 0.4, 0.0), 'RatM01': (0.13, 0.55, 0.13), 'RatM02': (0.2, 0.8, 0.2),\n",
    "           'RatF20': (0.4, 0.0, 0.0), 'RatF21': (0.55, 0.13, 0.13), 'RatF22': (0.8, 0.2, 0.2),\n",
    "           'RatM20': (0.0, 0.4, 0.0), 'RatM21': (0.13, 0.55, 0.13), 'RatM22': (0.2, 0.8, 0.2),\n",
    "           'RatF30': (0.4, 0.0, 0.0), 'RatF31': (0.55, 0.13, 0.13), 'RatF32': (0.8, 0.2, 0.2), 'RatF33': (0.8, 0.2, 0.2),\n",
    "           'RatM30': (0.0, 0.4, 0.0), 'RatM31': (0.13, 0.55, 0.13), 'RatM32': (0.2, 0.8, 0.2), \n",
    "           'RatF30L': (0.4, 0.0, 0.0), 'RatF31L': (0.55, 0.13, 0.13), 'RatF32L': (0.8, 0.2, 0.2), 'RatF33L': (0.8, 0.2, 0.2),\n",
    "           'RatM30L': (0.0, 0.4, 0.0), 'RatM31L': (0.13, 0.55, 0.13), 'RatM32L': (0.2, 0.8, 0.2)}\n",
    "\n",
    "# define brain status (lesion/CNO/intact) for each rat, used in plots\n",
    "# needs to be properly implemented, setting is in behav_params for each session.\n",
    "brainstatus = {'RatF00': 'normal', 'RatF01': 'normal', 'RatF02': 'normal',\n",
    "               'RatM00': 'normal', 'RatM01': 'normal', 'RatM02': 'normal',\n",
    "               'RatF20': 'thcre', 'RatF21': 'thcre', 'RatF22': 'thcre',\n",
    "               'RatM20': 'thcre', 'RatM21': 'thcre', 'RatM22': 'thcre',\n",
    "               'RatF30': 'lesion', 'RatF31': 'lesion', 'RatF32': 'normal', 'RatF33': 'normal',\n",
    "               'RatM30': 'lesion', 'RatM31': 'normal', 'RatM32': 'normal',\n",
    "                'RatF30L': 'lesion', 'RatF31L': 'lesion', 'RatF32L': 'biglesion', 'RatF33L': 'biglesion',\n",
    "                'RatM30L': 'lesion', 'RatM31L': 'biglesion', 'RatM32L': 'biglesion'\n",
    "               }\n",
    "\n",
    "markers = {'normal': 'o', 'thcre': 'd', 'lesion': 'x', 'biglesion': 'X'}\n",
    "lines = {'normal': '-', 'thcre': '--', 'lesion': ':', 'biglesion': '-.'}\n",
    "# define list of rats to be analyzed\n",
    "# first batch  \n",
    "# animalList = ['RatF00', 'RatF01', 'RatF02', 'RatM00', 'RatM01', 'RatM02']\n",
    "\n",
    "# all rats\n",
    "# animalList = [os.path.basename(path) for path in sorted(glob.glob(root+\"/Rat*\"))]\n",
    "# animalList += ['RatF30L', 'RatF31L', 'RatF32L', 'RatF33L', 'RatM30L', 'RatM31L', 'RatM32L']\n",
    "\n",
    "# INTACT RATS\n",
    "animalList = ['RatF00', 'RatF01', 'RatF02', 'RatM00', 'RatM01', 'RatM02', 'RatF32', 'RatF33', 'RatM31', 'RatM32']\n",
    "# THcre RATS\n",
    "# animalList += ['RatF20', 'RatF21', 'RatF22', 'RatM20', 'RatM21', 'RatM22']\n",
    "\n",
    "for index, animal in enumerate(animalList):\n",
    "    print(f'Loading data for {animal}')\n",
    "    # define marker and color for each rat, used in plots\n",
    "    if fnmatch.fnmatch(animal, 'RatF*'):\n",
    "        rat_markers[animal]=[palette[animal], markers[brainstatus[animal]], lines[brainstatus[animal]]]\n",
    "    elif fnmatch.fnmatch(animal, 'RatM*'):\n",
    "        rat_markers[animal]=[palette[animal], markers[brainstatus[animal]], lines[brainstatus[animal]]]\n",
    "    elif fnmatch.fnmatch(animal, 'Rat00*'):\n",
    "        rat_markers[animal]=[(0.0, 0.0, 0.0), \"$\\u2426$\",]\n",
    "    else:\n",
    "        print(\"error, this is not a rat you got here\")\n",
    "\n",
    "    # loop over all sessions for each rat and get the pickled preprocessed data. Data is processed in VIGOR_Preprocess.py\n",
    "    # data (list or list of lists) for each variable is stored in a dictionary with keys (animal, session)\n",
    "    for session in sorted(matchsession(animal, dist60+dist90+dist120 + TM20+TM10+TM2+TMrev2+TMrev10+TMrev20)):\n",
    "                                                #  dist60bis+dist90bis+dist120bis)):\n",
    "\n",
    "        # get the preprocessed data from the pickle file\n",
    "        # In this notebook we only need the sequence of events, so we only load that\n",
    "        biglesion = True if 'L' in session else False\n",
    "        sequence[animal, session] = get_from_pickle(root, animal[0:6], session, name=\"sequence.p\", biglesion=biglesion)\n",
    "\n",
    "\n",
    "# separate the data into time and reward bins for each experimental condition\n",
    "# distances \n",
    "data60 = prepare_data_idle_times(sequence, animalList, dist60)\n",
    "data90 = prepare_data_idle_times(sequence, animalList, dist90)\n",
    "data120 = prepare_data_idle_times(sequence, animalList, dist120)\n",
    "\n",
    "# treadmill speeds\n",
    "data20 = prepare_data_idle_times(sequence, animalList, TM20)\n",
    "data10 = prepare_data_idle_times(sequence, animalList, TM10)\n",
    "data2 = prepare_data_idle_times(sequence, animalList, TM2+TMrev2)\n",
    "datarev10 = prepare_data_idle_times(sequence, animalList, TMrev10)\n",
    "datarev20 = prepare_data_idle_times(sequence, animalList, TMrev20)\n",
    "\n",
    "# all conditions pooled\n",
    "dataAll = prepare_data_idle_times(sequence, animalList, dist60+dist90+dist120 + TM20+TM10+TM2+TMrev2+TMrev10+TMrev20)\n",
    "\n",
    "# distances bis\n",
    "# data60bis = prepare_data_idle_times(sequence, animalList, dist60bis)\n",
    "# data90bis = prepare_data_idle_times(sequence, animalList, dist90bis)\n",
    "# data120bis = prepare_data_idle_times(sequence, animalList, dist120bis)\n",
    "\n",
    "\n",
    "# for each session separate the data into time and reward bins for each experimental condition\n",
    "data60_bysession = prepare_data_by_session(sequence, animalList, dist60)\n",
    "data90_bysession = prepare_data_by_session(sequence, animalList, dist90)\n",
    "data120_bysession = prepare_data_by_session(sequence, animalList, dist120)\n",
    "data20_bysession = prepare_data_by_session(sequence, animalList, TM20)\n",
    "data10_bysession = prepare_data_by_session(sequence, animalList, TM10)\n",
    "data2_bysession = prepare_data_by_session(sequence, animalList, TM2+TMrev2)\n",
    "datarev10_bysession = prepare_data_by_session(sequence, animalList, TMrev10)\n",
    "datarev20_bysession = prepare_data_by_session(sequence, animalList, TMrev20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task  \n",
    "The task and the main behavioral results are presented in notebook 1.  \n",
    "We developed an automated foraging task in which water restricted rats have to run back and\n",
    "forth on a treadmill to obtain drops of water. Within one hour-long session, the\n",
    "probability of getting a reward was alternatively high and low in 5 min-long uncued\n",
    "blocks (dark and light gray in fig.1).  \n",
    "\n",
    "<img src=\"Figures/Picturetask1.png\" alt=\"task\" width=\"300\"/>  \n",
    "\n",
    "## Experimental conditions\n",
    "Across sessions, we manipulated the effort rats had to produce by either\n",
    "modifying the length of the treadmill while its speed remained null, or by\n",
    "manipulating the speed and direction of the belt to facilitate or counteract the\n",
    "animals' crossings.\n",
    "\n",
    "<img src=\"Figures/conditions.png\" alt=\"conditions\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim of the Notebook \n",
    "One of the variables that we analyze is the duration of the idle times between \n",
    "two subsequent run epochs (orange part on the track of the animal, Fig 1A.).  \n",
    "A quick analysis of the median idle time shows that it increases along the \n",
    "session and tends to be higher in low probability blocks, especially at \n",
    "the end of the session (Fig1B.); i.e. animals are less motivated/more tired \n",
    "as time passes, and modulate their idle time according to the reward probability.  \n",
    "\n",
    "However, a simple analysis of the median fails to grasp the complexity of the data. \n",
    "For instance, we consider very long idle times as a feature and not as aberrant values (compared to most papers in the litterature (#REFS)).   \n",
    "\n",
    "In this notebook we characterise how time and reward probability affects idle time.  \n",
    "\n",
    "Fig 1.  \n",
    "A) Position of an example animal across a 120 cm session. Blue is run epoch, orange is idle epoch.  \n",
    "Reward probability in 5 min blocks is either high (90%, dark gray), or low (10%, light gray)  \n",
    "B) Median idle time across session and blocks.  \n",
    "Reward probability in 5 min blocks is either high (90%, dark gray), or low (10%, light gray)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 1.\n",
    "animal, session = 'RatM01', 'RatM01_2021_07_22_17_14_48'  # 'RatF00', 'RatF00_2021_07_24_15_28_05'\n",
    "fig, axs = plt.subplots(1, 2, figsize = (24, 4), gridspec_kw={'width_ratios': [5, 1]})\n",
    "\n",
    "# Load preprocessed data for one animal and one session. params contains the parameters of the session,\n",
    "# idleTimeInLeftBin and idleTimeInRightBin contain the idle time in each time bin for each animal\n",
    "example_params = get_from_pickle(root, animal, session, name=\"params.p\")\n",
    "example_idleTimeInLeftBin, example_idleTimeInRightBin = get_from_pickle(root, animal, session, name=\"timeinZone.p\")\n",
    "\n",
    "# plot the trajectory\n",
    "plot_animal_trajectory(root=root, animal=animal, session=session, params=example_params, barplotaxes=[0, 3600, 0, 120], \n",
    "                 xyLabels=[\"Time (min)\", \"Position along treadmill (cm)\"], title=\"Position of example animal across a 120 cm session\", ax=axs[0])\n",
    "\n",
    "# plot the median idle time in each time block\n",
    "plot_median_per_bin([example_idleTimeInLeftBin[i]+example_idleTimeInRightBin[i] for i in range(0, 12)], \n",
    "                example_params['rewardProbaBlock'], example_params['blocks'], barplotaxes=[0, 3600/60, 0, 10], \n",
    "                color=['orange'], xyLabels=[\"Time (min)\",\"idle time (s)\"], title=\"Median idle time\", scatter=False, stat='Med. ', ax=axs[1]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data binning\n",
    "\n",
    "To see the effect of **reward probability** $R$ we chose to use the history of rewards obtained by the rat over the previous trials.  \n",
    "We chose reward history to see how rats detect transitions from/to high and low reward probability blocks. In high (low) probability blocks, the average number of rewards obtained in the previous trials is high (low); the average number of rewards decreases (increases) when transitioning into low (high) reward probability blocks. (WE DON'T TALK ABOUT THIS ANALYSIS ANYMORE).  \n",
    "\n",
    "The reward history is defined as the average number of rewards obtained over the 3 previous runs. With a memory span of 3, there is 4 possible reward histories: with $\\frac{3}{3}$ rewards obtained we have a reward history of $1$; the other possible combinations are $\\frac{2}{3}=0.67$, $\\frac{1}{3}=0.33$ and $\\frac{0}{3}=0$. In the rest of the notebook the list of reward histories follows this order: [1, 0.67, 0.33, 0].  \n",
    "In Fig 2.A we select all the idle times that occured after $\\frac{2}{3}=0,67$ rewards obtained in a session (black + gray circled sequences).  \n",
    "\n",
    "To see the effect of **time** $t$, we chose to split the dataset in 6 * 10 min bins. This allows a good resolution for the temporal evolution and ensures that all reward history combinations are represented in each bin. In the idle times after $\\frac{2}{3}=0,67$ rewards obtained, we can select the ones occuring in the first 10 minutes (black circled sequences, Fig 2A.).  \n",
    "\n",
    "The distribution of the idle times occuring after $\\frac{2}{3}=0,67$ and in the first 10 minutes is shown in figure 2B.  \n",
    "We represent the inverse cumulative distribution of the same data in a log-log plot as some idle times are **very long** (>50s, Fig 2C.). \n",
    "\n",
    "\n",
    "A) reward sequence in a session, each line a 5 min block, each dot a rewarded (green) or not rewarded (red) run. \n",
    "Rectangles: sequences matching the target sequence (here $\\frac{2}{3}$ rewards obtained).  \n",
    "Colors: black 0-10 mins | gray the rest   \n",
    "B) distribution (PDF) of the idle times occuring after $\\frac{2}{3}=0,67$ and in the first 10 minutes\n",
    "C) same as B, but in 1-CDF. Because we have very long waits, we use a log scale.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 2.\n",
    "# plot reward sequence in example session\n",
    "fig, ax = plt.subplots(1, figsize=(35, 4))\n",
    "avg = 0.67  # i.e. yes, yes, no\n",
    "waits_one_session = plot_rewards(sequence[animal, session], avg=avg, ax=ax, filter=[0, 600])\n",
    "\n",
    "# plot distribution of idle time following 0.67 R in the first 10 min in example session\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "plot_rewards_distribution(waits_one_session, avg=avg, color=rat_markers[animal][0], ax=ax, label=f'{animal} one session 120 cm');\n",
    "print(f'Number of trials in one session: {len(waits_one_session)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads to small subsets (i.e. n=29 in this case. Accentuated at the end of the sessions), so we pool data for each experimental condition (i.e. all sessions for a rat at 60cm distance, all sessions for a rat at 120cm distance, etc.).  \n",
    "\n",
    "A&B) same as above for the same rat but we pooled all 120 cm sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of idle time following 0.67 R in the first 10 min in all 120 cm sessions\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "exampledata = prepare_data_idle_times(sequence, animalList, dist120)[animal][0][1]  # time_bin 0 -> 0-10 min ||| rwd_bin 1 -> 0.67\n",
    "plot_rewards_distribution(exampledata, avg=avg, color='k', ax=ax, label=f'{animal} all sessions 120 cm');\n",
    "print(f'Number of trials in all 120 cm sessions: {len(exampledata)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete distribution\n",
    "We have the distribution of the idle times occuring after $\\frac{2}{3}=0,67$ and in the first $10$ minutes for a rat. \n",
    "For the same rat, we can also get the distributions for the other reward histories ($1, 0.33, 0$) and the other time bins (from $10$ min to $60$ min).  \n",
    "These distributions are shown in Fig 3. The one colored in black is the distribution of the idle times occuring after $\\frac{2}{3}=0,67$ and in the first $10$ minutes seen previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 3.\n",
    "# distribution of waiting times\n",
    "def plot_full_distribution(data, animal, plot_fit=False, N_bins=6, N_avg=4):\n",
    "    '''plot the full distribution of the data'''\n",
    "    ###\n",
    "    # NOT SAME NUMBER OF OBSERVATIONS IN EACH CURVE, BUT SAME NORMALIZATION ???\n",
    "    ###\n",
    "\n",
    "    def _plot_wald_fitted(waits, p, ax=None, color='k', plot_fit=True, label='', lw=2):\n",
    "        \"\"\"plot fitted wald distribution without fitting\"\"\"\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "        waits = np.asarray(waits)\n",
    "\n",
    "        bins = np.linspace(0, waits.max(), int(max(waits))*25)\n",
    "        ydata, xdata, _ = ax.hist(waits, bins=bins,\n",
    "                                  color=color, alpha=1, zorder=1,\n",
    "                                  density=True,  # weights=np.ones_like(waits) / len(waits),\n",
    "                                  histtype=\"step\", lw=lw, cumulative=-1, label=label)\n",
    "\n",
    "        if plot_fit:\n",
    "            x = np.linspace(0.001, 500, 10000)\n",
    "            ax.plot(x, 1-Wald_cdf(x, *p), color=color, lw=2, zorder=4, ls='--', label=f'{label} fit')\n",
    "        return ax\n",
    "\n",
    "    fig, axs = plt.subplots(1, N_bins, figsize=(3*N_bins, 3))\n",
    "    (alpha, theta, gamma, alpha_t, thetaprime, gamma_t, alpha_R, thetasecond, gamma_R), loss = modelwald_fit(data[animal])\n",
    "\n",
    "    lbls = ['1', '0.67', '0.33', '0']\n",
    "    for j in range(N_bins):\n",
    "        for i in range(N_avg):\n",
    "            color = plt.get_cmap('inferno')(i / N_avg)\n",
    "            lw = 3.5 if j == 0 and i == 1 else 2\n",
    "            _plot_wald_fitted(data[animal][j][i],\n",
    "                              (alpha + j*alpha_t + i*alpha_R, theta, gamma + j*gamma_t + i*gamma_R), \n",
    "                              ax=axs[j], color=color, plot_fit=plot_fit, label=lbls[i], lw=lw)\n",
    "        axs[j].set_xlim(.1, 1000)\n",
    "        axs[j].set_ylim(.001, 1.1)\n",
    "        axs[j].set_xscale(\"log\")\n",
    "        axs[j].set_yscale(\"log\")\n",
    "        axs[j].set_xlabel('log(idle time) (s)')\n",
    "        axs[j].set_ylabel('log(1-CDF)')\n",
    "        axs[j].set_title(f'{j*10}-{(j+1)*10} min')\n",
    "        axs[j].legend()\n",
    "\n",
    "animal = 'RatM01'\n",
    "exampledata = prepare_data_idle_times(sequence, animalList, dist120)\n",
    "plot_full_distribution(exampledata, animal, plot_fit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drift diffusion model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-bound DDM\n",
    "We have the intuition that before leaving, the rat accumulates motivation. The amount of motivation needed to start running and the speed at which it accumulates can be modelled with a simple one-bound drift diffusion model (e.g. Ratcliff, Van Dongen, 2011; Ratcliff, 2015).  \n",
    "\n",
    "The one-bound diffusion model describes a continuous time-stochastic accumulation process in which a quantity $X$ continuously accumulates until reaching a threshold.  \n",
    "\n",
    "Intuition that $X$ is *motivation* that is accumulated at a given rate $\\color{red}{v}$ (with gaussian noise $\\epsilon(0, \\eta=1)$) until it reaches a threshold $\\color{blue}{A}$ at time $t_f$, at which the animal starts to run again. $\\color{green}{t_0}$ (fixed to $0$) is the time lapsed outside (before and/or after) of the process.  \n",
    "\n",
    "Illustration of the one-bound drift diffusion model and resulting distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 4. plot DDM example with *fast* accumulation\n",
    "\n",
    "std = 1\n",
    "t0 = 2\n",
    "N = 100\n",
    "\n",
    "plot_DDMexample(.25, std, 10, t0, N=N, title=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 4. plot DDM example with *slow* accumulation\n",
    "plot_DDMexample(.05, std, 10, t0, N=N, title=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same plot but interactive\n",
    "pl = interact(plot_DDMexampleParams, v=(0, 2, 0.1), A=(0, 5, 0.1));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wald distribution\n",
    "\n",
    "The explicit solution for the <span style=\"color:magenta\">resulting distribution</span>  is the Wald distribution. (https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution)  \n",
    "The probability density function of the Wald distribution is:  \n",
    "\n",
    "$Wald(x|\\alpha, \\theta, \\gamma) = \\frac{\\alpha}{\\sqrt{2\\pi (x-\\theta)³}}\\cdot exp{\\left\\{-\\frac{[\\alpha-\\gamma (x-\\theta)]²}{2(x-\\theta)}\\right\\}}$  \n",
    "\n",
    "The wald distribution has 3 parameters: $\\alpha$, $\\theta$, $\\gamma$.  \n",
    "- $\\alpha$ is linked to the boundary $A$, \n",
    "- $\\theta$ is linked to the non-decision time $t_0$,  \n",
    "- and $\\gamma$ is linked to the drift rate $v$.  \n",
    "\n",
    "With the $\\theta$ parameter fixed to $0$ the distribution simplifies to:     \n",
    "$Wald(x|\\alpha, \\gamma) = \\frac{\\alpha}{\\sqrt{2\\pi x³}}\\cdot exp{\\left\\{-\\frac{[\\alpha-\\gamma x]²}{2x}\\right\\}}$  \n",
    "\n",
    "&nbsp;  \n",
    "A) Changes in the Wald distribution as a result of changes in the $\\alpha$, $\\theta$, $\\gamma$ parameters.  \n",
    "B) Interactive PDF  \n",
    "C) Interactive CDF  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pl = interact(plot_interactiveWald, alpha=(0, 5, 0.1), gamma=(-1, 5, 0.1), t_0=(0, 3, 0.1));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "We fit idle time distributions $x$ to the Wald distribution using the maximum likelihood estimation method.\n",
    "We find the parameters $\\hat{\\alpha}, \\hat{\\gamma}$ that maximizes the log-likelihood function $\\ell (Wald(x); \\alpha, \\gamma)$, with $\\alpha, \\gamma \\in \\mathrm{A}, \\Gamma$, using the default 'L-BFGS-B' method from scipy. https://en.wikipedia.org/wiki/Limited-memory_BFGS#L-BFGS-B  \n",
    " \n",
    "Fig 5.\n",
    "Sanity check: We generate synthetic idle times from a Wald distribution with known $\\alpha, \\gamma$ parameters, and fit them to check that the fitted parameters are the same as the known parameters. We are able to recover the parameters well (QUANTIFY).  \n",
    "\n",
    "TOP LEFT) Synthetic data fit with different values of $\\gamma$.  \n",
    "TOP RIGHT) Synthetic data fit with different values of $\\alpha$  \n",
    "BOT LEFT&RIGHT) Hidden (lines) and recovered (dots) parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = 0\n",
    "N = 1000\n",
    "std = 1\n",
    "AAA = 5\n",
    "MEAN = 1\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "means = np.linspace(0.1, 1, 10)\n",
    "plot_color_line(axs[1, 0], means, means, means, cmap = 'autumn', vmin=0, vmax=1, alpha=1, linewidth=2, linestyle = '-', zorder = 1)\n",
    "axs[1, 0].plot(means, [t0 for _ in means], color='g')\n",
    "axs[1, 0].plot(means, [AAA for _ in means], color='c')\n",
    "for mean in means:\n",
    "    alpha, theta, gamma, lossWald = example_wald_fit(mean, std, AAA, t0, N, ax=axs[0, 0], color=plt.get_cmap('autumn')(mean / max(means)))\n",
    "    axs[1, 0].scatter(mean, alpha, color='c', label='alpha_fit')\n",
    "    axs[1, 0].scatter(mean, theta, color='g', label='theta_fit')\n",
    "    axs[1, 0].scatter(mean, gamma, color=plt.get_cmap('autumn')(mean / max(means)), label='gamma_fit')\n",
    "    axs[1, 0].set_xlabel('gamma ground truth')\n",
    "    axs[1, 0].set_ylabel('fitted params')\n",
    "\n",
    "As = np.linspace(1, 5, 10)\n",
    "plot_color_line(axs[1, 1], As, As, As, cmap = 'winter', vmin=0, vmax=5, alpha=1, linewidth=2, linestyle = '-', zorder = 1)\n",
    "axs[1, 1].plot(As, [t0 for _ in As], color='g')\n",
    "axs[1, 1].plot(As, [MEAN for _ in As], color='r')\n",
    "for A in As:\n",
    "    alpha, theta, gamma, lossWald = example_wald_fit(MEAN, std, A, t0, N, ax=axs[0, 1], color=plt.get_cmap('winter')(A / max(As)))\n",
    "    axs[1, 1].scatter(A, alpha, color=plt.get_cmap('winter')(A / max(As)), label='alpha_fit')\n",
    "    axs[1, 1].scatter(A, theta, color='g', label='theta_fit')\n",
    "    axs[1, 1].scatter(A, gamma, color='r', label='gamma_fit')\n",
    "    axs[1, 1].set_xlabel(' alpha ground truth')\n",
    "    axs[1, 1].set_ylabel('fitted params')\n",
    "\n",
    "\n",
    "legend_without_duplicate_labels(axs[1, 0])\n",
    "legend_without_duplicate_labels(axs[1, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idle time model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have the Wald distribution with $\\alpha$ and $\\gamma$ parameters that we can fit and recover from individual idle times distributions. \n",
    "We've seen earlier that the sub-distributions of idle times in our data changes with time $t$ and the reward history $R$.  \n",
    "Can we link $t$ and $R$ to $\\alpha$ and/or $\\gamma$?  \n",
    "\n",
    "To evaluate how $\\alpha$ and $\\gamma$ change with $t$ and/or $R$ we define the following model:\n",
    "\n",
    "$\\mathrm{A}(t, R) = \\alpha_0 + \\alpha_t t + \\alpha_R R$  \n",
    "$\\Gamma(t, R) = \\gamma_0 + \\gamma_t t + \\gamma_R R$  \n",
    "\n",
    "With:  \n",
    "$\\alpha_0, \\gamma_0$ parameters at the beginning of the session (0-10 min) and $\\frac{3}{3}$ rewards have been obtained  \n",
    "$\\alpha_t, \\gamma_t$ how $\\alpha$ and $\\gamma$ evolve linearly with time  \n",
    "$\\alpha_R, \\gamma_R$ how $\\alpha$ and $\\gamma$ evolve linearly with reward history  \n",
    "\n",
    "\n",
    "We find the best $\\alpha_0, \\alpha_t, \\alpha_R, \\gamma_0, \\gamma_t, \\gamma_R$ that minimize the total error of the model using maximum likelihood estimation.  \n",
    "\n",
    "The total error of the model is defined as:  \n",
    "$\\sum_{n_t=0}^{6} \\sum_{n_R=0}^{1} \\frac{\\ell (Wald(x(t, R)); \\alpha_0 + \\alpha_t + \\alpha_R, \\gamma_0 + \\gamma_t + \\gamma_R)}{N(t, R)}$  \n",
    "\n",
    "with:  \n",
    "$x$, experimental data  \n",
    "$x(t, R)$, experimental data for a given $t$ and $R$  \n",
    "$N(t, R)$, number of observations in $x(t, R)$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical representation of $\\alpha$ and $\\gamma$ evolution\n",
    "Evolution of $\\mathrm{A}$ and $\\Gamma$ on the z axis, with $R$ on the x axis, $t$ on the y axis.  \n",
    "- $\\mathrm{A}$: starts low, increases with $t$, no big change with $R$  \n",
    "- $\\Gamma$: starts high, decreases with $t$ and $R$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT THE SAME ANIMAL AS BEFORE (RatM01)!!!!!!!!\n",
    "\n",
    "# example fit model on all 120 cm session for each animal\n",
    "# print fitted parameters and loss for each animal\n",
    "animal = 'RatF01'\n",
    "exampledata = prepare_data_idle_times(sequence, animalList, dist120)\n",
    "p, loss = modelwald_fit(exampledata[animal])\n",
    "(alpha, theta, gamma, alpha_t, thetaprime, gamma_t, alpha_R, thetasecond, gamma_R) = p\n",
    "\n",
    "print(f\"{animal}  α:{alpha:.2f}, αt:{alpha_t:.2f}, αR: {alpha_R:.2f}, || γ: {gamma:.2f}, γt: {gamma_t:.2f}, γR: {gamma_R:.2f} ||| loss: {loss:.2f}\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), subplot_kw={'projection': '3d'})\n",
    "plot_parameter_evolutionIdleTime((alpha, gamma, alpha_t, gamma_t, alpha_R, gamma_R), axs=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter ablation\n",
    "To evaluate the contribution of the different model parameters $\\alpha_t, \\alpha_R, \\gamma_t, \\gamma_R$ we performed (single and multiple) parameter ablation (parameter fixed to 0) of the model.  \n",
    "For instance ablating $\\alpha_t$ constrains $\\mathrm{A}$ to not evolve with time.  \n",
    "Ablated models were compared using the Bayesian Information Criterion (BIC) to penalize the number of free parameters fit.\n",
    "\n",
    "\n",
    "The likelihood of the model is the same as above:  \n",
    "$Loss = \\sum_{n_t=0}^{6} \\sum_{n_R=0}^{1} \\frac{\\ell (Wald(x(t, R)); \\alpha_0 + \\alpha_t + \\alpha_R, \\gamma_0 + \\gamma_t + \\gamma_R)}{N(t, R)}$  \n",
    "\n",
    "The BIC of the model is defined as:  \n",
    "$BIC = k * log(N) - 2 * Loss$  \n",
    "With:  \n",
    "$k$: number of parameters, $\\alpha$, $\\gamma$ (2) + number of free parameters  \n",
    "$N$: total number of observations  \n",
    "$Loss$: same as defined above  \n",
    "\n",
    "Results:  \n",
    "\n",
    "The loss of the model with all the parameters free (++++) is smaller than the model with all parameters ablated (----). Multiple parameter ablation increases the loss.  \n",
    "\n",
    "All parameter ablation increases the loss. All parameters are important.  \n",
    "Paiwise comparisons show that ablation of some parameters produce stronger increase in loss (e.g. $\\gamma_R$ > $\\alpha_R$).  \n",
    "\n",
    "\n",
    "Friedman for main effect of ablation  \n",
    "If F < 0.05, pairwise comparison with Wilcoxon\n",
    "\n",
    "Maybe difference between M/F  \n",
    "Do that with synthetic data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetlist = generate_targetList(seq_len=4)[::-1]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 7))\n",
    "\n",
    "the_keys_i_want = [(False, False, False, False), \n",
    "                    (True, False, False, False), \n",
    "                    (False, True, False, False), \n",
    "                    (False, False, True, False), \n",
    "                    (False, False, False, True), \n",
    "                    (True, True, True, True)]\n",
    "\n",
    "if os.path.exists(\"picklejar/idle_time_model_BIC_ablation.p\"):\n",
    "    losses = pickle.load(open(\"picklejar/idle_time_model_BIC_ablation.p\", \"rb\"))\n",
    "else:\n",
    "    losses = {}\n",
    "    for animal in animalList:\n",
    "        losses[animal] = {}\n",
    "        for alpha_t_fixed in [False, True]:\n",
    "            for gamma_t_fixed in [False, True]:\n",
    "                for alpha_R_fixed in [False, True]:\n",
    "                    for gamma_R_fixed in [False, True]:\n",
    "                        number_of_params = 2  # alpha, gamma\n",
    "                        number_of_extra_params = alpha_t_fixed+gamma_t_fixed+alpha_R_fixed+gamma_R_fixed\n",
    "                        loss = modelwald_fit(dataAll[animal], \n",
    "                                            f=model_compare,\n",
    "                                            alpha_t_fixed=alpha_t_fixed, \n",
    "                                            gamma_t_fixed=gamma_t_fixed, \n",
    "                                            alpha_R_fixed=alpha_R_fixed, \n",
    "                                            gamma_R_fixed=gamma_R_fixed, \n",
    "                                            N_params=number_of_params + (4 - number_of_extra_params),\n",
    "                                            )[1]\n",
    "\n",
    "                        losses[animal][(alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed)] = loss\n",
    "\n",
    "for animal in animalList:\n",
    "    axs[0].scatter(np.arange(16), losses[animal].values(), color=rat_markers[animal][0], \n",
    "                   label=animal, marker=rat_markers[animal][1])\n",
    "    axs[0].set_title(f\"loss\")\n",
    "    axs[0].set_ylabel(r'$\\Sigma$ Loss')\n",
    "    axs[0].set_xticks(np.arange(-1, 16))\n",
    "    axs[0].set_xticklabels(dict_to_xticklabels(losses[animal], labels=['αt', 'γt', 'αR', 'γR']))\n",
    "    # axs[0].set_ylim([45, 70])\n",
    "    # axs[0].set_ylim([80000, 140000])\n",
    "    axs[0].set_xlim([-1.5, 16.5])\n",
    "\n",
    "    axs[1].scatter(np.arange(16), list(losses[animal].values())/losses[animal][False, False, False, False],\n",
    "                   color=rat_markers[animal][0], label=animal, marker=rat_markers[animal][1])\n",
    "    axs[1].set_title(f\"nomalized loss\")\n",
    "    axs[1].set_ylabel(r'$\\Sigma$ Loss, Normalized')\n",
    "    axs[1].set_xticks(np.arange(-1, 16))\n",
    "    axs[1].set_xticklabels(dict_to_xticklabels(losses[animal], labels=['αt', 'γt', 'αR', 'γR']))\n",
    "    # axs[1].set_ylim([.975, 1.12])\n",
    "    axs[1].set_xlim([-1.5, 16.5])\n",
    "    axs[1].axhline(1, color='k', linestyle='--')\n",
    "\n",
    "    for i, key in enumerate(the_keys_i_want):\n",
    "        axs[2].scatter(i+1, losses[animal][key]/losses[animal][False, False, False, False], \n",
    "                       color=rat_markers[animal][0], label=animal, marker=rat_markers[animal][1])\n",
    "    axs[2].set_title(f\"normalized loss (1)\")\n",
    "    axs[2].set_ylabel(r'$\\Sigma$ Loss')\n",
    "    axs[2].set_xticks(np.arange(7))\n",
    "    axs[2].set_xticklabels(dict_to_xticklabels({k:losses[animal][k] for k in the_keys_i_want}, \n",
    "                           labels=['αt', 'γt', 'αR', 'γR']))\n",
    "    # axs[2].set_ylim([.975, 1.12])\n",
    "    axs[2].set_xlim([-.5, 6.5])\n",
    "    axs[2].axhline(1, color='k', linestyle='--')\n",
    "\n",
    "# average by key\n",
    "means = [np.mean([losses[animal][key] for animal in animalList]) for key in losses[animal].keys()]\n",
    "yerr = [np.std([losses[animal][key] for animal in animalList]) for key in losses[animal].keys()]\n",
    "axs[0].errorbar(np.arange(16)+.25, means, yerr=yerr, color='k', label='Mean', marker='o', fmt=' ')\n",
    "\n",
    "means_norm = [np.mean([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in losses[animal].keys()]\n",
    "yerr_norm = [np.std([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in losses[animal].keys()]\n",
    "axs[1].errorbar(np.arange(16)+.25, means_norm, yerr=yerr_norm, color='k', label='Mean', marker='o', fmt=' ')\n",
    "\n",
    "means_norm_select = [np.mean([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in the_keys_i_want]\n",
    "yerr_norm_select = [np.std([losses[animal][key]/losses[animal][False, False, False, False] for animal in animalList]) for key in the_keys_i_want]\n",
    "axs[2].errorbar(np.arange(len(the_keys_i_want))+1.25, means_norm_select, yerr=yerr_norm_select, color='k', label='Mean', marker='o', fmt=' ')\n",
    "\n",
    "\n",
    "_losses1 = [losses[animal][False, False, False, False]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "_losses2 = [losses[animal][True, False, False, False]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "_losses3 = [losses[animal][False, True, False, False]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "_losses4 = [losses[animal][False, False, True, False]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "_losses5 = [losses[animal][False, False, False, True]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "_losses6 = [losses[animal][True, True, True, True]/losses[animal][False, False, False, False] for animal in animalList]\n",
    "\n",
    "print(\"Effect of parameters on loss (Friedman)\")\n",
    "f_test = stats.friedmanchisquare(_losses1, _losses2, _losses3, _losses4, _losses5, _losses6)\n",
    "print(f'Friedman test: F={f_test[0]:.3f}, p={f_test[1]:.3f}')\n",
    "print(\" \")\n",
    "print(\"comparisons: (wilcoxon)\")\n",
    "test_all_keys_between_themselves(losses, the_keys_i_want, axs[2])\n",
    "\n",
    "# pickle.dump(losses, open(\"picklejar/idle_time_model_BIC_ablation.p\", \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "### Example animal fit - 120cm\n",
    "Fit of the model for the same example animal on all Dist-120cm sessions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'RatM01'\n",
    "exampledata = prepare_data_idle_times(sequence, animalList, dist120)\n",
    "plot_full_distribution(exampledata, animal, plot_fit=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All experimental conditions fit\n",
    "We can now do the same as above for all experimental conditions (Distances and TM speed) and for each rat.  \n",
    "Each color is a different rat.  \n",
    "\n",
    "$\\mathrm{A}$:  \n",
    "- $\\alpha_0$ > 0, positive bound at start  \n",
    "- $\\alpha t$ > 0, $\\alpha$ increases with time  \n",
    "- $\\alpha R$ ~ 0, no effect of reward history on $\\alpha$  \n",
    "\n",
    "The distance to boundary $A$ increases with time, but not with reward history.  \n",
    "With time, need more motivation to start running.  \n",
    "\n",
    "**This is either congruent with *satiety*, which is low at the start of the session and increases with the total number of rewards obtained, or with *tiredness*, which is low at the start of the session and increases with the total distance travelled.**  \n",
    "Being sated, you need more motivation to leave. Being tired you need more motivation to leave.\n",
    "\n",
    "$\\Gamma$:  \n",
    "- $\\gamma_0$ > 0, positive drift rate at start  \n",
    "- $\\gamma t$ < 0, $\\gamma$ decreases with time  \n",
    "- $\\gamma R$ < 0, $\\gamma$ decreases with reward history  \n",
    "\n",
    "The drift rate $v$ decreases with time, and with reward history.  \n",
    "\n",
    "Accumulation of motivation is slower with time, and is slower when reward history is low (few rewards over previous trials).  \n",
    "With time, motivation accumulation is slower. When reward history is low, motivation accumulation is slower.  \n",
    "\n",
    "**This is congruent with the *perceived value of reward*, it is higher at the beginning of the session compared to the end, and it is higher when the probability of receiving it is high, compared to low.**\n",
    "Perceived value is Probability to get it * how much you want it.  \n",
    "\n",
    "\n",
    "However, we do not see a clear effect of experimental conditions on $\\mathrm{A}$ and $\\Gamma$.  \n",
    "In our case, the experimental conditions impact the amount of effort the animal needs to provide to get the reward, by either increasing the physical distance or facilitating/impeding each crossing.  \n",
    "Therefore, it seems that the amount of effort required has no impact on the idle time!!!  \n",
    "**The role of $\\alpha$ in capturing *tiredness* is therefore not plausible**\n",
    "\n",
    "\n",
    "Maybe we see no effect of condition because:  \n",
    "- animals are too thirsty? *no*, they would not stop running at the end if they were that thirsty.  \n",
    "- the amount of effort required is not enough? *no*, we see a decrease in the running speed with time.  \n",
    "\n",
    "**Stats**\n",
    "Not normal, so use wilcoxon to see if mean in each condition is != 0.  \n",
    "Wilcoxon to see if difference between two conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, figsize=(12, 20), gridspec_kw={'width_ratios': [5, 5, 2]})\n",
    "ylabels = [r'$\\alpha_0$', r\"$\\alpha_t$\", r\"$\\alpha_R$\", r'$\\gamma_0$', r\"$\\gamma_t$\", r\"$\\gamma_R$\"]\n",
    "ylims = [[-.5, 3], [-.1, .65], [-.45, .5], [-.2, 1.6], [-.25, .1], [-.35, .1]]\n",
    "alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, False, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, True, True, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, True, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = True, True, True, True\n",
    "\n",
    "alpha, gamma, alpha_t, gamma_t, alpha_R, gamma_R, lossWald = {}, {}, {}, {}, {}, {}, {}\n",
    "alpha_fit, gamma_fit, alpha_t_fit, gamma_t_fit, alpha_R_fit, gamma_R_fit = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "if os.path.exists(\"picklejar/idle_time_model_parameters_fit.p\"):\n",
    "    alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R, lossWald = pickle.load(open(\"picklejar/idle_time_model_parameters_fit.p\", \"rb\"))\n",
    "else:\n",
    "    if os.path.exists(\"picklejar/resamplingParameters100ITER.p\"):\n",
    "        alpha_fit, gamma_fit, alpha_t_fit, gamma_t_fit, alpha_R_fit, gamma_R_fit = pickle.load(open(\"picklejar/resamplingParameters100ITER.p\", \"rb\"))\n",
    "\n",
    "    for animal in animalList:\n",
    "        alpha[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        gamma[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        alpha_t[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        gamma_t[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        alpha_R[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        gamma_R[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "        lossWald[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "\n",
    "        for cond, data in zip([\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"], [data60, data90, data120, data20, data10, data2, datarev10, datarev20]):\n",
    "            (alpha[animal][cond], theta, gamma[animal][cond], \\\n",
    "            alpha_t[animal][cond], thetaprime, gamma_t[animal][cond], \\\n",
    "            alpha_R[animal][cond], thetasecond, gamma_R[animal][cond]), lossWald[animal][cond] = modelwald_fit(data[animal], alpha_t_fixed=alpha_t_fixed, \n",
    "                                                                                                                                        gamma_t_fixed=gamma_t_fixed, \n",
    "                                                                                                                                        alpha_R_fixed=alpha_R_fixed, \n",
    "                                                                                                                                        gamma_R_fixed=gamma_R_fixed, \n",
    "                                                                                                                                        )\n",
    "\n",
    "vars = [alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R]\n",
    "resampled = [alpha_fit, alpha_t_fit, alpha_R_fit, gamma_fit, gamma_t_fit, gamma_R_fit]\n",
    "\n",
    "def _percentiles(sample):\n",
    "        s = np.sort(sample)\n",
    "        return s[int(.05 * len(s))], s[int(.95 * len(s))]\n",
    "        \n",
    "for animal in animalList:\n",
    "    for i, (var, ylabel, ylim, resample) in enumerate(zip(vars, ylabels, ylims, resampled)):\n",
    "        \n",
    "        # axs[i, 0].plot((0, 0), _percentiles(resample[animal]['60']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 0].plot((1, 1), _percentiles(resample[animal]['90']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 0].plot((2, 2), _percentiles(resample[animal]['120']), color=rat_markers[animal][0], lw=2)\n",
    "        x, y = np.arange(3), [var[animal][\"60\"], var[animal][\"90\"], var[animal][\"120\"]]\n",
    "        axs[i, 0].plot(x, y, color=rat_markers[animal][0], label=animal, marker=rat_markers[animal][1], markersize=6.5, lw=2)\n",
    "        # gradient, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "        # axs[i, 0].plot(np.linspace(np.min(x), np.max(x), 100), gradient * np.linspace(np.min(x), np.max(x), 100) + intercept, color=rat_markers[animal][0], lw=2 if p_value < .05 else .5)\n",
    "        axs[i, 0].set_title(f\"\")\n",
    "        axs[i, 0].set_xticks(np.arange(3))\n",
    "        axs[i, 0].set_xticklabels([\"60\", \"90\", \"120\"])\n",
    "        axs[i, 0].set_ylabel(ylabel)\n",
    "        axs[i, 0].set_xlim(-.5, 2.5)\n",
    "        axs[i, 0].set_ylim(ylim)\n",
    "        axs[i, 0].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    for i, (var, ylabel, ylim, resample) in enumerate(zip(vars, ylabels, ylims, resampled)):\n",
    "\n",
    "        # axs[i, 1].plot((0, 0), _percentiles(resample[animal]['20']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 1].plot((1, 1), _percentiles(resample[animal]['10']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 1].plot((2, 2), _percentiles(resample[animal]['2']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 1].plot((3, 3), _percentiles(resample[animal]['rev10']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 1].plot((4, 4), _percentiles(resample[animal]['rev20']), color=rat_markers[animal][0], lw=2)\n",
    "        x, y = np.arange(5), [var[animal][\"20\"], var[animal][\"10\"], var[animal][\"2\"], var[animal][\"rev10\"], var[animal][\"rev20\"]]\n",
    "        axs[i, 1].plot(x, y, color=rat_markers[animal][0], label=animal, marker=rat_markers[animal][1], markersize=6.5, lw=2)\n",
    "        # gradient, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "        # axs[i, 1].plot(np.linspace(np.min(x), np.max(x), 100), gradient * np.linspace(np.min(x), np.max(x), 100) + intercept, color=rat_markers[animal][0], lw=2 if p_value < .05 else .5)\n",
    "        axs[i, 1].set_title(f\"\")\n",
    "        axs[i, 1].set_xticks(np.arange(5))\n",
    "        axs[i, 1].set_xticklabels([\"20\", \"10\", \"0\", \"-10\", \"-20\"])\n",
    "        axs[i, 1].set_ylabel(ylabel)\n",
    "        axs[i, 1].set_xlim(-.5, 4.5)\n",
    "        axs[i, 1].set_ylim(ylim)\n",
    "        axs[i, 1].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "axs[i, 0].set_xlabel(\"Distance\")\n",
    "axs[i, 1].set_xlabel(r'$v_{belt}$')\n",
    "axs[i, 2].set_xlabel(\"All conditions pooled\")\n",
    "\n",
    "#mean per condition\n",
    "for idx, cond in enumerate([\"60\", \"90\", \"120\"]):\n",
    "    for jdx, var in enumerate([alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R]):\n",
    "        d = [var[animal][cond] for animal in animalList]\n",
    "        mean, std = np.mean(d), np.std(d)/np.sqrt(len(d))\n",
    "        s, p = stats.wilcoxon(d)\n",
    "        if p < .05: axs[jdx, 0].scatter(idx+.3, mean, color='k', marker=r'$\\ast$')\n",
    "        axs[jdx, 0].errorbar(idx+.2, mean, yerr=std, color='black', marker='o', markersize=5, capsize=5, capthick=2, linewidth=2)\n",
    "\n",
    "for idx, cond in enumerate([\"20\", \"10\", \"2\", \"rev10\", \"rev20\"]):\n",
    "    for jdx, var in enumerate([alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R]):\n",
    "        d = [var[animal][cond] for animal in animalList]\n",
    "        mean, std = np.mean(d), np.std(d)/np.sqrt(len(d))\n",
    "        s, p = stats.wilcoxon(d)\n",
    "        if p < .05: axs[jdx, 1].scatter(idx+.3, mean, color='k', marker=r'$\\ast$')\n",
    "        axs[jdx, 1].errorbar(idx+.2, mean, yerr=std, color='black', marker='o', markersize=5, capsize=5, capthick=2, linewidth=2)\n",
    "\n",
    "test_all_conds_between_themselves([\"60\", \"90\", \"120\"], vars, ax=axs[:, 0])\n",
    "test_all_conds_between_themselves([\"20\", \"10\", \"2\", \"rev10\", \"rev20\"], vars, ax=axs[:, 1])\n",
    "\n",
    "# pickle.dump([alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R], open(\"picklejar/main_fitting_results.p\", \"wb\"))\n",
    "# pickle.dump([alphaPool, alpha_tPool, alpha_RPool, gammaPool, gamma_tPool, gamma_RPool], open(\"picklejar/main_fitting_results_pooled.p\", \"wb\"))\n",
    "\n",
    "Zalpha = {animal: {key: (alpha[animal][key] - np.mean([alpha[animal][key] for animal in animalList]))/np.std([alpha[animal][key] for animal in animalList]) for key in alpha[animal]} for animal in animalList}\n",
    "Zalpha_t = {animal: {key: (alpha_t[animal][key] - np.mean([alpha_t[animal][key] for animal in animalList]))/np.std([alpha_t[animal][key] for animal in animalList]) for key in alpha_t[animal]} for animal in animalList}\n",
    "Zalpha_R = {animal: {key: (alpha_R[animal][key] - np.mean([alpha_R[animal][key] for animal in animalList]))/np.std([alpha_R[animal][key] for animal in animalList]) for key in alpha_R[animal]} for animal in animalList}\n",
    "Zgamma = {animal: {key: (gamma[animal][key] - np.mean([gamma[animal][key] for animal in animalList]))/np.std([gamma[animal][key] for animal in animalList]) for key in gamma[animal]} for animal in animalList}\n",
    "Zgamma_t = {animal: {key: (gamma_t[animal][key] - np.mean([gamma_t[animal][key] for animal in animalList]))/np.std([gamma_t[animal][key] for animal in animalList]) for key in gamma_t[animal]} for animal in animalList}\n",
    "Zgamma_R = {animal: {key: (gamma_R[animal][key] - np.mean([gamma_R[animal][key] for animal in animalList]))/np.std([gamma_R[animal][key] for animal in animalList]) for key in gamma_R[animal]} for animal in animalList}\n",
    "\n",
    "traits = {animal: [] for animal in animalList}\n",
    "Zvars = [Zalpha, Zalpha_t, Zalpha_R, Zgamma, Zgamma_t, Zgamma_R]\n",
    "for j, zvar in enumerate(Zvars):\n",
    "    for animal in animalList:\n",
    "        zscores = [zvar[animal][cond] for cond in [\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"]]\n",
    "        pdf = stats.norm.pdf(np.linspace(-3, 3, 600), np.mean(zscores), np.std(zscores))\n",
    "        traits[animal].append(np.mean(zscores))\n",
    "        axs[j, 2].plot(pdf, np.linspace(-3, 3, 600), color=rat_markers[animal][0], linestyle=lines[brainstatus[animal]])\n",
    "        Ri = compute_Ri(zvar, animalList)\n",
    "        axs[j, 2].annotate(f'Ri = {Ri:.2f}: {interpret_Ri(Ri)}', xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "        axs[j, 2].set_ylim(-3, 3)\n",
    "        axs[j, 2].set_ylabel(\"Z-scored \" + ylabels[j])\n",
    "        axs[j, 2].set_xlabel(\"\")\n",
    "        axs[j, 2].set_xticks([])\n",
    "\n",
    "# pickle.dump([alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R, lossWald], open(\"picklejar/idle_time_model_parameters_fit.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 2, figsize=(10, 20), gridspec_kw={'width_ratios': [3, 1]})\n",
    "for j, zvar in enumerate(Zvars):\n",
    "    for animal in animalList:\n",
    "        zscores = [zvar[animal][cond] for cond in [\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"]]\n",
    "\n",
    "        axs[j, 0].plot(np.arange(8), zscores, color=rat_markers[animal][0], linestyle=lines[brainstatus[animal]])\n",
    "        axs[j, 0].set_ylim(-3, 3)\n",
    "\n",
    "\n",
    "        # axs[j, 1].hist(zscores, bins=np.linspace(-3, 3, 61), color=rat_markers[animal][0], alpha=0.25)\n",
    "        Ri = compute_Ri(zvar, animalList)\n",
    "        pdf = stats.norm.pdf(np.linspace(-3, 3, 600), np.mean(zscores), np.std(zscores))\n",
    "        axs[j, 1].plot(pdf, np.linspace(-3, 3, 600), color=rat_markers[animal][0], linestyle=lines[brainstatus[animal]])\n",
    "        axs[j, 1].annotate(f'Ri = {Ri:.2f}: {interpret_Ri(Ri)}', xy=(0.05, 0.9), xycoords='axes fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = interact(intuition_Ri, gain=(0, .5, .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "for idx, animal in enumerate(animalList):\n",
    "        make_spider(axs, traits[animal], title='', \n",
    "        color=rat_markers[animal][0], marker=rat_markers[animal][1], linestyle=lines[brainstatus[animal]],\n",
    "        labels=[r'$\\alpha_0$', r\"$\\alpha_t$\", r\"$\\alpha_R$\", r'$\\gamma_0$', r\"$\\gamma_t$\", r\"$\\gamma_R$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter/weight correlation\n",
    "Correlation between average weight of each animal and the fitted parameters.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'RatF00': 212.02, 'RatF01': 205.85, 'RatF02': 193.75,\n",
    "            'RatM00': 259.37, 'RatM01': 278.12, 'RatM02': 253.19,\n",
    "            'RatF20': 220.10, 'RatF21': 215.53, 'RatF22': 215.0,\n",
    "            'RatM20': 254.68, 'RatM21': 307.29, 'RatM22': 330.53,\n",
    "            'RatF30': 217.32, 'RatF31': 228.95, 'RatF32': 216.80, 'RatF33': 222.77,\n",
    "            'RatM30': 261.38, 'RatM31': 300.55, 'RatM32': 279.23, \n",
    "            'RatF30L': 217.32, 'RatF31L': 228.95, 'RatF32L': 216.80, 'RatF33L': 222.77,\n",
    "            'RatM30L': 261.38, 'RatM31L': 300.55, 'RatM32L': 279.23}\n",
    "\n",
    "fig, ax = plt.subplots(1, 6, figsize=(15, 3))\n",
    "for j, zvar in enumerate(Zvars):\n",
    "    _x, _y = [], []\n",
    "    for animal in animalList:\n",
    "        zscores = [zvar[animal][cond] for cond in [\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"]]\n",
    "        y = np.mean(zscores)\n",
    "        x = weights[animal]\n",
    "\n",
    "        ax[j].scatter(x, y, color=rat_markers[animal][0], marker=rat_markers[animal][1], s=100)\n",
    "        ax[j].set_xlabel(\"Weight (g)\")\n",
    "        ax[j].set_ylabel(ylabels[j])\n",
    "        ax[j].set_ylim(-2, 2)\n",
    "\n",
    "        _x.append(x)\n",
    "        _y.append(y)\n",
    "\n",
    "    pearson = stats.pearsonr(_x, _y)\n",
    "    print(ylabels[j]+f' corr: {pearson[0]:.2f}, p: {pearson[1]:.4f}')\n",
    "    \n",
    "    gradient, intercept, r_value, p_value, std_err = stats.linregress(_x, _y)\n",
    "    ax[j].plot(np.linspace(np.min(_x), np.max(_x), 100), gradient * np.linspace(np.min(_x), np.max(_x), 100) + intercept, color='black', lw=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary - Model hyperparameters\n",
    "We search the optimal hyperparameters for our model:  \n",
    "- memory size,  \n",
    "- number of time bins,  \n",
    "- data pooling -removed-.  \n",
    "\n",
    "We use the BIC to compare two models with different memory sizes and time bins (i.e. not the same number of cells).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Memory size\n",
    "How many items does the rat keep in memory?  \n",
    "Compute the total loss of the model using data from all conditions for different memory sizes, find the memory size that minimizes the loss.  \n",
    "--> 4 --> 3 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memsizes = np.arange(1, 9)\n",
    "\n",
    "losses = {k:np.zeros(len(memsizes)) for k in animalList}\n",
    "sessions = dist60+dist90+dist120+TM20+TM10+TM2+TMrev2+TMrev10+TMrev20\n",
    "\n",
    "if os.path.exists(\"picklejar/lossesMemSize.p\"):\n",
    "    losses = pickle.load(open(\"picklejar/lossesMemSize.p\", \"rb\"))\n",
    "else:\n",
    "    for idx, memsize in enumerate(memsizes):\n",
    "        data_all = prepare_data_idle_times(sequence, animalList, sessions, memsize=memsize, time_bins=6)\n",
    "        for animal in animalList:\n",
    "            p, losses[animal][idx] = modelwald_fit(data_all[animal], f=model_compare, N_bins=6, N_avg=len(meankeys(generate_targetList(seq_len=memsize)[::-1])))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "avglosses = np.zeros((len(animalList), len(memsizes)))\n",
    "for idx, animal in enumerate(animalList):\n",
    "    axs[0].plot(memsizes, losses[animal], color=rat_markers[animal][0])\n",
    "    axs[1].plot(memsizes, (losses[animal])/(losses[animal][0]), color=rat_markers[animal][0], label=animal)\n",
    "    avglosses[idx] = losses[animal]/losses[animal][0]\n",
    "\n",
    "f = np.mean(avglosses[:3], axis=0)\n",
    "m = np.mean(avglosses[3:], axis=0)\n",
    "avglosses = np.median(avglosses, axis=0)\n",
    "\n",
    "axs[1].plot(memsizes, avglosses, color='k', lw=2)\n",
    "z = np.poly1d(np.polyfit(memsizes, avglosses, 4))\n",
    "x=np.linspace(1, 8, 100)\n",
    "axs[1].plot(x, z(x), color='k', lw=3, ls='--')\n",
    "print(x[np.argmin(z(x))])\n",
    "# axs[0].plot(memsizes, f/3, color='r', lw=2, ls='--')\n",
    "# axs[0].plot(memsizes, m/3, color='g', lw=2, ls='--')\n",
    "# axs[1].plot(memsizes, f, color='r', lw=2, ls='--')\n",
    "# axs[1].plot(memsizes, m, color='g', lw=2, ls='--')\n",
    "\n",
    "axs[0].set_xlabel('mem span')\n",
    "axs[1].set_xlabel('mem span')\n",
    "axs[0].set_ylabel(r'$\\Sigma$ loss')\n",
    "axs[1].set_ylabel(r'$\\Sigma$ loss, norm')\n",
    "axs[1].legend()\n",
    "\n",
    "# pickle.dump(losses, open(\"picklejar/lossesMemSize.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Time bins\n",
    "In how many time bins should we cut the data?  \n",
    "Trade off between resolution (more bins is better), having data from all average reward obtained (less bins is better).  \n",
    "--> 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memsize = 4\n",
    "time_bins = [3, 6]\n",
    "time_bins = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "losses = {k:np.zeros(len(time_bins)) for k in animalList}\n",
    "sessions = dist60+dist90+dist120+TM20+TM10+TM2+TMrev2+TMrev10+TMrev20\n",
    "\n",
    "if os.path.exists(\"picklejar/lossesTimeBins.p\"):\n",
    "    losses = pickle.load(open(\"picklejar/lossesTimeBins.p\", \"rb\"))\n",
    "else:\n",
    "    for idx, bins in enumerate(time_bins):\n",
    "        data_all = prepare_data_idle_times(sequence, animalList, sessions, memsize=memsize, time_bins=bins)\n",
    "        for animal in animalList:\n",
    "            p, losses[animal][idx] = modelwald_fit(data_all[animal], f=model_compare, N_bins=bins, N_avg=len(meankeys(generate_targetList(seq_len=memsize)[::-1])))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "avglosses = np.zeros(len(time_bins))\n",
    "for idx, animal in enumerate(animalList):\n",
    "    axs[0].plot(time_bins, losses[animal], color=rat_markers[animal][0])\n",
    "    axs[1].plot(time_bins, (losses[animal])/(losses[animal][0]), color=rat_markers[animal][0], label=animal)\n",
    "    avglosses += losses[animal]\n",
    "\n",
    "axs[1].plot(time_bins, avglosses/avglosses[0], color='k', lw=3)\n",
    "\n",
    "axs[0].set_xlabel('# time bins')\n",
    "axs[1].set_xlabel('# time bins')\n",
    "axs[0].set_ylabel(r'$\\Sigma$ loss')\n",
    "axs[1].set_ylabel(r'$\\Sigma$ loss, norm')\n",
    "axs[1].legend()\n",
    "\n",
    "# pickle.dump(losses, open(\"picklejar/lossesTimeBins.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) t_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha, alpha', alpha'', gamma, gamma', gamma''\n",
    "def model_compareT(params, *args, robustness_param=1e-20):\n",
    "    alpha, theta, gamma, alpha_t, theta_prime, gamma_t, alpha_R, theta_second, gamma_R = params\n",
    "    BIC = 0\n",
    "    N_bins, N_avg, t_0 = args[1]\n",
    "    ALPHA = np.zeros((N_bins, N_avg))\n",
    "    GAMMA = np.zeros((N_bins, N_avg))\n",
    "    _theta = t_0\n",
    "\n",
    "    for bin in range(N_bins):\n",
    "        for avg in range(N_avg):\n",
    "            ALPHA[bin, avg] = alpha + bin*alpha_t + avg*alpha_R\n",
    "            GAMMA[bin, avg] = gamma + bin*gamma_t + avg*gamma_R\n",
    "\n",
    "    for bin in range(N_bins):\n",
    "        for avg in range(N_avg):\n",
    "            _alpha = ALPHA[bin, avg] if ALPHA[bin, avg] > 0 else 1e-8\n",
    "            _gamma = GAMMA[bin, avg]# if GAMMA[bin, avg] > 0 else 1e-8\n",
    "            try:\n",
    "                pdf_vals = Wald_pdf(args[0][bin][avg], _alpha, _theta, _gamma)\n",
    "                ln_pdf_vals = np.log(pdf_vals + robustness_param)\n",
    "                log_lik_val = ln_pdf_vals.sum()\n",
    "\n",
    "                n = len(args[0][bin][avg]) if len(args[0][bin][avg]) > 0 else 1\n",
    "                k = 2  # alpha, gamma\n",
    "                BIC += k * np.log(n) - 2 * log_lik_val\n",
    "            except:\n",
    "                BIC += 0  # add 0 instead of throwing an error when there is no data in a bin*avg\n",
    "    return BIC\n",
    "\n",
    "\n",
    "def modelwald_fitT(data, init=[2, 0, .5, 0, 0, 0, 0, 0, 0], f=model_crit, N_bins=6, N_avg=4, t_0=0, alpha_t_fixed=False, gamma_t_fixed=False, alpha_R_fixed=False, gamma_R_fixed=False):\n",
    "    params_init = np.array(init)\n",
    "    alpha_t_bounds = (None, None) if not alpha_t_fixed else (0, 1e-8)\n",
    "    gamma_t_bounds = (None, None) if not gamma_t_fixed else (0, 1e-8)\n",
    "    alpha_R_bounds = (None, None) if not alpha_R_fixed else (0, 1e-8)\n",
    "    gamma_R_bounds = (None, None) if not gamma_R_fixed else (0, 1e-8)\n",
    "\n",
    "    res = scipy.optimize.minimize(f, params_init, args=(data, [N_bins, N_avg, t_0]), \n",
    "                                        bounds=((0, None), (0, 1e-8), (0, None), \n",
    "                                            alpha_t_bounds, (0, 1e-8), gamma_t_bounds, \n",
    "                                            alpha_R_bounds, (0, 1e-8), gamma_R_bounds))\n",
    "    return res.x, res.fun\n",
    "\n",
    "\n",
    "\n",
    "memsize = 4\n",
    "t_0s = np.linspace(0, 1, 26)\n",
    "t_0s = np.linspace(0, .5, 10)\n",
    "\n",
    "losses = {k:np.zeros(len(t_0s)) for k in animalList}\n",
    "sessions = dist60+dist90+dist120+TM20+TM10+TM2+TMrev2+TMrev10+TMrev20\n",
    "\n",
    "for idx, t_0 in enumerate(t_0s):\n",
    "    data_all = prepare_data_idle_times(sequence, animalList, sessions, memsize=3, time_bins=6)\n",
    "    for animal in animalList:\n",
    "        p, losses[animal][idx] = modelwald_fitT(data_all[animal], t_0=t_0, f=model_compareT, N_bins=6, N_avg=len(meankeys(generate_targetList(seq_len=4)[::-1])))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "avglosses = np.zeros(len(t_0s))\n",
    "for idx, animal in enumerate(animalList):\n",
    "    axs[0].plot(t_0s, losses[animal], color=rat_markers[animal][0])\n",
    "    axs[1].plot(t_0s, (losses[animal])/(losses[animal][0]), color=rat_markers[animal][0], label=animal)\n",
    "    avglosses += losses[animal]\n",
    "\n",
    "axs[1].plot(t_0s, avglosses/avglosses[0], color='k', lw=3)\n",
    "\n",
    "axs[0].set_xlabel('# time bins')\n",
    "axs[1].set_xlabel('# time bins')\n",
    "axs[0].set_ylabel(r'$\\Sigma$ loss')\n",
    "axs[1].set_ylabel(r'$\\Sigma$ loss, norm')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interindividual variability/Confidence interval/Resampling\n",
    "We can also see some variability between animals. Is this an artifact of our fitting method or is it interindividual variability?  \n",
    "Variability conserved between conditions.  \n",
    "Male/female difference.  \n",
    "\n",
    "Resampling.  \n",
    "To test if the variability is due to the fit we perform a resampling.  \n",
    "We use the fitted $\\alpha_0, \\alpha t, \\alpha R, \\gamma_0, \\gamma t, \\gamma R$ parameters for each rat to generate synthetic idle times. We then fit the synthetic data (for which we know the parameters, same number of synthetic data as experimental data) and recover a distribution of parameter estimation (N=100 iterations). The distribution of parameter estimation give us a confidence interval for each parameter. \n",
    "For each fitted value in the above plot, the error bars denote the 5-95th values obtained in the resampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute \n",
    "ITER = 100\n",
    "\n",
    "alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R = pickle.load(open(\"picklejar/main_fitting_results.p\", \"rb\"))\n",
    "\n",
    "if os.path.exists(\"picklejar/resamplingParameters100ITER.p\"):\n",
    "    alpha_fit, gamma_fit, alpha_t_fit, gamma_t_fit, alpha_R_fit, gamma_R_fit = pickle.load(open(\"picklejar/resamplingParameters100ITER.p\", \"rb\"))\n",
    "\n",
    "else:    \n",
    "    alpha_fit, gamma_fit, alpha_t_fit, gamma_t_fit, alpha_R_fit, gamma_R_fit = {}, {}, {}, {}, {}, {}\n",
    "    alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, False, False\n",
    "    for idx, animal in enumerate(animalList):\n",
    "        alpha_fit[animal] = {}\n",
    "        gamma_fit[animal] = {}\n",
    "        alpha_t_fit[animal] = {}\n",
    "        gamma_t_fit[animal] = {}\n",
    "        alpha_R_fit[animal] = {}\n",
    "        gamma_R_fit[animal] = {}\n",
    "\n",
    "        for cond, sessions, data in zip([\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"], \n",
    "                                        [matchsession(animal, dist60), matchsession(animal, dist90), matchsession(animal, dist120), \n",
    "                                            matchsession(animal, TM20), matchsession(animal, TM10), matchsession(animal, TM2), matchsession(animal, TMrev10), matchsession(animal, TMrev20)],\n",
    "                                        [data60_bysession, data90_bysession, data120_bysession, \n",
    "                                            data20_bysession, data10_bysession, data2_bysession, datarev10_bysession, datarev20_bysession]):\n",
    "\n",
    "            _alpha, _gamma, _alpha_t, _gamma_t, _alpha_R, _gamma_R = alpha[animal][cond], gamma[animal][cond], alpha_t[animal][cond], gamma_t[animal][cond], alpha_R[animal][cond], gamma_R[animal][cond]\n",
    "\n",
    "            N_bins = 6\n",
    "            N_avg = 4\n",
    "            ALPHA = np.zeros((N_bins, N_avg))\n",
    "            GAMMA = np.zeros((N_bins, N_avg))\n",
    "            sample = np.zeros((N_bins, N_avg)).tolist()\n",
    "            N_OBS = np.zeros((N_bins, N_avg))\n",
    "\n",
    "            for session in sessions:\n",
    "                for bin in range(0, N_bins):\n",
    "                    for avg in range(0, N_avg):\n",
    "                        N_OBS[bin][avg] += len(data[animal][session][bin][avg])\n",
    "\n",
    "            for bin in range(0, N_bins):\n",
    "                for avg in range(0, N_avg):\n",
    "                    ALPHA[bin, avg] = _alpha + bin*_alpha_t + avg*_alpha_R\n",
    "                    GAMMA[bin, avg] = _gamma + bin*_gamma_t + avg*_gamma_R\n",
    "\n",
    "            iters = ITER\n",
    "            alpha_fit[animal][cond] = np.zeros((iters))\n",
    "            gamma_fit[animal][cond] = np.zeros((iters))\n",
    "            alpha_t_fit[animal][cond] = np.zeros((iters))\n",
    "            gamma_t_fit[animal][cond] = np.zeros((iters))\n",
    "            alpha_R_fit[animal][cond] = np.zeros((iters))\n",
    "            gamma_R_fit[animal][cond] = np.zeros((iters))\n",
    "\n",
    "            fit_dicts = [alpha_fit, gamma_fit, alpha_t_fit, gamma_t_fit, alpha_R_fit, gamma_R_fit]\n",
    "\n",
    "            for iter in range(0, iters):\n",
    "                simple_progress_bar(iter, iters, animal, cond, bar_length=20)\n",
    "                for bin in range(0, N_bins):\n",
    "                    for avg in range(0, N_avg):\n",
    "                        sample[bin][avg] = np.asarray(genWaldSamples(N_OBS[bin, avg], ALPHA[bin, avg], GAMMA[bin, avg]))\n",
    "\n",
    "                (alpha_fit[animal][cond][iter], theta_fit, gamma_fit[animal][cond][iter], \\\n",
    "                    alpha_t_fit[animal][cond][iter], theta_prime_fit, gamma_t_fit[animal][cond][iter], \\\n",
    "                        alpha_R_fit[animal][cond][iter], theta_second_fit, gamma_R_fit[animal][cond][iter]), loss = modelwald_fit(sample, \n",
    "                                                                                                    alpha_t_fixed=alpha_t_fixed, \n",
    "                                                                                                    gamma_t_fixed=gamma_t_fixed, \n",
    "                                                                                                    alpha_R_fixed=alpha_R_fixed, \n",
    "                                                                                                    gamma_R_fixed=gamma_R_fixed)\n",
    "    pickle.dump([alpha_fit, gamma_fit, alpha_t_fit, gamma_t_fit, alpha_R_fit, gamma_R_fit], open(\"picklejar/resamplingParameters100ITER.p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) data not pooled\n",
    "What happens when we don't pool the data -> increase in variability due to lack of data.  \n",
    "some sessions with no data at the end of session/when R low, underestimate $\\alpha'$, $\\gamma'$, $\\alpha''$ and $\\gamma''$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) session by session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetlist = generate_targetList(seq_len=4)[::-1]\n",
    "fig, axs = plt.subplots(6, 2, figsize=(10, 20), constrained_layout=True)\n",
    "\n",
    "\n",
    "ylabels = [r'$\\alpha$', r\"$\\alpha'$\", r\"$\\alpha''$\", r'$\\gamma$', r\"$\\gamma'$\", r\"$\\gamma''$\"]\n",
    "ylims = [[-.5, 3], [-.1, .65], [-.45, .5], [-.2, 1.6], [-.25, .1], [-.35, .1]]\n",
    "\n",
    "\n",
    "alpha_session = {}\n",
    "gamma_session = {}\n",
    "alpha_t_session = {}\n",
    "gamma_t_session = {}\n",
    "alpha_R_session = {}\n",
    "gamma_R_session = {}\n",
    "lossWald_session = {}\n",
    "\n",
    "\n",
    "alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, False, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, True, True, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, True, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = True, True, True, True\n",
    "\n",
    "for idx, animal in enumerate(animalList):\n",
    "\n",
    "    alpha_session[animal] = {}\n",
    "    gamma_session[animal] = {}\n",
    "    alpha_t_session[animal] = {}\n",
    "    gamma_t_session[animal] = {}\n",
    "    alpha_R_session[animal] = {}\n",
    "    gamma_R_session[animal] = {}\n",
    "    lossWald_session[animal] = {}\n",
    "\n",
    "    for cond, data, sessionlist in zip([60, 90, 120, 20, 10, 2, -10, -20], \n",
    "                                        [data60_bysession, data90_bysession, data120_bysession, data20_bysession, \n",
    "                                            data10_bysession, data2_bysession, datarev10_bysession, datarev20_bysession], \n",
    "                                        [dist60, dist90, dist120, TM20, TM10, TM2+TMrev2, TMrev10, TMrev20]):\n",
    "\n",
    "        for session in matchsession(animal, sessionlist):\n",
    "            alpha_session[animal][session] = 0\n",
    "            gamma_session[animal][session] = 0\n",
    "            alpha_t_session[animal][session] = 0\n",
    "            gamma_t_session[animal][session] = 0\n",
    "            alpha_R_session[animal][session] = 0\n",
    "            gamma_R_session[animal][session] = 0\n",
    "            lossWald_session[animal][session] = 0\n",
    "\n",
    "            (alpha_session[animal][session], theta_session, gamma_session[animal][session], \\\n",
    "            alpha_t_session[animal][session], thetaprime_session, gamma_t_session[animal][session], \\\n",
    "            alpha_R_session[animal][session], thetasecond_session, gamma_R_session[animal][session]), lossWald_session[animal][session] = modelwald_fit(data[animal][session], alpha_t_fixed=alpha_t_fixed, \n",
    "                                                                                                                                                                gamma_t_fixed=gamma_t_fixed, \n",
    "                                                                                                                                                                alpha_R_fixed=alpha_R_fixed, \n",
    "                                                                                                                                                                gamma_R_fixed=gamma_R_fixed, \n",
    "                                                                                                                                                                )\n",
    "    \n",
    "            vars = [alpha_session, alpha_t_session, alpha_R_session, gamma_session, gamma_t_session, gamma_R_session]\n",
    "            if cond in [60, 90, 120]:\n",
    "                for i, (var, ylabel, ylim) in enumerate(zip(vars, ylabels, ylims)):\n",
    "                    # axs[i, 0].scatter(np.arange(3), [var[animal][session][\"60\"], var[animal][session][\"90\"], var[animal][session][\"120\"]], color=rat_markers[animal][0], label=animal)\n",
    "                    axs[i, 0].scatter(cond + 3*idx, var[animal][session], color=rat_markers[animal][0], label=animal)\n",
    "                    axs[i, 0].set_title(f\"\")\n",
    "                    axs[i, 0].set_xticks([60, 90, 120])\n",
    "                    axs[i, 0].set_xticklabels([\"60\", \"90\", \"120\"])\n",
    "                    axs[i, 0].set_xlabel(\"Distance\", fontsize=14)\n",
    "                    axs[i, 0].set_ylabel(ylabel, fontsize=14)\n",
    "                    axs[i, 0].set_xlim(40, 140)\n",
    "                    axs[i, 0].set_ylim(ylim)\n",
    "                    axs[i, 0].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "            else:\n",
    "                for i, (var, ylabel, ylim) in enumerate(zip(vars, ylabels, ylims)):\n",
    "                    # axs[i, 1].scatter(np.arange(5), [var[animal][\"20\"], var[animal][\"10\"], var[animal][\"2\"], var[animal][\"rev10\"], var[animal][\"rev20\"]], color=rat_markers[animal][0], label=animal)\n",
    "                    axs[i, 1].scatter(cond + idx, var[animal][session], color=rat_markers[animal][0], label=animal)\n",
    "                    axs[i, 1].set_title(f\"\")\n",
    "                    axs[i, 1].set_xticks([20, 10, 0, -10, -20])\n",
    "                    axs[i, 1].set_xticklabels([\"20\", \"10\", \"0\", \"-10\", \"-20\"])\n",
    "                    axs[i, 1].set_xlabel(r'$v_{belt}$', fontsize=14)\n",
    "                    axs[i, 1].set_ylabel(ylabel, fontsize=14)\n",
    "                    axs[i, 1].set_xlim(-30, 30)\n",
    "                    axs[i, 1].set_ylim(ylim)\n",
    "                    axs[i, 1].axhline(0, color='black', linestyle='--', linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Generating avg number of waiting times per session\n",
    "100 sampling+fitting iterations  \n",
    "pickle results because ~1s/(gen+fit) -> ~1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITER = 1  # 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# redo\n",
    "alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R = pickle.load(open(\"picklejar/main_fitting_results.p\", \"rb\"))\n",
    "\n",
    "\n",
    "alpha_fit = {}\n",
    "gamma_fit = {}\n",
    "alpha_t_fit = {}\n",
    "gamma_t_fit = {}\n",
    "alpha_R_fit = {}\n",
    "gamma_R_fit = {}\n",
    "\n",
    "\n",
    "for idx, animal in enumerate(animalList):\n",
    "    alpha_fit[animal] = {}\n",
    "    gamma_fit[animal] = {}\n",
    "    alpha_t_fit[animal] = {}\n",
    "    gamma_t_fit[animal] = {}\n",
    "    alpha_R_fit[animal] = {}\n",
    "    gamma_R_fit[animal] = {}\n",
    "\n",
    "    for cond, sessions, data in zip(\n",
    "                                        [\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"], \n",
    "                                        [matchsession(animal, dist60), matchsession(animal, dist90), matchsession(animal, dist120), \n",
    "                                            matchsession(animal, TM20), matchsession(animal, TM10), matchsession(animal, TM2), matchsession(animal, TMrev10), matchsession(animal, TMrev20)],\n",
    "                                        [data60_bysession, data90_bysession, data120_bysession, data20_bysession, data10_bysession, data2_bysession, datarev10_bysession, datarev20_bysession]):\n",
    "\n",
    "        _alpha, _gamma, _alpha_t, _gamma_t, _alpha_R, _gamma_R = alpha[animal][cond], gamma[animal][cond], alpha_t[animal][cond], gamma_t[animal][cond], alpha_R[animal][cond], gamma_R[animal][cond]\n",
    "\n",
    "        N_bins=6\n",
    "        N_avg=4\n",
    "        ALPHA = np.zeros((N_bins, N_avg))\n",
    "        GAMMA = np.zeros((N_bins, N_avg))\n",
    "        sample = np.zeros((N_bins, N_avg)).tolist()\n",
    "        N_OBS = np.zeros((N_bins, N_avg))\n",
    "\n",
    "        for session in sessions:\n",
    "            for bin in range(0, N_bins):\n",
    "                for avg in range(0, N_avg):\n",
    "                    N_OBS[bin][avg] += len(data[animal][session][bin][avg])\n",
    "                    \n",
    "        ####################################################\n",
    "        N_OBS /= len(sessions)\n",
    "        ####################################################\n",
    "\n",
    "        for bin in range(0, N_bins):\n",
    "            for avg in range(0, N_avg):\n",
    "                ALPHA[bin, avg] = _alpha + bin*_alpha_t + avg*_alpha_R\n",
    "                GAMMA[bin, avg] = _gamma + bin*_gamma_t + avg*_gamma_R\n",
    "\n",
    "        iters = ITER\n",
    "        alpha_fit[animal][cond] = np.zeros((iters))\n",
    "        gamma_fit[animal][cond] = np.zeros((iters))\n",
    "        alpha_t_fit[animal][cond] = np.zeros((iters))\n",
    "        gamma_t_fit[animal][cond] = np.zeros((iters))\n",
    "        alpha_R_fit[animal][cond] = np.zeros((iters))\n",
    "        gamma_R_fit[animal][cond] = np.zeros((iters))\n",
    "\n",
    "        for iter in range(0, iters):\n",
    "            simple_progress_bar(iter, iters, animal, cond, bar_length=20)\n",
    "            for bin in range(0, N_bins):\n",
    "                for avg in range(0, N_avg):\n",
    "                    sample[bin][avg] = np.asarray(genWaldSamples(N_OBS[bin, avg], ALPHA[bin, avg], GAMMA[bin, avg]))\n",
    "\n",
    "            (alpha_fit[animal][cond][iter], theta_fit, gamma_fit[animal][cond][iter], \\\n",
    "                alpha_t_fit[animal][cond][iter], theta_prime_fit, gamma_t_fit[animal][cond][iter], \\\n",
    "                    alpha_R_fit[animal][cond][iter], theta_second_fit, gamma_R_fit[animal][cond][iter]), loss = modelwald_fit(sample, \n",
    "                                                                                                alpha_t_fixed=alpha_t_fixed, \n",
    "                                                                                                gamma_t_fixed=gamma_t_fixed, \n",
    "                                                                                                alpha_R_fixed=alpha_R_fixed, \n",
    "                                                                                                gamma_R_fixed=gamma_R_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle\n",
    "# pickle.dump(alpha_fit, open(\"picklejar/alpha_fit100_sessionBIC.p\", \"wb\"))\n",
    "# pickle.dump(gamma_fit, open(\"picklejar/gamma_fit100_sessionBIC.p\", \"wb\"))\n",
    "# pickle.dump(alpha_t_fit, open(\"picklejar/alpha_t_fit100_sessionBIC.p\", \"wb\"))\n",
    "# pickle.dump(gamma_t_fit, open(\"picklejar/gamma_t_fit100_sessionBIC.p\", \"wb\"))\n",
    "# pickle.dump(alpha_R_fit, open(\"picklejar/alpha_R_fit100_sessionBIC.p\", \"wb\"))\n",
    "# pickle.dump(gamma_R_fit, open(\"picklejar/gamma_R_fit100_sessionBIC.p\", \"wb\"))\n",
    "\n",
    "# load \n",
    "# alpha_fit = pickle.load(open(\"picklejar/alpha_fit100_sessionBIC.p\", \"rb\"))\n",
    "# gamma_fit = pickle.load(open(\"picklejar/gamma_fit100_sessionBIC.p\", \"rb\"))\n",
    "# alpha_t_fit = pickle.load(open(\"picklejar/alpha_t_fit100_sessionBIC.p\", \"rb\"))\n",
    "# gamma_t_fit = pickle.load(open(\"picklejar/gamma_t_fit100_sessionBIC.p\", \"rb\"))\n",
    "# alpha_R_fit = pickle.load(open(\"picklejar/alpha_R_fit100_sessionBIC.p\", \"rb\"))\n",
    "# gamma_R_fit = pickle.load(open(\"picklejar/gamma_R_fit100_sessionBIC.p\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 2, figsize=(10, 20))\n",
    "iters=1\n",
    "for idx, animal in enumerate(animalList):\n",
    "    for x, cond in zip([0, 2, 4, 4, 3, 2, 1, 0], [\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"]):\n",
    "\n",
    "        _alpha, _gamma, _alpha_t, _gamma_t, _alpha_R, _gamma_R = alpha[animal][cond], gamma[animal][cond], alpha_t[animal][cond], gamma_t[animal][cond], alpha_R[animal][cond], gamma_R[animal][cond]\n",
    "        truths = [_alpha, _alpha_t, _alpha_R, _gamma, _gamma_t, _gamma_R]\n",
    "\n",
    "        ylims = [[-.5, 3], [-.1, .65], [-.45, .5], [-.2, 1.6], [-.25, .1], [-.35, .1]]\n",
    "        vars = [alpha_fit[animal][cond], alpha_t_fit[animal][cond], alpha_R_fit[animal][cond], gamma_fit[animal][cond], gamma_t_fit[animal][cond], gamma_R_fit[animal][cond]]\n",
    "        if cond in [\"60\", \"90\", \"120\"]:\n",
    "\n",
    "            for i, (var, ylabel, ylim, true) in enumerate(zip(vars, ylabels, ylims, truths)):\n",
    "                # violinplot\n",
    "                # violin_parts = axs[i, 0].violinplot(var, positions=[x + (idx/10)])#, showmeans=True, showextrema=True, showmedians=False)\n",
    "\n",
    "                # for vp in violin_parts['bodies']:\n",
    "                #     # vp.set_facecolor(rat_markers[animal][0])\n",
    "                #     # vp.set_edgecolor(rat_markers[animal][0])\n",
    "                #     vp.set_facecolor('gray')\n",
    "                #     vp.set_edgecolor('gray')\n",
    "                #     vp.set_linewidth(1)\n",
    "                #     vp.set_alpha(0.5)\n",
    "\n",
    "                # for partname in ('cbars','cmins','cmaxes','cmeans','cmedians'):\n",
    "                #     try:\n",
    "                #         vp = violin_parts[partname]\n",
    "                #         # vp.set_edgecolor(rat_markers[animal][0])\n",
    "                #         vp.set_edgecolor('gray')\n",
    "                #         vp.set_linewidth(1)\n",
    "                #     except: pass\n",
    "\n",
    "                # scatter\n",
    "                axs[i, 0].scatter([x + np.random.normal(0, .0)+(idx/10) for i in range(iters)], var, color=rat_markers[animal][0], alpha=.25, linewidth=1, edgecolors='gray')\n",
    "                axs[i, 0].scatter([x + (idx/10)], true, color=rat_markers[animal][0], alpha=1, linewidth=1, edgecolors='k', zorder=10)\n",
    "\n",
    "                axs[i, 0].set_title(f\"\")\n",
    "                axs[i, 0].set_xticks([0, 2, 4])\n",
    "                axs[i, 0].set_xticklabels([\"60\", \"90\", \"120\"])\n",
    "                axs[i, 0].set_xlabel(\"Distance\")\n",
    "                axs[i, 0].set_ylabel(ylabel)\n",
    "                axs[i, 0].set_xlim(-1, 5)\n",
    "                axs[i, 0].set_ylim(ylim)\n",
    "                axs[i, 0].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "        else:\n",
    "            for i, (var, ylabel, ylim, true) in enumerate(zip(vars, ylabels, ylims, truths)):\n",
    "                # violin plot\n",
    "                # violin_parts = axs[i, 1].violinplot(var, positions=[x + idx/10])#, showmeans=False, showextrema=True, showmedians=True) \n",
    "\n",
    "                # for vp in violin_parts['bodies']:\n",
    "                #     # vp.set_facecolor(rat_markers[animal][0])\n",
    "                #     # vp.set_edgecolor(rat_markers[animal][0])\n",
    "                #     vp.set_facecolor('gray')\n",
    "                #     vp.set_edgecolor('gray')\n",
    "                #     vp.set_linewidth(1)\n",
    "                #     vp.set_alpha(0.5)\n",
    "\n",
    "                # for partname in ('cbars','cmins','cmaxes','cmeans','cmedians'):\n",
    "                #     try:\n",
    "                #         vp = violin_parts[partname]\n",
    "                #         # vp.set_edgecolor(rat_markers[animal][0])\n",
    "                #         vp.set_edgecolor('gray')\n",
    "                #         vp.set_linewidth(1)\n",
    "                #     except: pass\n",
    "\n",
    "                # scatter\n",
    "                axs[i, 1].scatter([x + np.random.normal(0, .0)+idx/10 for i in range(iters)], var, color=rat_markers[animal][0], alpha=.25, linewidth=1, edgecolors='gray')\n",
    "                axs[i, 1].scatter([x + idx/10], true, color=rat_markers[animal][0], alpha=1, linewidth=1, edgecolors='k', zorder=10)\n",
    "\n",
    "                axs[i, 1].set_title(f\"\")\n",
    "                axs[i, 1].set_xticks([4, 3, 2, 1, 0])\n",
    "                axs[i, 1].set_xticklabels([\"20\", \"10\", \"0\", \"-10\", \"-20\"])\n",
    "                axs[i, 1].set_xlabel(r'$v_{belt}$')\n",
    "                axs[i, 1].set_ylabel(ylabel)\n",
    "                axs[i, 1].set_xlim(-1, 5)\n",
    "                axs[i, 1].set_ylim(ylim)\n",
    "                axs[i, 1].axhline(0, color='black', linestyle='--', linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Generating total number of waiting times\n",
    "This has been moved above in interindividual variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) pooling AM/PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > AM/PM for all conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be merged with prepare_data_by_session\n",
    "\n",
    "def prepare_dataAMPM(animalList, sessionList, memsize=3, time_bins=6, AMPM=False):\n",
    "    \"\"\"prepare data for fitting\n",
    "    cut the data into time bins and reward bins and AM/PM\"\"\"\n",
    "    bin_size = 3600/time_bins\n",
    "    targetlist = generate_targetList(memsize)[::-1]\n",
    "    temp_data = {}\n",
    "    for bin in range(time_bins):\n",
    "        temp_data[bin] = {}\n",
    "        for animal in animalList:\n",
    "            temp_data[bin][animal] = {k:[] for k in meankeys(targetlist)}\n",
    "            for session in matchsession(animal, sessionList, AMPM=AMPM):\n",
    "                temp_data[bin][animal] = combine_dict(temp_data[bin][animal], get_waiting_times(sequence[animal, session], memsize=memsize, filter=[bin*bin_size, (bin+1)*bin_size]))\n",
    "    \n",
    "    data = {}\n",
    "    for animal in animalList:\n",
    "        data[animal] = np.zeros((time_bins, len(meankeys(targetlist)))).tolist()\n",
    "        for i, avg in enumerate(meankeys(targetlist)):  # 1 -> 0\n",
    "            for bin in range(time_bins):\n",
    "                data[animal][bin][i] = np.asarray(temp_data[bin][animal][avg])\n",
    "    return data\n",
    "\n",
    "\n",
    "data60AM, data60PM = prepare_dataAMPM(animalList, dist60, AMPM='AM'), prepare_dataAMPM(animalList, dist60, AMPM='PM')\n",
    "data90AM, data90PM = prepare_dataAMPM(animalList, dist90, AMPM='AM'), prepare_dataAMPM(animalList, dist90, AMPM='PM')\n",
    "data120AM, data120PM = prepare_dataAMPM(animalList, dist120, AMPM='AM'), prepare_dataAMPM(animalList, dist120, AMPM='PM')\n",
    "\n",
    "data20AM, data20PM = prepare_dataAMPM(animalList, TM20, AMPM='AM'), prepare_dataAMPM(animalList, TM20, AMPM='PM')\n",
    "data10AM, data10PM = prepare_dataAMPM(animalList, TM10, AMPM='AM'), prepare_dataAMPM(animalList, TM10, AMPM='PM')\n",
    "data2AM, data2PM = prepare_dataAMPM(animalList, TM2+TMrev2, AMPM='AM'), prepare_dataAMPM(animalList, TM2+TMrev2, AMPM='PM')\n",
    "datarev10AM, datarev10PM = prepare_dataAMPM(animalList, TMrev10, AMPM='AM'), prepare_dataAMPM(animalList, TMrev10, AMPM='PM')\n",
    "datarev20AM, datarev20PM = prepare_dataAMPM(animalList, TMrev20, AMPM='AM'), prepare_dataAMPM(animalList, TMrev20, AMPM='PM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetlist = generate_targetList(seq_len=4)[::-1]\n",
    "fig, axs = plt.subplots(6, 2, figsize=(10, 20), constrained_layout=True)\n",
    "\n",
    "\n",
    "ylabels = [r'$\\alpha$', r\"$\\alpha'$\", r\"$\\alpha''$\", r'$\\gamma$', r\"$\\gamma'$\", r\"$\\gamma''$\"]\n",
    "ylims = [[-.5, 3], [-.1, .65], [-.45, .5], [-.2, 1.6], [-.25, .1], [-.35, .1]]\n",
    "\n",
    "alphaAM = {}\n",
    "gammaAM = {}\n",
    "alpha_tAM = {}\n",
    "gamma_tAM = {}\n",
    "alpha_RAM = {}\n",
    "gamma_RAM = {}\n",
    "lossWaldAM = {}\n",
    "\n",
    "alphaPM = {}\n",
    "gammaPM = {}\n",
    "alpha_tPM = {}\n",
    "gamma_tPM = {}\n",
    "alpha_RPM = {}\n",
    "gamma_RPM = {}\n",
    "lossWaldPM = {}\n",
    "\n",
    "\n",
    "alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, False, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, True, True, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, True, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = True, True, True, True\n",
    "\n",
    "for animal in animalList:\n",
    "\n",
    "    alphaAM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    gammaAM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    alpha_tAM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    gamma_tAM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    alpha_RAM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    gamma_RAM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    lossWaldAM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "\n",
    "    alphaPM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    gammaPM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    alpha_tPM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    gamma_tPM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    alpha_RPM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    gamma_RPM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    lossWaldPM[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "\n",
    "\n",
    "    # AM ###########################################################\n",
    "    for cond, data in zip([\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"], [data60AM, data90AM, data120AM, data20AM, data10AM, data2AM, datarev10AM, datarev20AM]):\n",
    "        (alphaAM[animal][cond], thetaAM, gammaAM[animal][cond], \\\n",
    "        alpha_tAM[animal][cond], thetaprimeAM, gamma_tAM[animal][cond], \\\n",
    "        alpha_RAM[animal][cond], thetasecondAM, gamma_RAM[animal][cond]), lossWaldAM[animal][cond] = modelwald_fit(data[animal], alpha_t_fixed=alpha_t_fixed, \n",
    "                                                                                                                                    gamma_t_fixed=gamma_t_fixed, \n",
    "                                                                                                                                    alpha_R_fixed=alpha_R_fixed, \n",
    "                                                                                                                                    gamma_R_fixed=gamma_R_fixed)\n",
    "    \n",
    "    # PM ###########################################################\n",
    "    for cond, data in zip([\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"], [data60PM, data90PM, data120PM, data20PM, data10PM, data2PM, datarev10PM, datarev20PM]):\n",
    "        (alphaPM[animal][cond], thetaPM, gammaPM[animal][cond], \\\n",
    "        alpha_tPM[animal][cond], thetaprimePM, gamma_tPM[animal][cond], \\\n",
    "        alpha_RPM[animal][cond], thetasecondPM, gamma_RPM[animal][cond]), lossWaldPM[animal][cond] = modelwald_fit(data[animal], alpha_t_fixed=alpha_t_fixed,\n",
    "                                                                                                                                    gamma_t_fixed=gamma_t_fixed,    \n",
    "                                                                                                                                    alpha_R_fixed=alpha_R_fixed,\n",
    "                                                                                                                                    gamma_R_fixed=gamma_R_fixed)\n",
    "\n",
    "    varsAM = [alphaAM, alpha_tAM, alpha_RAM, gammaAM, gamma_tAM, gamma_RAM]\n",
    "    varsPM = [alphaPM, alpha_tPM, alpha_RPM, gammaPM, gamma_tPM, gamma_RPM]\n",
    "\n",
    "    for i, (varAM, varPM, ylabel, ylim) in enumerate(zip(varsAM, varsPM, ylabels, ylims)):\n",
    "        axs[i, 0].plot([0, .25], [varAM[animal][\"60\"], varPM[animal][\"60\"]], color=rat_markers[animal][0], label=animal, marker='o')\n",
    "        axs[i, 0].plot([1, 1.25], [varAM[animal][\"90\"], varPM[animal][\"90\"]], color=rat_markers[animal][0], label=animal, marker='o')\n",
    "        axs[i, 0].plot([2, 2.25], [varAM[animal][\"120\"], varPM[animal][\"120\"]], color=rat_markers[animal][0], label=animal, marker='o')\n",
    "        axs[i, 0].set_title(f\"\")\n",
    "        axs[i, 0].set_xticks(np.arange(3))\n",
    "        axs[i, 0].set_xticklabels([\"60\", \"90\", \"120\"])\n",
    "        axs[i, 0].set_xlabel(\"Distance\", fontsize=14)\n",
    "        axs[i, 0].set_ylabel(ylabel, fontsize=14)\n",
    "        axs[i, 0].set_xlim(-.5, 2.5)\n",
    "        axs[i, 0].set_ylim(ylim)\n",
    "        axs[i, 0].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    for i, (varAM, varPM, ylabel, ylim) in enumerate(zip(varsAM, varsPM, ylabels, ylims)):\n",
    "        axs[i, 1].plot([0, .25], [varAM[animal][\"20\"], varPM[animal][\"20\"]], color=rat_markers[animal][0], label=animal, marker='o')\n",
    "        axs[i, 1].plot([1, 1.25], [varAM[animal][\"10\"], varPM[animal][\"10\"]], color=rat_markers[animal][0], label=animal, marker='o')\n",
    "        axs[i, 1].plot([2, 2.25], [varAM[animal][\"2\"], varPM[animal][\"2\"]], color=rat_markers[animal][0], label=animal, marker='o')\n",
    "        axs[i, 1].plot([3, 3.25], [varAM[animal][\"rev10\"], varPM[animal][\"rev10\"]], color=rat_markers[animal][0], label=animal, marker='o')\n",
    "        axs[i, 1].plot([4, 4.25], [varAM[animal][\"rev20\"], varPM[animal][\"rev20\"]], color=rat_markers[animal][0], label=animal, marker='o') \n",
    "        axs[i, 1].set_title(f\"\")\n",
    "        axs[i, 1].set_xticks(np.arange(5))\n",
    "        axs[i, 1].set_xticklabels([\"20\", \"10\", \"0\", \"-10\", \"-20\"])\n",
    "        axs[i, 1].set_xlabel(r'$v_{belt}$', fontsize=14)\n",
    "        axs[i, 1].set_ylabel(ylabel, fontsize=14)\n",
    "        axs[i, 1].set_xlim(-.5, 4.5)\n",
    "        axs[i, 1].set_ylim(ylim)\n",
    "        axs[i, 1].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "\n",
    "# # comp ampm\n",
    "for idx, cond in enumerate([\"60\", \"90\", \"120\"]):\n",
    "    for jdx, (varAM, varPM) in enumerate(zip(varsAM, varsPM)):\n",
    "        s, p = stats.ttest_rel([varAM[animal][cond] for animal in animalList], [varPM[animal][cond] for animal in animalList])\n",
    "        if p < .05: axs[jdx, 0].scatter(idx+.125, (np.mean([varAM[animal][cond] for animal in animalList])+np.mean([varPM[animal][cond] for animal in animalList]))/2, color='r', marker=r'$\\ast$', zorder=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > AM/PM pooling conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only dist\n",
    "# dataallAM = prepare_dataAMPM(animalList, dist60+dist90+dist120, AMPM='AM')\n",
    "# dataallPM = prepare_dataAMPM(animalList, dist60+dist90+dist120, AMPM='PM')\n",
    "\n",
    "# only TM\n",
    "# dataallAM = prepare_dataAMPM(animalList, TM20+TM10+TM2+TMrev2+TMrev10+TMrev20, AMPM='AM')\n",
    "# dataallPM = prepare_dataAMPM(animalList, TM20+TM10+TM2+TMrev2+TMrev10+TMrev20, AMPM='PM')\n",
    "\n",
    "# all\n",
    "dataallAM = prepare_dataAMPM(animalList, dist60+dist90+dist120+TM20+TM10+TM2+TMrev2+TMrev10+TMrev20, AMPM='AM')\n",
    "dataallPM = prepare_dataAMPM(animalList, dist60+dist90+dist120+TM20+TM10+TM2+TMrev2+TMrev10+TMrev20, AMPM='PM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same but pool all experimental conditions\n",
    "targetlist = generate_targetList(seq_len=4)[::-1]\n",
    "fig, axs = plt.subplots(6, 1, figsize=(5, 20))\n",
    "\n",
    "\n",
    "ylabels = [r'$\\alpha$', r\"$\\alpha'$\", r\"$\\alpha''$\", r'$\\gamma$', r\"$\\gamma'$\", r\"$\\gamma''$\"]\n",
    "ylims = [[-.5, 3], [-.1, .65], [-.45, .5], [-.2, 1.6], [-.25, .1], [-.35, .1]]\n",
    "\n",
    "alphaAM = {}\n",
    "gammaAM = {}\n",
    "alpha_tAM = {}\n",
    "gamma_tAM = {}\n",
    "alpha_RAM = {}\n",
    "gamma_RAM = {}\n",
    "lossWaldAM = {}\n",
    "\n",
    "alphaPM = {}\n",
    "gammaPM = {}\n",
    "alpha_tPM = {}\n",
    "gamma_tPM = {}\n",
    "alpha_RPM = {}\n",
    "gamma_RPM = {}\n",
    "lossWaldPM = {}\n",
    "\n",
    "\n",
    "alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, False, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, True, True, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, True, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = True, True, True, True\n",
    "\n",
    "for animal in animalList:\n",
    "\n",
    "    # AM ###########################################################\n",
    "    (alphaAM[animal], thetaAM, gammaAM[animal], \\\n",
    "    alpha_tAM[animal], thetaprimeAM, gamma_tAM[animal], \\\n",
    "    alpha_RAM[animal], thetasecondAM, gamma_RAM[animal]), lossWaldAM[animal] = modelwald_fit(dataallAM[animal], alpha_t_fixed=alpha_t_fixed, \n",
    "                                                                                                                                    gamma_t_fixed=gamma_t_fixed, \n",
    "                                                                                                                                    alpha_R_fixed=alpha_R_fixed, \n",
    "                                                                                                                                    gamma_R_fixed=gamma_R_fixed)\n",
    "    # PM ###########################################################                                                                                                                                \n",
    "    (alphaPM[animal], thetaPM, gammaPM[animal], \\\n",
    "    alpha_tPM[animal], thetaprimePM, gamma_tPM[animal], \\\n",
    "    alpha_RPM[animal], thetasecondPM, gamma_RPM[animal]), lossWaldPM[animal] = modelwald_fit(dataallPM[animal], alpha_t_fixed=alpha_t_fixed,\n",
    "                                                                                                                                    gamma_t_fixed=gamma_t_fixed,    \n",
    "                                                                                                                                    alpha_R_fixed=alpha_R_fixed,\n",
    "                                                                                                                                    gamma_R_fixed=gamma_R_fixed)\n",
    "\n",
    "    varsAM = [alphaAM, alpha_tAM, alpha_RAM, gammaAM, gamma_tAM, gamma_RAM]\n",
    "    varsPM = [alphaPM, alpha_tPM, alpha_RPM, gammaPM, gamma_tPM, gamma_RPM]\n",
    "\n",
    "    for i, (varAM, varPM, ylabel, ylim) in enumerate(zip(varsAM, varsPM, ylabels, ylims)):\n",
    "        axs[i].plot([0, 1], [varAM[animal], varPM[animal]], color=rat_markers[animal][0], label=animal, marker='o')\n",
    "        axs[i].set_title(f\"\")\n",
    "        axs[i].set_xticks([0, 1])\n",
    "        axs[i].set_xticklabels([\"all AM\", \"all PM\"])\n",
    "        axs[i].set_xlabel(\"all conditions\", fontsize=14)\n",
    "        axs[i].set_ylabel(ylabel, fontsize=14)\n",
    "        axs[i].set_xlim(-.5, 1.5)\n",
    "        axs[i].set_ylim(ylim)\n",
    "        axs[i].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "\n",
    "# # comp ampm\n",
    "for jdx, (varAM, varPM) in enumerate(zip(varsAM, varsPM)):\n",
    "    s, p = stats.ttest_rel([varAM[animal] for animal in animalList], [varPM[animal] for animal in animalList])\n",
    "    print(jdx, p)\n",
    "    if p < .05: axs[jdx].scatter(0.5, (np.mean([varAM[animal] for animal in animalList])+np.mean([varPM[animal] for animal in animalList]))/2, color='r', marker=r'$\\ast$', zorder=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Misc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to do that \n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.plot([0, 1], [70, 80], color='k', marker='o', linestyle='--')\n",
    "\n",
    "\n",
    "ax.set_xlim([-.4,1.4])\n",
    "ax.set_ylim([63,85])\n",
    "ax.spines['left'].set_bounds(65,85)\n",
    "ax.spines['bottom'].set_bounds(0,1)\n",
    "ax.set_yticks(np.arange(65,86,5))\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels([f'Control\\n$n={4}$',f'Lesion\\n$n={6}$'])\n",
    "ax.set_ylabel('Max. Pos. (cm)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# link T with total water or total dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal, session = 'RatF00', 'RatF00_2021_07_18_10_36_33'  # tm90\n",
    "seq = sequence['RatF00', 'RatF00_2021_07_18_10_36_33']\n",
    "\n",
    "time = read_csv_pandas((root+os.sep+animal+os.sep+\"Experiments\"+os.sep + session + os.sep+session+\".position\"), Col=[3])[:90000]\n",
    "pos  = read_csv_pandas((root+os.sep+animal+os.sep+\"Experiments\"+os.sep + session + os.sep+session+\".position\"), Col=[4])[:90000]/11\n",
    "tot = [0]\n",
    "tot.extend(abs(np.diff(pos)))\n",
    "\n",
    "totaldist = np.cumsum(tot) / 100\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 5))\n",
    "axs.plot(time, totaldist, color='k')\n",
    "axs.set_xlabel('time [s]')\n",
    "\n",
    "\n",
    "data = bin_seq(seq)\n",
    "rw, trw = [], []\n",
    "for i in range(12):\n",
    "    for a in range(0, len(data[i])):\n",
    "        if data[i][a][1] == \"run\":\n",
    "            rw.append(data[i][a][2])\n",
    "            trw.append(data[i][a][0])\n",
    "            \n",
    "totalreward = np.zeros(len(time))\n",
    "for i in range(len(trw)):\n",
    "    totalreward[np.argmin(np.abs(time-trw[i]))+1] = rw[i]\n",
    "totalreward = np.cumsum(totalreward)\n",
    "\n",
    "axs.plot(time, totalreward, color='c')\n",
    "axs.set_xlabel('time [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wait_duration, moment_of_wait = [], []\n",
    "for a in range(0, len(seq)):\n",
    "        if seq[a][1] == \"stay\":\n",
    "            wait_duration.append(seq[a][3])\n",
    "            moment_of_wait.append(seq[a][0])\n",
    "plt.plot(moment_of_wait, wait_duration, color='k')\n",
    "\n",
    "dist_at_moment_of_wait = np.zeros(len(moment_of_wait))\n",
    "water_at_moment_of_wait = np.zeros(len(moment_of_wait))\n",
    "for i in range(len(moment_of_wait)):\n",
    "    dist_at_moment_of_wait[i] = totaldist[int(moment_of_wait[i]*25)]\n",
    "    water_at_moment_of_wait[i] = totalreward[int(moment_of_wait[i]*25)]\n",
    "\n",
    "plt.plot(moment_of_wait, dist_at_moment_of_wait, color='r')\n",
    "plt.plot(moment_of_wait, water_at_moment_of_wait, color='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_duration, moment_of_run = [], []\n",
    "for a in range(0, len(seq)):\n",
    "        if seq[a][1] == \"run\":\n",
    "            run_duration.append(seq[a][3])\n",
    "            moment_of_run.append(seq[a][0])\n",
    "plt.plot(moment_of_run, run_duration, color='k')\n",
    "\n",
    "# get distance traveled at time truntime\n",
    "dist_at_moment_of_run = np.zeros(len(moment_of_run))\n",
    "water_at_moment_of_run = np.zeros(len(moment_of_run))\n",
    "for i in range(len(moment_of_run)):\n",
    "    dist_at_moment_of_run[i] = totaldist[int(moment_of_run[i]*25)]\n",
    "    water_at_moment_of_run[i] = totalreward[int(moment_of_run[i]*25)]\n",
    "\n",
    "plt.plot(moment_of_run, dist_at_moment_of_run, color='r')\n",
    "plt.plot(moment_of_run, water_at_moment_of_run, color='c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bin_seq(seq)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axs[0, 0].plot(dist_at_moment_of_run, run_duration, color='k', marker='o', lw=0)\n",
    "# axs[0, 0].set_ylim(0, 2.5)\n",
    "axs[0, 0].set_yscale('log')\n",
    "axs[0, 0].set_xlabel('distance traveled [m]')\n",
    "axs[0, 0].set_ylabel('run duration [s]')\n",
    "\n",
    "axs[0, 1].plot(water_at_moment_of_run, run_duration, color='k', marker='o', lw=0)\n",
    "axs[0, 1].set_yscale('log')\n",
    "axs[0, 1].set_xlabel('rewards obtained [n]')\n",
    "axs[0, 1].set_ylabel('run duration [s]')\n",
    "\n",
    "axs[1, 0].plot(dist_at_moment_of_wait, wait_duration, color='k', marker='o', lw=0)\n",
    "axs[1, 0].set_yscale('log')\n",
    "axs[1, 0].set_xlabel('distance traveled [m]')\n",
    "axs[1, 0].set_ylabel('idle duration [s]')\n",
    "\n",
    "axs[1, 1].plot(water_at_moment_of_wait, wait_duration, color='k', marker='o', lw=0)\n",
    "axs[1, 1].set_yscale('log')\n",
    "axs[1, 1].set_xlabel('rewards obtained [n]')\n",
    "axs[1, 1].set_ylabel('idle duration [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bin_seq(seq)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axs[0, 0].plot(dist_at_moment_of_run, np.cumsum(run_duration), color='k', marker='o', lw=0)\n",
    "# axs[0, 0].set_yscale('log')\n",
    "axs[0, 0].set_xlabel('distance traveled [m]')\n",
    "axs[0, 0].set_ylabel('run duration [s]')\n",
    "\n",
    "axs[0, 1].plot(water_at_moment_of_run, np.cumsum(run_duration), color='k', marker='o', lw=0)\n",
    "# axs[0, 1].set_yscale('log')\n",
    "axs[0, 1].set_xlabel('rewards obtained [n]')\n",
    "axs[0, 1].set_ylabel('run duration [s]')\n",
    "\n",
    "axs[1, 0].plot(dist_at_moment_of_wait, np.cumsum(wait_duration), color='k', marker='o', lw=0)\n",
    "# axs[1, 0].set_yscale('log')\n",
    "axs[1, 0].set_xlabel('distance traveled [m]')\n",
    "axs[1, 0].set_ylabel('idle duration [s]')\n",
    "\n",
    "axs[1, 1].plot(water_at_moment_of_wait, np.cumsum(wait_duration), color='k', marker='o', lw=0)\n",
    "# axs[1, 1].set_yscale('log')\n",
    "axs[1, 1].set_xlabel('rewards obtained [n]')\n",
    "axs[1, 1].set_ylabel('idle duration [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(15, 5))\n",
    "_x, _y = [], []\n",
    "\n",
    "for elem in seq: \n",
    "    if seq[elem][1]=='run':\n",
    "        _x.append(seq[elem][0])\n",
    "        _y.append(seq[elem][3])\n",
    "        # axs.scatter(seq[elem][0], seq[elem][3], c='dodgerblue')\n",
    "axs.plot(_x, _y, marker='o', c='k', lw=0)\n",
    "axs.set_ylim(0.5, 2.5)\n",
    "\n",
    "gradient, intercept, r_value, p_value, std_err = stats.linregress(_x, _y)\n",
    "\n",
    "\n",
    "gradient, intercept = stats.siegelslopes(_y, _x)\n",
    "axs.plot(time, gradient * time + intercept, color='black', lw=2)\n",
    "print(gradient, intercept)\n",
    "\n",
    "\n",
    "# mu0=1.1789160402663743+- 0.019960534970052304\n",
    "# mut=0.07473171153304926+-0.014515223630007406\n",
    "# mut = change in 10 min\n",
    "# 10 min = 600sec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mass in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = a, t, g, a', t', g', a'', t'', g''\n",
    "def modelwald_fitW(data, init=[2, 0, .5, 0, 0, 0, 0, 0, 0],\n",
    "                  f=model_crit, N_bins=6, N_avg=4, N_params=2, weight=1, \n",
    "                  alpha_t_fixed=False, gamma_t_fixed=False,\n",
    "                  alpha_R_fixed=False, gamma_R_fixed=False,\n",
    "                  ):\n",
    "    \"\"\"fit full model to data\"\"\"\n",
    "    params_init = np.array(init)\n",
    "    alpha_t_bounds = (None, None) if not alpha_t_fixed else (0, 1e-8)\n",
    "    gamma_t_bounds = (None, None) if not gamma_t_fixed else (0, 1e-8)\n",
    "    alpha_R_bounds = (None, None) if not alpha_R_fixed else (0, 1e-8)\n",
    "    gamma_R_bounds = (None, None) if not gamma_R_fixed else (0, 1e-8)\n",
    "\n",
    "    res = minimize(f, params_init, args=(data, [N_bins, N_avg], N_params, weight),\n",
    "                   bounds=((0, None), (0, 1e-8), (0, None),\n",
    "                   alpha_t_bounds, (0, 1e-8), gamma_t_bounds,\n",
    "                   alpha_R_bounds, (0, 1e-8), gamma_R_bounds))\n",
    "    return res.x, res.fun\n",
    "\n",
    "def model_critW(params, *args, robustness_param=1e-20):\n",
    "    \"\"\"negative log likelihood function for full model\"\"\"\n",
    "    alpha, theta, gamma, alpha_t, theta_prime, gamma_t, alpha_R, theta_second, gamma_R = params\n",
    "    neg_log_lik_val = 0\n",
    "    N_bins, N_avg = args[1]\n",
    "    N_params = args[2]\n",
    "    weight = args[3]\n",
    "    ALPHA = np.zeros((N_bins, N_avg))\n",
    "    GAMMA = np.zeros((N_bins, N_avg))\n",
    "    _theta = theta + theta_prime + theta_second\n",
    "\n",
    "    for bin in range(N_bins):\n",
    "        for avg in range(N_avg):\n",
    "            ALPHA[bin, avg] = alpha/weight + bin*alpha_t/weight + avg*alpha_R/weight\n",
    "            GAMMA[bin, avg] = gamma/weight + bin*gamma_t/weight + avg*gamma_R/weight\n",
    "\n",
    "    for bin in range(N_bins):\n",
    "        for avg in range(N_avg):\n",
    "            _alpha = ALPHA[bin, avg] if ALPHA[bin, avg] > 0 else 1e-8\n",
    "            _gamma = GAMMA[bin, avg]# if GAMMA[bin, avg] > 0 else 1e-8\n",
    "            try:\n",
    "                pdf_vals = Wald_pdf(args[0][bin][avg], _alpha, _theta, _gamma)\n",
    "                ln_pdf_vals = np.log(pdf_vals + robustness_param)\n",
    "                log_lik_val = ln_pdf_vals.sum()\n",
    "\n",
    "                n = len(args[0][bin][avg]) if len(args[0][bin][avg]) > 0 else 1\n",
    "                neg_log_lik_val += (-log_lik_val / n)\n",
    "            except:\n",
    "                neg_log_lik_val += 0  # add 0 instead of throwing an error when there is no data in a bin*avg\n",
    "    return neg_log_lik_val\n",
    "\n",
    "modelwald_fitW(data[animal], f=model_critW, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, figsize=(12, 20), gridspec_kw={'width_ratios': [5, 5, 2]})\n",
    "\n",
    "\n",
    "ylabels = [r'$\\alpha_0$', r\"$\\alpha_t$\", r\"$\\alpha_R$\", r'$\\gamma_0$', r\"$\\gamma_t$\", r\"$\\gamma_R$\"]\n",
    "ylims = [[-.5, 3], [-.1, .65], [-.45, .5], [-.2, 1.6], [-.25, .1], [-.35, .1]]\n",
    "\n",
    "alpha, gamma, alpha_t, gamma_t, alpha_R, gamma_R, lossWald = {}, {}, {}, {}, {}, {}, {}\n",
    "alphaPool, gammaPool, alpha_tPool, gamma_tPool, alpha_RPool, gamma_RPool, lossWaldPool = {}, {}, {}, {}, {}, {}, {}\n",
    "\n",
    "alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, False, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, True, True, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = False, False, True, False\n",
    "# alpha_t_fixed, gamma_t_fixed, alpha_R_fixed, gamma_R_fixed = True, True, True, True\n",
    "\n",
    "alpha_fit, gamma_fit, alpha_t_fit, gamma_t_fit, alpha_R_fit, gamma_R_fit = {}, {}, {}, {}, {}, {}\n",
    "if os.path.exists(\"picklejar/resamplingParameters100ITER.p\"):\n",
    "    alpha_fit, gamma_fit, alpha_t_fit, gamma_t_fit, alpha_R_fit, gamma_R_fit = pickle.load(open(\"picklejar/resamplingParameters100ITER.p\", \"rb\"))\n",
    "    \n",
    "alpha_fitPooled, alpha_t_fitPooled, alpha_R_fitPooled, gamma_fitPooled, gamma_t_fitPooled, gamma_R_fitPooled = {}, {}, {}, {}, {}, {}\n",
    "if os.path.exists(\"picklejar/resamplingParameters100ITER_Pooled.p\"):\n",
    "    alpha_fitPooled, alpha_t_fitPooled, alpha_R_fitPooled, gamma_fitPooled, gamma_t_fitPooled, gamma_R_fitPooled = pickle.load(open(\"picklejar/resamplingParameters100ITER_Pooled.p\", \"rb\"))\n",
    "    \n",
    "\n",
    "for animal in animalList:\n",
    "    alpha[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    gamma[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    alpha_t[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    gamma_t[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    alpha_R[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    gamma_R[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "    lossWald[animal] = {\"60\": 0, \"90\": 0, \"120\": 0, \"20\": 0, \"10\": 0, \"2\": 0, \"rev10\": 0, \"rev20\": 0}\n",
    "\n",
    "\n",
    "    for cond, data in zip([\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"], [data60, data90, data120, data20, data10, data2, datarev10, datarev20]):\n",
    "        (alpha[animal][cond], theta, gamma[animal][cond], \\\n",
    "        alpha_t[animal][cond], thetaprime, gamma_t[animal][cond], \\\n",
    "        alpha_R[animal][cond], thetasecond, gamma_R[animal][cond]), lossWald[animal][cond] = modelwald_fitW(data[animal], f=model_critW, weight=weights[animal]/1000,\n",
    "                                                                                                            alpha_t_fixed=alpha_t_fixed, \n",
    "                                                                                                                                    gamma_t_fixed=gamma_t_fixed, \n",
    "                                                                                                                                    alpha_R_fixed=alpha_R_fixed, \n",
    "                                                                                                                                    gamma_R_fixed=gamma_R_fixed, \n",
    "                                                                                                                                    )\n",
    "    vars = [alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R]\n",
    "    varsPool = [alphaPool, alpha_tPool, alpha_RPool, gammaPool, gamma_tPool, gamma_RPool]\n",
    "    resampled = [alpha_fit, alpha_t_fit, alpha_R_fit, gamma_fit, gamma_t_fit, gamma_R_fit]\n",
    "    resampledPooled = [alpha_fitPooled, alpha_t_fitPooled, alpha_R_fitPooled, gamma_fitPooled, gamma_t_fitPooled, gamma_R_fitPooled]\n",
    "\n",
    "    def _percentiles(sample):\n",
    "            s = np.sort(sample)\n",
    "            return s[int(.05 * len(s))], s[int(.95 * len(s))]\n",
    "\n",
    "    for i, (var, ylabel, ylim, resample) in enumerate(zip(vars, ylabels, ylims, resampled)):\n",
    "        \n",
    "        # axs[i, 0].plot((0, 0), _percentiles(resample[animal]['60']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 0].plot((1, 1), _percentiles(resample[animal]['90']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 0].plot((2, 2), _percentiles(resample[animal]['120']), color=rat_markers[animal][0], lw=2)\n",
    "\n",
    "        x, y = np.arange(3), [var[animal][\"60\"], var[animal][\"90\"], var[animal][\"120\"]]\n",
    "        axs[i, 0].plot(x, y, color=rat_markers[animal][0], label=animal, marker=rat_markers[animal][1], markersize=6.5, lw=2)\n",
    "        # gradient, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "        # axs[i, 0].plot(np.linspace(np.min(x), np.max(x), 100), gradient * np.linspace(np.min(x), np.max(x), 100) + intercept, color=rat_markers[animal][0], lw=2 if p_value < .05 else .5)\n",
    "        axs[i, 0].set_title(f\"\")\n",
    "        axs[i, 0].set_xticks(np.arange(3))\n",
    "        axs[i, 0].set_xticklabels([\"60\", \"90\", \"120\"])\n",
    "        axs[i, 0].set_ylabel(ylabel)\n",
    "        axs[i, 0].set_xlim(-.5, 2.5)\n",
    "        # axs[i, 0].set_ylim(ylim)\n",
    "        axs[i, 0].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    for i, (var, ylabel, ylim, resample) in enumerate(zip(vars, ylabels, ylims, resampled)):\n",
    "\n",
    "        # axs[i, 1].plot((0, 0), _percentiles(resample[animal]['20']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 1].plot((1, 1), _percentiles(resample[animal]['10']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 1].plot((2, 2), _percentiles(resample[animal]['2']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 1].plot((3, 3), _percentiles(resample[animal]['rev10']), color=rat_markers[animal][0], lw=2)\n",
    "        # axs[i, 1].plot((4, 4), _percentiles(resample[animal]['rev20']), color=rat_markers[animal][0], lw=2)\n",
    "\n",
    "        x, y = np.arange(5), [var[animal][\"20\"], var[animal][\"10\"], var[animal][\"2\"], var[animal][\"rev10\"], var[animal][\"rev20\"]]\n",
    "        axs[i, 1].plot(x, y, color=rat_markers[animal][0], label=animal, marker=rat_markers[animal][1], markersize=6.5, lw=2)\n",
    "        # gradient, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "        # axs[i, 1].plot(np.linspace(np.min(x), np.max(x), 100), gradient * np.linspace(np.min(x), np.max(x), 100) + intercept, color=rat_markers[animal][0], lw=2 if p_value < .05 else .5)\n",
    "        axs[i, 1].set_title(f\"\")\n",
    "        axs[i, 1].set_xticks(np.arange(5))\n",
    "        axs[i, 1].set_xticklabels([\"20\", \"10\", \"0\", \"-10\", \"-20\"])\n",
    "        axs[i, 1].set_ylabel(ylabel)\n",
    "        axs[i, 1].set_xlim(-.5, 4.5)\n",
    "        # axs[i, 1].set_ylim(ylim)\n",
    "        axs[i, 1].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    # for i, (var, ylabel, ylim, resample) in enumerate(zip(varsPool, ylabels, ylims, resampledPooled)):\n",
    "    #     # axs[i, 2].plot((0, 0), _percentiles(resample[animal]), color=rat_markers[animal][0], lw=2)\n",
    "\n",
    "    #     x, y = 0, var[animal]\n",
    "    #     axs[i, 2].scatter(x, y, color=rat_markers[animal][0], label=animal, marker=rat_markers[animal][1], s=50)\n",
    "    #     axs[i, 2].set_title(f\"\")\n",
    "    #     axs[i, 2].set_xticks([])\n",
    "    #     axs[i, 2].set_ylabel(ylabel)\n",
    "    #     axs[i, 2].set_xlim(-.5, .5)\n",
    "    #     axs[i, 2].set_ylim(ylim)\n",
    "    #     axs[i, 2].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "axs[i, 0].set_xlabel(\"Distance\")\n",
    "axs[i, 1].set_xlabel(r'$v_{belt}$')\n",
    "axs[i, 2].set_xlabel(\"All conditions pooled\")\n",
    "\n",
    "#mean per condition\n",
    "for idx, cond in enumerate([\"60\", \"90\", \"120\"]):\n",
    "    for jdx, var in enumerate([alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R]):\n",
    "        d = [var[animal][cond] for animal in animalList]\n",
    "        mean, std = np.mean(d), np.std(d)/np.sqrt(len(d))\n",
    "        s, p = stats.wilcoxon(d)\n",
    "        if p < .05: axs[jdx, 0].scatter(idx+.3, mean, color='k', marker=r'$\\ast$')\n",
    "        axs[jdx, 0].errorbar(idx+.2, mean, yerr=std, color='black', marker='o', markersize=5, capsize=5, capthick=2, linewidth=2)\n",
    "\n",
    "for idx, cond in enumerate([\"20\", \"10\", \"2\", \"rev10\", \"rev20\"]):\n",
    "    for jdx, var in enumerate([alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R]):\n",
    "        d = [var[animal][cond] for animal in animalList]\n",
    "        mean, std = np.mean(d), np.std(d)/np.sqrt(len(d))\n",
    "        s, p = stats.wilcoxon(d)\n",
    "        if p < .05: axs[jdx, 1].scatter(idx+.3, mean, color='k', marker=r'$\\ast$')\n",
    "        axs[jdx, 1].errorbar(idx+.2, mean, yerr=std, color='black', marker='o', markersize=5, capsize=5, capthick=2, linewidth=2)\n",
    "\n",
    "test_all_conds_between_themselves([\"60\", \"90\", \"120\"], vars, ax=axs[:, 0])\n",
    "test_all_conds_between_themselves([\"20\", \"10\", \"2\", \"rev10\", \"rev20\"], vars, ax=axs[:, 1])\n",
    "\n",
    "# pickle.dump([alpha, alpha_t, alpha_R, gamma, gamma_t, gamma_R], open(\"picklejar/main_fitting_results.p\", \"wb\"))\n",
    "# pickle.dump([alphaPool, alpha_tPool, alpha_RPool, gammaPool, gamma_tPool, gamma_RPool], open(\"picklejar/main_fitting_results_pooled.p\", \"wb\"))\n",
    "\n",
    "Zalpha = {animal: {key: (alpha[animal][key] - np.mean([alpha[animal][key] for animal in animalList]))/np.std([alpha[animal][key] for animal in animalList]) for key in alpha[animal]} for animal in animalList}\n",
    "Zalpha_t = {animal: {key: (alpha_t[animal][key] - np.mean([alpha_t[animal][key] for animal in animalList]))/np.std([alpha_t[animal][key] for animal in animalList]) for key in alpha_t[animal]} for animal in animalList}\n",
    "Zalpha_R = {animal: {key: (alpha_R[animal][key] - np.mean([alpha_R[animal][key] for animal in animalList]))/np.std([alpha_R[animal][key] for animal in animalList]) for key in alpha_R[animal]} for animal in animalList}\n",
    "Zgamma = {animal: {key: (gamma[animal][key] - np.mean([gamma[animal][key] for animal in animalList]))/np.std([gamma[animal][key] for animal in animalList]) for key in gamma[animal]} for animal in animalList}\n",
    "Zgamma_t = {animal: {key: (gamma_t[animal][key] - np.mean([gamma_t[animal][key] for animal in animalList]))/np.std([gamma_t[animal][key] for animal in animalList]) for key in gamma_t[animal]} for animal in animalList}\n",
    "Zgamma_R = {animal: {key: (gamma_R[animal][key] - np.mean([gamma_R[animal][key] for animal in animalList]))/np.std([gamma_R[animal][key] for animal in animalList]) for key in gamma_R[animal]} for animal in animalList}\n",
    "\n",
    "traits = {animal: [] for animal in animalList}\n",
    "Zvars = [Zalpha, Zalpha_t, Zalpha_R, Zgamma, Zgamma_t, Zgamma_R]\n",
    "for j, zvar in enumerate(Zvars):\n",
    "    for animal in animalList:\n",
    "        zscores = [zvar[animal][cond] for cond in [\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"]]\n",
    "        pdf = stats.norm.pdf(np.linspace(-3, 3, 600), np.mean(zscores), np.std(zscores))\n",
    "        traits[animal].append(np.mean(zscores))\n",
    "        axs[j, 2].plot(pdf, np.linspace(-3, 3, 600), color=rat_markers[animal][0], linestyle=lines[brainstatus[animal]])\n",
    "        axs[j, 2].set_ylim(-3, 3)\n",
    "        axs[j, 2].set_ylabel(\"Z-scored \" + ylabels[j])\n",
    "        axs[j, 2].set_xlabel(\"\")\n",
    "        axs[j, 2].set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'RatF00': 212.02, 'RatF01': 205.85, 'RatF02': 193.75,\n",
    "            'RatM00': 259.37, 'RatM01': 278.12, 'RatM02': 253.19,\n",
    "            'RatF20': 220.10, 'RatF21': 215.53, 'RatF22': 215.0,\n",
    "            'RatM20': 254.68, 'RatM21': 307.29, 'RatM22': 330.53,\n",
    "            'RatF30': 217.32, 'RatF31': 228.95, 'RatF32': 216.80, 'RatF33': 222.77,\n",
    "            'RatM30': 261.38, 'RatM31': 300.55, 'RatM32': 279.23, \n",
    "            'RatF30L': 217.32, 'RatF31L': 228.95, 'RatF32L': 216.80, 'RatF33L': 222.77,\n",
    "            'RatM30L': 261.38, 'RatM31L': 300.55, 'RatM32L': 279.23}\n",
    "\n",
    "fig, ax = plt.subplots(1, 6, figsize=(15, 3))\n",
    "for j, zvar in enumerate(Zvars):\n",
    "    _x, _y = [], []\n",
    "    for animal in animalList:\n",
    "        zscores = [zvar[animal][cond] for cond in [\"60\", \"90\", \"120\", \"20\", \"10\", \"2\", \"rev10\", \"rev20\"]]\n",
    "        y = np.mean(zscores)\n",
    "        x = weights[animal]\n",
    "\n",
    "        ax[j].scatter(x, y, color=rat_markers[animal][0])\n",
    "        ax[j].set_xlabel(\"Weight (g)\")\n",
    "        ax[j].set_ylabel(ylabels[j])\n",
    "        ax[j].set_ylim(-2, 2)\n",
    "\n",
    "        _x.append(x)\n",
    "        _y.append(y)\n",
    "\n",
    "    pearson = stats.pearsonr(_x, _y)\n",
    "    print(ylabels[j]+f' corr: {pearson[0]:.2f}, p: {pearson[1]:.4f}')\n",
    "    \n",
    "    gradient, intercept, r_value, p_value, std_err = stats.linregress(_x, _y)\n",
    "    ax[j].plot(np.linspace(np.min(_x), np.max(_x), 100), gradient * np.linspace(np.min(_x), np.max(_x), 100) + intercept, color='black', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "a05f93782d31fb45d30263a0389582a01d7e14abf3ec6aacde92652303ee35ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
